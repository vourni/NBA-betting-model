{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c41ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Downloading data\n",
    "\"\"\"\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "years = range(1, 25)\n",
    "seasons = [f\"20{i:02d}-{(i+1)%100:02d}\" for i in years]\n",
    "\n",
    "to_merge = []\n",
    "for s in seasons:\n",
    "    time.sleep(1)\n",
    "    finder = leaguegamefinder.LeagueGameFinder(\n",
    "        season_nullable=s,\n",
    "        season_type_nullable=\"Regular Season\",\n",
    "        league_id_nullable='00'\n",
    "    )\n",
    "\n",
    "    game_df = finder.get_data_frames()[0]\n",
    "    to_merge.append(game_df)\n",
    "\n",
    "games_df = pd.concat(to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14763311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SEASON_ID_home', 'TEAM_ID_home', 'TEAM_ABBREVIATION_home',\n",
      "       'TEAM_NAME_home', 'GAME_ID', 'GAME_DATE_home', 'MATCHUP_home',\n",
      "       'WL_home', 'MIN_home', 'PTS_home', 'FGM_home', 'FGA_home',\n",
      "       'FG_PCT_home', 'FG3M_home', 'FG3A_home', 'FG3_PCT_home', 'FTM_home',\n",
      "       'FTA_home', 'FT_PCT_home', 'OREB_home', 'DREB_home', 'REB_home',\n",
      "       'AST_home', 'STL_home', 'BLK_home', 'TOV_home', 'PF_home',\n",
      "       'PLUS_MINUS_home', 'HOME_home', 'SEASON_ID_away', 'TEAM_ID_away',\n",
      "       'TEAM_ABBREVIATION_away', 'TEAM_NAME_away', 'GAME_DATE_away',\n",
      "       'MATCHUP_away', 'WL_away', 'MIN_away', 'PTS_away', 'FGM_away',\n",
      "       'FGA_away', 'FG_PCT_away', 'FG3M_away', 'FG3A_away', 'FG3_PCT_away',\n",
      "       'FTM_away', 'FTA_away', 'FT_PCT_away', 'OREB_away', 'DREB_away',\n",
      "       'REB_away', 'AST_away', 'STL_away', 'BLK_away', 'TOV_away', 'PF_away',\n",
      "       'PLUS_MINUS_away', 'HOME_away'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>date</th>\n",
       "      <th>team_home</th>\n",
       "      <th>team_away</th>\n",
       "      <th>score_home</th>\n",
       "      <th>score_away</th>\n",
       "      <th>win_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>NYK</td>\n",
       "      <td>WAS</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>MIN</td>\n",
       "      <td>PHI</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>UTA</td>\n",
       "      <td>MIL</td>\n",
       "      <td>112</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>CLE</td>\n",
       "      <td>BOS</td>\n",
       "      <td>89</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>SAS</td>\n",
       "      <td>LAC</td>\n",
       "      <td>109</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28825</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>MIN</td>\n",
       "      <td>UTA</td>\n",
       "      <td>116</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28826</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>POR</td>\n",
       "      <td>LAL</td>\n",
       "      <td>109</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28827</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>CLE</td>\n",
       "      <td>IND</td>\n",
       "      <td>118</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28828</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>PHI</td>\n",
       "      <td>CHI</td>\n",
       "      <td>102</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28829</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>HOU</td>\n",
       "      <td>DEN</td>\n",
       "      <td>111</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28830 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid       date team_home team_away  score_home  score_away  win_home\n",
       "0      22001 2001-10-30       NYK       WAS          93          91         1\n",
       "1      22001 2001-10-30       MIN       PHI          83          74         1\n",
       "2      22001 2001-10-30       UTA       MIL         112         119         0\n",
       "3      22001 2001-10-30       CLE       BOS          89         108         0\n",
       "4      22001 2001-10-30       SAS       LAC         109          98         1\n",
       "...      ...        ...       ...       ...         ...         ...       ...\n",
       "28825  22024 2025-04-13       MIN       UTA         116         105         1\n",
       "28826  22024 2025-04-13       POR       LAL         109          81         1\n",
       "28827  22024 2025-04-13       CLE       IND         118         126         0\n",
       "28828  22024 2025-04-13       PHI       CHI         102         122         0\n",
       "28829  22024 2025-04-13       HOU       DEN         111         126         0\n",
       "\n",
       "[28830 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Merging games into single rows\n",
    "\"\"\"\n",
    "\n",
    "def merge_games(df):\n",
    "    df['HOME'] = df['MATCHUP'].str.contains('vs.') \n",
    "    home_df = df[df['HOME']].copy()\n",
    "    away_df = df[~df['HOME']].copy()\n",
    "\n",
    "    merged = home_df.merge(\n",
    "        away_df,\n",
    "        on='GAME_ID',\n",
    "        suffixes=('_home', '_away')\n",
    "    )\n",
    "    print(merged.columns)\n",
    "    merged = merged[[\n",
    "        'SEASON_ID_home', 'GAME_DATE_home', 'TEAM_ABBREVIATION_home', 'TEAM_ABBREVIATION_away',\n",
    "        'PTS_home', 'PTS_away'\n",
    "    ]].rename(columns={\n",
    "        'SEASON_ID_home' : 'sid',\n",
    "        'GAME_DATE_home': 'date',\n",
    "        'TEAM_ABBREVIATION_home': 'team_home',\n",
    "        'TEAM_ABBREVIATION_away': 'team_away',\n",
    "        'PTS_home': 'score_home',\n",
    "        'PTS_away': 'score_away'\n",
    "    })\n",
    "\n",
    "    merged[\"win_home\"] = (merged[\"score_home\"] > merged[\"score_away\"]).astype(int)\n",
    "\n",
    "    merged['date'] = pd.to_datetime(merged['date'])\n",
    "    merged = merged.sort_values('date').reset_index(drop=True)\n",
    "    return merged\n",
    "\n",
    "games = merge_games(games_df)\n",
    "games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ffa8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned params: 9.389090813085769 76.18639609784859 0.5427645196624447 400.77247729219175\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "EPS = 1e-12\n",
    "\n",
    "games_sorted = games.sort_values(\"date\").reset_index(drop=False)\n",
    "cut1 = games_sorted[\"date\"].quantile(0.8)\n",
    "tr_idx = games_sorted.loc[games_sorted[\"date\"] < cut1, \"index\"].to_numpy()\n",
    "\n",
    "p_home = (games[\"win_home\"] == 1).mean()\n",
    "HCA = 400 * math.log10(p_home / (1 - p_home))\n",
    "\n",
    "def _elo_logloss_for_params(games_df, K, HCA, alpha, scale=400.0):\n",
    "    \"\"\"\n",
    "    Compute total negative log-likelihood for given Elo params on a chronologically\n",
    "    ordered DataFrame with columns: sid, date, team_home, team_away, score_home, score_away.\n",
    "    \"\"\"\n",
    "    teams = pd.unique(games_df[['team_home','team_away']].values.ravel())\n",
    "    elo = {t: 1500.0 for t in teams}\n",
    "    prev_sid = object()\n",
    "    nll = 0.0\n",
    "\n",
    "    for _, r in games_df.iterrows():\n",
    "        # season reset (shrink to mean)\n",
    "        if r['sid'] != prev_sid:\n",
    "            for t in elo:\n",
    "                elo[t] = alpha * elo[t] + (1.0 - alpha) * 1500.0\n",
    "\n",
    "        Ra, Rb = elo[r.team_home], elo[r.team_away]\n",
    "\n",
    "        # probability of home win using learned scale (400 by default)\n",
    "        # elo_diff = Ra - Rb + HCA\n",
    "        Ea = 1.0 / (1.0 + 10.0 ** (-(Ra - Rb + HCA) / scale))\n",
    "\n",
    "        y = 1.0 if r.score_home > r.score_away else 0.0\n",
    "        nll += -(y * np.log(Ea + EPS) + (1 - y) * np.log(1 - Ea + EPS))\n",
    "\n",
    "        # update ratings with margin-of-victory multiplier\n",
    "        margin = abs(r.score_home - r.score_away)\n",
    "        mult = np.log1p(margin) * 2.2 / ((Ra - Rb) * 0.001 + 2.2)\n",
    "        delta = K * mult * (y - Ea)\n",
    "\n",
    "        elo[r.team_home] = Ra + delta\n",
    "        elo[r.team_away] = Rb - delta\n",
    "        prev_sid = r['sid']\n",
    "\n",
    "    return nll\n",
    "\n",
    "def fit_elo_params(games_train, K0=20.0, HCA0=60.0, alpha0=0.55, scale0=400.0):\n",
    "    \"\"\"\n",
    "    Learn K, HCA, alpha (season reset), and scale by ML on the TRAIN window only.\n",
    "    games_train must be chronologically sorted.\n",
    "    \"\"\"\n",
    "    bounds = [(5.0, 80.0),     # K\n",
    "              (0.0, 120.0),    # HCA (Elo points)\n",
    "              (0.20, 0.95),    # alpha (keep some shrink)\n",
    "              (250.0, 550.0)]  # scale in the Elo->prob sigmoid (400 standard)\n",
    "\n",
    "    x0 = np.array([K0, HCA0, alpha0, scale0], dtype=float)\n",
    "\n",
    "    def objective(x):\n",
    "        K, HCA, alpha, scale = x\n",
    "        return _elo_logloss_for_params(games_train, K, HCA, alpha, scale)\n",
    "\n",
    "    res = minimize(objective, x0=x0, method=\"L-BFGS-B\", bounds=bounds)\n",
    "    K, HCA, alpha, scale = res.x\n",
    "    return float(K), float(HCA), float(alpha), float(scale)\n",
    "\n",
    "# build the TRAIN slice and ensure chronological order\n",
    "train_df = games.loc[tr_idx].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# a reasonable HCA starting guess from your earlier empirical calc\n",
    "K_star, HCA_star, alpha_star, scale_star = fit_elo_params(\n",
    "    train_df, K0=20.0, HCA0=HCA, alpha0=0.55, scale0=400.0\n",
    ")\n",
    "print(\"Learned params:\", K_star, HCA_star, alpha_star, scale_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5936cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>date</th>\n",
       "      <th>team_home</th>\n",
       "      <th>team_away</th>\n",
       "      <th>score_home</th>\n",
       "      <th>score_away</th>\n",
       "      <th>win_home</th>\n",
       "      <th>elo_pre_home</th>\n",
       "      <th>elo_pre_away</th>\n",
       "      <th>elo_post_home</th>\n",
       "      <th>elo_post_away</th>\n",
       "      <th>elo_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>NYK</td>\n",
       "      <td>WAS</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1506.268566</td>\n",
       "      <td>1493.731434</td>\n",
       "      <td>76.186396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>MIN</td>\n",
       "      <td>PHI</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1513.138308</td>\n",
       "      <td>1486.861692</td>\n",
       "      <td>76.186396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>UTA</td>\n",
       "      <td>MIL</td>\n",
       "      <td>112</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1492.341009</td>\n",
       "      <td>1507.658991</td>\n",
       "      <td>76.186396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>CLE</td>\n",
       "      <td>BOS</td>\n",
       "      <td>89</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1488.966130</td>\n",
       "      <td>1511.033870</td>\n",
       "      <td>76.186396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>SAS</td>\n",
       "      <td>LAC</td>\n",
       "      <td>109</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1514.178615</td>\n",
       "      <td>1485.821385</td>\n",
       "      <td>76.186396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28825</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>MIN</td>\n",
       "      <td>UTA</td>\n",
       "      <td>116</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1641.853758</td>\n",
       "      <td>1273.693534</td>\n",
       "      <td>1645.000158</td>\n",
       "      <td>1270.547134</td>\n",
       "      <td>444.346620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28826</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>POR</td>\n",
       "      <td>LAL</td>\n",
       "      <td>109</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1467.006438</td>\n",
       "      <td>1613.824468</td>\n",
       "      <td>1493.520352</td>\n",
       "      <td>1587.310554</td>\n",
       "      <td>-70.631634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28827</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>CLE</td>\n",
       "      <td>IND</td>\n",
       "      <td>118</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1704.470944</td>\n",
       "      <td>1600.218892</td>\n",
       "      <td>1693.830368</td>\n",
       "      <td>1610.859468</td>\n",
       "      <td>180.438449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28828</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>PHI</td>\n",
       "      <td>CHI</td>\n",
       "      <td>102</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1289.996284</td>\n",
       "      <td>1516.052122</td>\n",
       "      <td>1285.225130</td>\n",
       "      <td>1520.823276</td>\n",
       "      <td>-149.869442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28829</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>HOU</td>\n",
       "      <td>DEN</td>\n",
       "      <td>111</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1605.798043</td>\n",
       "      <td>1590.172824</td>\n",
       "      <td>1595.099851</td>\n",
       "      <td>1600.871016</td>\n",
       "      <td>91.811615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28830 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid       date team_home team_away  score_home  score_away  win_home  \\\n",
       "0      22001 2001-10-30       NYK       WAS          93          91         1   \n",
       "1      22001 2001-10-30       MIN       PHI          83          74         1   \n",
       "2      22001 2001-10-30       UTA       MIL         112         119         0   \n",
       "3      22001 2001-10-30       CLE       BOS          89         108         0   \n",
       "4      22001 2001-10-30       SAS       LAC         109          98         1   \n",
       "...      ...        ...       ...       ...         ...         ...       ...   \n",
       "28825  22024 2025-04-13       MIN       UTA         116         105         1   \n",
       "28826  22024 2025-04-13       POR       LAL         109          81         1   \n",
       "28827  22024 2025-04-13       CLE       IND         118         126         0   \n",
       "28828  22024 2025-04-13       PHI       CHI         102         122         0   \n",
       "28829  22024 2025-04-13       HOU       DEN         111         126         0   \n",
       "\n",
       "       elo_pre_home  elo_pre_away  elo_post_home  elo_post_away    elo_diff  \n",
       "0       1500.000000   1500.000000    1506.268566    1493.731434   76.186396  \n",
       "1       1500.000000   1500.000000    1513.138308    1486.861692   76.186396  \n",
       "2       1500.000000   1500.000000    1492.341009    1507.658991   76.186396  \n",
       "3       1500.000000   1500.000000    1488.966130    1511.033870   76.186396  \n",
       "4       1500.000000   1500.000000    1514.178615    1485.821385   76.186396  \n",
       "...             ...           ...            ...            ...         ...  \n",
       "28825   1641.853758   1273.693534    1645.000158    1270.547134  444.346620  \n",
       "28826   1467.006438   1613.824468    1493.520352    1587.310554  -70.631634  \n",
       "28827   1704.470944   1600.218892    1693.830368    1610.859468  180.438449  \n",
       "28828   1289.996284   1516.052122    1285.225130    1520.823276 -149.869442  \n",
       "28829   1605.798043   1590.172824    1595.099851    1600.871016   91.811615  \n",
       "\n",
       "[28830 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Updating Elos\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "p_home = (games[\"win_home\"] == 1).mean()\n",
    "HCA = 400 * math.log10(p_home / (1 - p_home))\n",
    "K = 20\n",
    "\n",
    "\n",
    "def update_elo(games_df, K=K, HCA=HCA, alpha=0.55, scale=400):\n",
    "    elo = {team: 1500 for team in pd.unique(games_df[['team_home', 'team_away']].values.ravel())}\n",
    "    records = []\n",
    "\n",
    "    prev_sid = object() \n",
    "    for idx, row in games_df.iterrows():\n",
    "        if row['sid'] != prev_sid:\n",
    "            for team, rating in elo.items():\n",
    "                elo[team] = alpha * rating + (1-alpha)* 1500\n",
    "\n",
    "        home, away = row['team_home'], row['team_away']\n",
    "        score_home, score_away = row['score_home'], row['score_away']\n",
    "        win_home = 1 if score_home > score_away else 0\n",
    "\n",
    "        Ra, Rb = elo[home], elo[away]\n",
    "        Ea = 1 / (1 + 10 ** ((Rb - Ra + HCA) / scale))\n",
    "        margin = abs(score_home - score_away)\n",
    "        mult = np.log1p(margin) * 2.2 / ((Ra - Rb) * 0.001 + 2.2)\n",
    "        delta = K * mult * (win_home - Ea)\n",
    "\n",
    "        elo[home] += delta\n",
    "        elo[away] -= delta\n",
    "\n",
    "        games_df.loc[idx, 'elo_pre_home'] = Ra\n",
    "        games_df.loc[idx, 'elo_pre_away'] = Rb\n",
    "        games_df.loc[idx, 'elo_post_home'] = elo[home]\n",
    "        games_df.loc[idx, 'elo_post_away'] = elo[away]\n",
    "\n",
    "        prev_sid = row['sid']\n",
    "\n",
    "    games_df['elo_diff'] = games_df['elo_pre_home'] - games_df['elo_pre_away'] + HCA\n",
    "\n",
    "    return elo\n",
    "\n",
    "elos = update_elo(games, K_star, HCA_star, alpha_star, scale_star)\n",
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c0ae6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_41710/316138917.py:108: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  logs = logs.groupby([\"team\",\"sid\"], group_keys=False).apply(_streak_from_prev)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_41710/316138917.py:132: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  logs = logs.groupby([\"team\",\"sid\"], group_keys=False).apply(_elo_roll)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>date</th>\n",
       "      <th>team_home</th>\n",
       "      <th>team_away</th>\n",
       "      <th>score_home</th>\n",
       "      <th>score_away</th>\n",
       "      <th>win_home</th>\n",
       "      <th>elo_pre_home</th>\n",
       "      <th>elo_pre_away</th>\n",
       "      <th>elo_post_home</th>\n",
       "      <th>...</th>\n",
       "      <th>elo_pre_ma5_diff</th>\n",
       "      <th>elo_pre_slope5_diff</th>\n",
       "      <th>elo_momentum_diff</th>\n",
       "      <th>elo_volatility_diff</th>\n",
       "      <th>elo_momentum_x_rest</th>\n",
       "      <th>momentum_index</th>\n",
       "      <th>elo_x_momentum</th>\n",
       "      <th>elo_x_rest</th>\n",
       "      <th>off_def_product</th>\n",
       "      <th>venue_x_streak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>NYK</td>\n",
       "      <td>WAS</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1506.268566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>MIN</td>\n",
       "      <td>PHI</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1513.138308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>UTA</td>\n",
       "      <td>MIL</td>\n",
       "      <td>112</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1492.341009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>CLE</td>\n",
       "      <td>BOS</td>\n",
       "      <td>89</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1488.966130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22001</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>SAS</td>\n",
       "      <td>LAC</td>\n",
       "      <td>109</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1514.178615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28825</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>MIN</td>\n",
       "      <td>UTA</td>\n",
       "      <td>116</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1641.853758</td>\n",
       "      <td>1273.693534</td>\n",
       "      <td>1645.000158</td>\n",
       "      <td>...</td>\n",
       "      <td>370.548466</td>\n",
       "      <td>-2.502127</td>\n",
       "      <td>0.970568</td>\n",
       "      <td>-2.301748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>337.703431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-27.442158</td>\n",
       "      <td>1.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28826</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>POR</td>\n",
       "      <td>LAL</td>\n",
       "      <td>109</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1467.006438</td>\n",
       "      <td>1613.824468</td>\n",
       "      <td>1493.520352</td>\n",
       "      <td>...</td>\n",
       "      <td>-111.510442</td>\n",
       "      <td>-12.924295</td>\n",
       "      <td>-12.670491</td>\n",
       "      <td>0.261534</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>49.442144</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.930651</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28827</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>CLE</td>\n",
       "      <td>IND</td>\n",
       "      <td>118</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1704.470944</td>\n",
       "      <td>1600.218892</td>\n",
       "      <td>1693.830368</td>\n",
       "      <td>...</td>\n",
       "      <td>100.821313</td>\n",
       "      <td>-3.037148</td>\n",
       "      <td>-3.034872</td>\n",
       "      <td>0.464517</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>75.784148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.477970</td>\n",
       "      <td>0.725641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28828</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>PHI</td>\n",
       "      <td>CHI</td>\n",
       "      <td>102</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1289.996284</td>\n",
       "      <td>1516.052122</td>\n",
       "      <td>1285.225130</td>\n",
       "      <td>...</td>\n",
       "      <td>-214.088297</td>\n",
       "      <td>-3.940207</td>\n",
       "      <td>-6.537780</td>\n",
       "      <td>-1.866836</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>107.905998</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>30.706904</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28829</th>\n",
       "      <td>22024</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>HOU</td>\n",
       "      <td>DEN</td>\n",
       "      <td>111</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1605.798043</td>\n",
       "      <td>1590.172824</td>\n",
       "      <td>1595.099851</td>\n",
       "      <td>...</td>\n",
       "      <td>41.787512</td>\n",
       "      <td>-1.290057</td>\n",
       "      <td>3.085720</td>\n",
       "      <td>7.451067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099959</td>\n",
       "      <td>9.177431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.205057</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28830 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid       date team_home team_away  score_home  score_away  win_home  \\\n",
       "0      22001 2001-10-30       NYK       WAS          93          91         1   \n",
       "1      22001 2001-10-30       MIN       PHI          83          74         1   \n",
       "2      22001 2001-10-30       UTA       MIL         112         119         0   \n",
       "3      22001 2001-10-30       CLE       BOS          89         108         0   \n",
       "4      22001 2001-10-30       SAS       LAC         109          98         1   \n",
       "...      ...        ...       ...       ...         ...         ...       ...   \n",
       "28825  22024 2025-04-13       MIN       UTA         116         105         1   \n",
       "28826  22024 2025-04-13       POR       LAL         109          81         1   \n",
       "28827  22024 2025-04-13       CLE       IND         118         126         0   \n",
       "28828  22024 2025-04-13       PHI       CHI         102         122         0   \n",
       "28829  22024 2025-04-13       HOU       DEN         111         126         0   \n",
       "\n",
       "       elo_pre_home  elo_pre_away  elo_post_home  ...  elo_pre_ma5_diff  \\\n",
       "0       1500.000000   1500.000000    1506.268566  ...          0.000000   \n",
       "1       1500.000000   1500.000000    1513.138308  ...          0.000000   \n",
       "2       1500.000000   1500.000000    1492.341009  ...          0.000000   \n",
       "3       1500.000000   1500.000000    1488.966130  ...          0.000000   \n",
       "4       1500.000000   1500.000000    1514.178615  ...          0.000000   \n",
       "...             ...           ...            ...  ...               ...   \n",
       "28825   1641.853758   1273.693534    1645.000158  ...        370.548466   \n",
       "28826   1467.006438   1613.824468    1493.520352  ...       -111.510442   \n",
       "28827   1704.470944   1600.218892    1693.830368  ...        100.821313   \n",
       "28828   1289.996284   1516.052122    1285.225130  ...       -214.088297   \n",
       "28829   1605.798043   1590.172824    1595.099851  ...         41.787512   \n",
       "\n",
       "       elo_pre_slope5_diff  elo_momentum_diff  elo_volatility_diff  \\\n",
       "0                 0.000000           0.000000             0.000000   \n",
       "1                 0.000000           0.000000             0.000000   \n",
       "2                 0.000000           0.000000             0.000000   \n",
       "3                 0.000000           0.000000             0.000000   \n",
       "4                 0.000000           0.000000             0.000000   \n",
       "...                    ...                ...                  ...   \n",
       "28825            -2.502127           0.970568            -2.301748   \n",
       "28826           -12.924295         -12.670491             0.261534   \n",
       "28827            -3.037148          -3.034872             0.464517   \n",
       "28828            -3.940207          -6.537780            -1.866836   \n",
       "28829            -1.290057           3.085720             7.451067   \n",
       "\n",
       "       elo_momentum_x_rest  momentum_index  elo_x_momentum  elo_x_rest  \\\n",
       "0                      0.0        0.000000        0.000000         0.0   \n",
       "1                      0.0        0.000000        0.000000         0.0   \n",
       "2                      0.0        0.000000        0.000000         0.0   \n",
       "3                      0.0        0.000000        0.000000         0.0   \n",
       "4                      0.0        0.000000        0.000000         0.0   \n",
       "...                    ...             ...             ...         ...   \n",
       "28825                  0.0        0.760000      337.703431         0.0   \n",
       "28826                 -0.0       -0.700000       49.442144        -0.0   \n",
       "28827                 -0.0        0.420000       75.784148         0.0   \n",
       "28828                 -0.0       -0.720000      107.905998        -0.0   \n",
       "28829                  0.0        0.099959        9.177431         0.0   \n",
       "\n",
       "       off_def_product  venue_x_streak  \n",
       "0             0.000000        0.000000  \n",
       "1             0.000000        0.000000  \n",
       "2             0.000000        0.000000  \n",
       "3             0.000000        0.000000  \n",
       "4             0.000000        0.000000  \n",
       "...                ...             ...  \n",
       "28825       -27.442158        1.275000  \n",
       "28826        -5.930651       -0.200000  \n",
       "28827       -13.477970        0.725641  \n",
       "28828        30.706904        0.600000  \n",
       "28829        45.205057       -0.600000  \n",
       "\n",
       "[28830 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "WIN_WINDOW = 10\n",
    "\n",
    "def add_features(games: pd.DataFrame, win_window: int = WIN_WINDOW, fill_rest: int = 7) -> pd.DataFrame:\n",
    "    df = games.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    if \"sid\" not in df.columns:\n",
    "        raise ValueError(\"Input must include 'sid' (season id).\")\n",
    "    df[\"sid\"] = pd.to_numeric(df[\"sid\"], errors=\"coerce\")\n",
    "\n",
    "    if \"win_home\" not in df.columns:\n",
    "        if {\"score_home\", \"score_away\"}.issubset(df.columns):\n",
    "            df[\"win_home\"] = (df[\"score_home\"] > df[\"score_away\"]).astype(int)\n",
    "        else:\n",
    "            raise ValueError(\"Need 'win_home' or both 'score_home' and 'score_away'.\")\n",
    "\n",
    "    # stable row id for same-day ties\n",
    "    df = df.reset_index(drop=False).rename(columns={\"index\": \"row_id\"})\n",
    "\n",
    "    # ---------- per-team logs (vectorized) ----------\n",
    "    home = df[[\"sid\",\"date\",\"team_home\",\"score_home\",\"score_away\",\"win_home\",\"row_id\"]].rename(\n",
    "        columns={\"team_home\":\"team\",\"score_home\":\"pf\",\"score_away\":\"pa\",\"win_home\":\"win\"}\n",
    "    )\n",
    "    home[\"is_home\"] = 1\n",
    "\n",
    "    away = df[[\"sid\",\"date\",\"team_away\",\"score_home\",\"score_away\",\"win_home\",\"row_id\"]].rename(\n",
    "        columns={\"team_away\":\"team\",\"score_home\":\"pa\",\"score_away\":\"pf\",\"win_home\":\"win\"}\n",
    "    )\n",
    "    away[\"is_home\"] = 0\n",
    "    away[\"win\"] = 1 - away[\"win\"]\n",
    "\n",
    "    logs = pd.concat([home, away], ignore_index=True)\n",
    "    logs = logs.sort_values([\"team\",\"sid\",\"date\",\"row_id\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    # per-game margin\n",
    "    logs[\"pt_diff\"] = (logs[\"pf\"] - logs[\"pa\"]).astype(float)\n",
    "\n",
    "    g = logs.groupby([\"team\",\"sid\"], sort=False)\n",
    "\n",
    "    # ---------- season-to-date BEFORE this game (index-safe; no shift) ----------\n",
    "    # 1) Overall season +/- before game\n",
    "    logs[\"spdiff\"] = (g[\"pt_diff\"].cumsum() - logs[\"pt_diff\"]).astype(float)\n",
    "\n",
    "    # 2) Off/Def efficiency before game (per-game averages)\n",
    "    gp_incl   = g.cumcount() + 1              # games including current\n",
    "    gp_prev   = gp_incl - 1                   # games before current\n",
    "    pf_cum_in = g[\"pf\"].cumsum()\n",
    "    pa_cum_in = g[\"pa\"].cumsum()\n",
    "    pf_pre    = pf_cum_in - logs[\"pf\"]        # totals before game\n",
    "    pa_pre    = pa_cum_in - logs[\"pa\"]\n",
    "    logs[\"off_eff\"] = np.where(gp_prev > 0, pf_pre / gp_prev, np.nan)\n",
    "    logs[\"def_eff\"] = np.where(gp_prev > 0, pa_pre / gp_prev, np.nan)\n",
    "\n",
    "    # 3) Venue-specific (home/away) win% and point-diff before game\n",
    "    logs[\"home_game\"]  = (logs[\"is_home\"] == 1).astype(int)\n",
    "    logs[\"away_game\"]  = (logs[\"is_home\"] == 0).astype(int)\n",
    "    logs[\"home_win\"]   = logs[\"win\"] * logs[\"home_game\"]\n",
    "    logs[\"away_win\"]   = logs[\"win\"] * logs[\"away_game\"]\n",
    "    logs[\"home_pdiff\"] = logs[\"pt_diff\"] * logs[\"home_game\"]\n",
    "    logs[\"away_pdiff\"] = logs[\"pt_diff\"] * logs[\"away_game\"]\n",
    "\n",
    "    # cumulative including current\n",
    "    h_games_in = g[\"home_game\"].cumsum()\n",
    "    a_games_in = g[\"away_game\"].cumsum()\n",
    "    h_wins_in  = g[\"home_win\"].cumsum()\n",
    "    a_wins_in  = g[\"away_win\"].cumsum()\n",
    "    h_pd_in    = g[\"home_pdiff\"].cumsum()\n",
    "    a_pd_in    = g[\"away_pdiff\"].cumsum()\n",
    "\n",
    "    # pre-game (subtract current row's contribution)\n",
    "    h_games = h_games_in - logs[\"home_game\"]\n",
    "    a_games = a_games_in - logs[\"away_game\"]\n",
    "    h_wins  = h_wins_in  - logs[\"home_win\"]\n",
    "    a_wins  = a_wins_in  - logs[\"away_win\"]\n",
    "    h_pd    = h_pd_in    - logs[\"home_pdiff\"]\n",
    "    a_pd    = a_pd_in    - logs[\"away_pdiff\"]\n",
    "\n",
    "    logs[\"home_win_pct\"]    = np.where(h_games > 0, h_wins / h_games, np.nan)\n",
    "    logs[\"away_win_pct\"]    = np.where(a_games > 0, a_wins / a_games, np.nan)\n",
    "    logs[\"home_point_diff\"] = np.where(h_games > 0, h_pd / h_games, np.nan)\n",
    "    logs[\"away_point_diff\"] = np.where(a_games > 0, a_pd / a_games, np.nan)\n",
    "\n",
    "    # ---------- rest / rw_pct / streak ----------\n",
    "    logs[\"prev_date\"] = g[\"date\"].shift(1)\n",
    "    logs[\"rest_days\"] = ((logs[\"date\"] - logs[\"prev_date\"]).dt.days - 1).clip(lower=0)\n",
    "\n",
    "    logs[\"prev_win\"] = g[\"win\"].shift(1)\n",
    "    logs[\"rw_pct\"] = (g[\"prev_win\"]\n",
    "                      .rolling(win_window, min_periods=1)\n",
    "                      .mean()\n",
    "                      .reset_index(level=[0,1], drop=True))\n",
    "\n",
    "    logs[\"prev_sign\"] = logs[\"prev_win\"].map({1: 1, 0: -1})\n",
    "    def _streak_from_prev(gr):\n",
    "        cur, out = 0, []\n",
    "        for s in gr[\"prev_sign\"]:\n",
    "            if pd.isna(s):\n",
    "                cur = 0\n",
    "            else:\n",
    "                s = int(s)\n",
    "                cur = (cur + 1 if cur > 0 else 1) if s > 0 else (cur - 1 if cur < 0 else -1)\n",
    "            out.append(cur)\n",
    "        gr = gr.copy()\n",
    "        gr[\"streak\"] = out\n",
    "        return gr\n",
    "    logs = logs.groupby([\"team\",\"sid\"], group_keys=False).apply(_streak_from_prev)\n",
    "\n",
    "    # ---------- Elo PRE rolling (leak-free) ----------\n",
    "    if {\"elo_pre_home\", \"elo_pre_away\"}.issubset(df.columns):\n",
    "        # map each per-team log row to the corresponding pre-game Elo from df\n",
    "        logs[\"elo_pre\"] = np.where(\n",
    "            logs[\"is_home\"] == 1,\n",
    "            df.loc[logs[\"row_id\"].values, \"elo_pre_home\"].values,\n",
    "            df.loc[logs[\"row_id\"].values, \"elo_pre_away\"].values\n",
    "        ).astype(float)\n",
    "\n",
    "        def _elo_roll(gr, w=5):\n",
    "            e = gr[\"elo_pre\"].astype(float)\n",
    "            gr = gr.copy()\n",
    "            gr[\"elo_pre_ma5\"]       = e.rolling(w, min_periods=3).mean()\n",
    "            # slope (linear trend) of Elo_pre within window\n",
    "            gr[\"elo_pre_slope5\"]    = e.rolling(w, min_periods=3).apply(\n",
    "                lambda x: np.polyfit(np.arange(len(x)), x, 1)[0], raw=False\n",
    "            )\n",
    "            de = e.diff()  # Δ Elo_pre between games (still pre-game to pre-game)\n",
    "            gr[\"elo_pre_diff_ma5\"]  = de.rolling(w, min_periods=3).mean()  # momentum\n",
    "            gr[\"elo_pre_diff_std5\"] = de.rolling(w, min_periods=3).std()   # volatility\n",
    "            return gr\n",
    "\n",
    "        logs = logs.groupby([\"team\",\"sid\"], group_keys=False).apply(_elo_roll)\n",
    "    else:\n",
    "        # if Elo pre columns are missing, create NaNs so downstream code still runs\n",
    "        logs[\"elo_pre_ma5\"] = np.nan\n",
    "        logs[\"elo_pre_slope5\"] = np.nan\n",
    "        logs[\"elo_pre_diff_ma5\"] = np.nan\n",
    "        logs[\"elo_pre_diff_std5\"] = np.nan\n",
    "\n",
    "    # ---------- spread back to game rows ----------\n",
    "    h = logs.rename(columns={\n",
    "        \"team\":\"team_home\",\n",
    "        \"rest_days\":\"rest_h\",\"rw_pct\":\"rw_pct_h\",\"streak\":\"streak_h\",\n",
    "        \"spdiff\":\"spdiff_h\",\n",
    "        \"off_eff\":\"off_eff_h\",\"def_eff\":\"def_eff_h\",\n",
    "        \"home_win_pct\":\"home_win_pct_h\",\n",
    "        \"home_point_diff\":\"home_point_diff_h\",\n",
    "        \"elo_pre_ma5\":\"elo_pre_ma5_h\",\n",
    "        \"elo_pre_slope5\":\"elo_pre_slope5_h\",\n",
    "        \"elo_pre_diff_ma5\":\"elo_momentum_h\",\n",
    "        \"elo_pre_diff_std5\":\"elo_volatility_h\",\n",
    "    })[[\"sid\",\"date\",\"team_home\",\n",
    "        \"rest_h\",\"rw_pct_h\",\"streak_h\",\"spdiff_h\",\n",
    "        \"off_eff_h\",\"def_eff_h\",\n",
    "        \"home_win_pct_h\",\"home_point_diff_h\",\n",
    "        \"elo_pre_ma5_h\",\"elo_pre_slope5_h\",\"elo_momentum_h\",\"elo_volatility_h\"]]\n",
    "\n",
    "    a = logs.rename(columns={\n",
    "        \"team\":\"team_away\",\n",
    "        \"rest_days\":\"rest_a\",\"rw_pct\":\"rw_pct_a\",\"streak\":\"streak_a\",\n",
    "        \"spdiff\":\"spdiff_a\",\n",
    "        \"off_eff\":\"off_eff_a\",\"def_eff\":\"def_eff_a\",\n",
    "        \"away_win_pct\":\"away_win_pct_a\",\n",
    "        \"away_point_diff\":\"away_point_diff_a\",\n",
    "        \"elo_pre_ma5\":\"elo_pre_ma5_a\",\n",
    "        \"elo_pre_slope5\":\"elo_pre_slope5_a\",\n",
    "        \"elo_pre_diff_ma5\":\"elo_momentum_a\",\n",
    "        \"elo_pre_diff_std5\":\"elo_volatility_a\",\n",
    "    })[[\"sid\",\"date\",\"team_away\",\n",
    "        \"rest_a\",\"rw_pct_a\",\"streak_a\",\"spdiff_a\",\n",
    "        \"off_eff_a\",\"def_eff_a\",\n",
    "        \"away_win_pct_a\",\"away_point_diff_a\",\n",
    "        \"elo_pre_ma5_a\",\"elo_pre_slope5_a\",\"elo_momentum_a\",\"elo_volatility_a\"]]\n",
    "\n",
    "    out = (df.drop(columns=\"row_id\")\n",
    "             .merge(h, on=[\"sid\",\"date\",\"team_home\"], how=\"left\")\n",
    "             .merge(a, on=[\"sid\",\"date\",\"team_away\"], how=\"left\"))\n",
    "\n",
    "    # fills\n",
    "    out[\"rest_h\"]   = out[\"rest_h\"].fillna(fill_rest)\n",
    "    out[\"rest_a\"]   = out[\"rest_a\"].fillna(fill_rest)\n",
    "    out[\"rw_pct_h\"] = out[\"rw_pct_h\"].fillna(0.5)\n",
    "    out[\"rw_pct_a\"] = out[\"rw_pct_a\"].fillna(0.5)\n",
    "    out[\"streak_h\"] = out[\"streak_h\"].fillna(0).astype(int)\n",
    "    out[\"streak_a\"] = out[\"streak_a\"].fillna(0).astype(int)\n",
    "\n",
    "    out[\"home_win_pct_h\"]    = out[\"home_win_pct_h\"].fillna(0.5)\n",
    "    out[\"away_win_pct_a\"]    = out[\"away_win_pct_a\"].fillna(0.5)\n",
    "    out[\"home_point_diff_h\"] = out[\"home_point_diff_h\"].fillna(0.0)\n",
    "    out[\"away_point_diff_a\"] = out[\"away_point_diff_a\"].fillna(0.0)\n",
    "\n",
    "    out[\"off_eff_h\"] = out[\"off_eff_h\"].fillna(0.0)\n",
    "    out[\"off_eff_a\"] = out[\"off_eff_a\"].fillna(0.0)\n",
    "    out[\"def_eff_h\"] = out[\"def_eff_h\"].fillna(0.0)\n",
    "    out[\"def_eff_a\"] = out[\"def_eff_a\"].fillna(0.0)\n",
    "\n",
    "    # Elo rolling fills (sensible defaults)\n",
    "    if \"elo_pre_home\" in out.columns:\n",
    "        out[\"elo_pre_ma5_h\"] = out[\"elo_pre_ma5_h\"].fillna(out[\"elo_pre_home\"])\n",
    "    else:\n",
    "        out[\"elo_pre_ma5_h\"] = out[\"elo_pre_ma5_h\"].fillna(0.0)\n",
    "    if \"elo_pre_away\" in out.columns:\n",
    "        out[\"elo_pre_ma5_a\"] = out[\"elo_pre_ma5_a\"].fillna(out[\"elo_pre_away\"])\n",
    "    else:\n",
    "        out[\"elo_pre_ma5_a\"] = out[\"elo_pre_ma5_a\"].fillna(0.0)\n",
    "\n",
    "    for c in [\"elo_pre_slope5_h\",\"elo_momentum_h\",\"elo_volatility_h\",\n",
    "              \"elo_pre_slope5_a\",\"elo_momentum_a\",\"elo_volatility_a\"]:\n",
    "        out[c] = out[c].fillna(0.0)\n",
    "\n",
    "    # diffs\n",
    "    out[\"rest_diff\"]          = out[\"rest_h\"] - out[\"rest_a\"]\n",
    "    out[\"rw_pct_diff\"]        = out[\"rw_pct_h\"] - out[\"rw_pct_a\"]\n",
    "    out[\"streak_diff\"]        = out[\"streak_h\"] - out[\"streak_a\"]\n",
    "    out[\"spdiff_diff\"]        = out[\"spdiff_h\"] - out[\"spdiff_a\"]\n",
    "    out[\"off_eff_diff\"]       = out[\"off_eff_h\"] - out[\"off_eff_a\"]\n",
    "    out[\"def_eff_diff\"]       = out[\"def_eff_h\"] - out[\"def_eff_a\"]\n",
    "    out[\"net_off_diff\"]       = out[\"off_eff_h\"] - out[\"def_eff_a\"]\n",
    "    out[\"net_def_diff\"]       = out[\"def_eff_h\"] - out[\"off_eff_a\"]\n",
    "    out[\"hvenue_winpct_diff\"] = out[\"home_win_pct_h\"] - out[\"away_win_pct_a\"]\n",
    "    out[\"hvenue_pdiff_diff\"]  = out[\"home_point_diff_h\"] - out[\"away_point_diff_a\"]\n",
    "    out[\"b2b_home\"] = (out[\"rest_h\"] == 0).astype(int)\n",
    "    out[\"b2b_away\"] = (out[\"rest_a\"] == 0).astype(int)\n",
    "\n",
    "    # Elo-based diffs & interaction\n",
    "    out[\"elo_pre_ma5_diff\"]    = out[\"elo_pre_ma5_h\"]    - out[\"elo_pre_ma5_a\"]\n",
    "    out[\"elo_pre_slope5_diff\"] = out[\"elo_pre_slope5_h\"] - out[\"elo_pre_slope5_a\"]\n",
    "    out[\"elo_momentum_diff\"]   = out[\"elo_momentum_h\"]   - out[\"elo_momentum_a\"]\n",
    "    out[\"elo_volatility_diff\"] = out[\"elo_volatility_h\"] - out[\"elo_volatility_a\"]\n",
    "    out[\"elo_momentum_x_rest\"] = out[\"elo_momentum_diff\"] * out[\"rest_diff\"]\n",
    "\n",
    "    out[\"momentum_index\"] = (\n",
    "        0.4 * out[\"rw_pct_diff\"] +\n",
    "        0.3 * out[\"streak_diff\"]/5 +\n",
    "        0.3 * np.tanh(out[\"spdiff_diff\"]/20)\n",
    "    )\n",
    "\n",
    "    out['elo_x_momentum'] = out['elo_diff'] * out['momentum_index']\n",
    "    out['elo_x_rest'] = out['elo_diff'] * out['rest_diff']\n",
    "    out['off_def_product'] = out['off_eff_diff'] * out['def_eff_diff']\n",
    "    out['venue_x_streak'] = out['hvenue_winpct_diff'] * out['streak_diff']\n",
    "\n",
    "\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "games_d = add_features(games)\n",
    "games_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96853f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = [\"elo_diff\",\"rest_diff\",\"rw_pct_diff\",\"streak_diff\", \"spdiff_diff\",\n",
    "         'off_eff_diff', 'def_eff_diff', 'net_off_diff', 'net_def_diff',\n",
    "         'hvenue_winpct_diff', \"hvenue_pdiff_diff\", \"momentum_index\", \"b2b_home\",\n",
    "         'b2b_away', 'elo_pre_ma5_diff', 'elo_pre_slope5_diff', 'elo_momentum_diff',\n",
    "         'elo_volatility_diff', 'elo_momentum_x_rest', 'elo_x_momentum', 'elo_x_rest',\n",
    "         'off_def_product', 'venue_x_streak']\n",
    "\n",
    "RAW_FOR_META = [\n",
    "    \"elo_diff\",\n",
    "    \"rest_diff\"\n",
    "]\n",
    "\n",
    "monos = \"(\" + \",\".join([\"1\"] + [\"0\"]*(len(FEATS)-1)) + \")\"\n",
    "\n",
    "def time_splits(df, date_col=\"date\", splits=(0.6, 0.2, 0.2)):\n",
    "    assert abs(sum(splits) - 1.0) < 1e-9\n",
    "    d = df.sort_values(date_col).reset_index(drop=True)\n",
    "    cut1 = d[date_col].quantile(splits[0])\n",
    "    cut2 = d[date_col].quantile(splits[0] + splits[1])\n",
    "    idx_tr = np.flatnonzero(d[date_col] <  cut1)\n",
    "    idx_va = np.flatnonzero((d[date_col] >= cut1) & (d[date_col] < cut2))\n",
    "    idx_te = np.flatnonzero(d[date_col] >= cut2)\n",
    "    return idx_tr, idx_va, idx_te\n",
    "\n",
    "idx_tr, idx_va, idx_te = time_splits(games_d, \"date\", (0.6, 0.2, 0.2))\n",
    "\n",
    "X = games_d.loc[:, FEATS]\n",
    "y = games_d[\"win_home\"].astype(int)\n",
    "\n",
    "X_tr, y_tr = X.iloc[idx_tr], y.iloc[idx_tr]\n",
    "X_va, y_va = X.iloc[idx_va], y.iloc[idx_va]\n",
    "X_te, y_te = X.iloc[idx_te], y.iloc[idx_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ce2d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb tuned\n",
      "cat tuned\n",
      "lr tuned\n",
      "mlp tuned\n",
      "Val LogLoss: 0.6178685390260285 | Val Brier: 0.21460783758121438 | Val AUC: 0.7030092112923438 | Val Accuracy: 0.6548073585560569\n",
      "xgb         LogLoss=0.6189  AUC=0.702\n",
      "cat         LogLoss=0.6191  AUC=0.701\n",
      "mlp         LogLoss=0.6219  AUC=0.700\n",
      "logistic    LogLoss=0.6175  AUC=0.703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "# ------- 0) CV splitter -------\n",
    "tss_outer = TimeSeriesSplit(n_splits=6) \n",
    "tss_inner = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "\n",
    "# ------- 1) Base learners as pipelines (so LR/MLP get scaling) -------\n",
    "pipe_xgb = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    monotone_constraints=monos,\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.03,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe_cat = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3.0,\n",
    "    eval_metric='Logloss',\n",
    "    loss_function='Logloss',\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "pipe_lr  = make_pipeline(\n",
    "    StandardScaler(with_mean=True, with_std=True),\n",
    "    LogisticRegression(max_iter=1000, solver=\"lbfgs\", penalty=\"l2\", C=1.0, random_state=42)\n",
    ")\n",
    "\n",
    "pipe_mlp = make_pipeline(\n",
    "    StandardScaler(with_mean=True, with_std=True),\n",
    "    MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        activation=\"relu\",\n",
    "        alpha=1e-4,\n",
    "        learning_rate_init=1e-3,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=10,\n",
    "        max_iter=400,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# ------- 2) Tune each base model (neg_log_loss/Brier) -------\n",
    "# XGB search space\n",
    "xgb_dist = {\n",
    "    \"max_depth\":        [2,3,4,5,6],\n",
    "    \"min_child_weight\": [1,2,3,5],\n",
    "    \"subsample\":        [0.6,0.7,0.8,0.9,1.0],\n",
    "    \"colsample_bytree\": [0.6,0.7,0.8,0.9,1.0],\n",
    "    \"reg_lambda\":       [0.0, 0.5, 1.0, 2.0, 5.0],\n",
    "    \"gamma\":            [0.0, 0.1, 0.2],\n",
    "    \"learning_rate\":    [0.01, 0.02, 0.03, 0.04, 0.05],\n",
    "    \"n_estimators\":     [200, 300, 400, 500, 700]\n",
    "}\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=pipe_xgb,\n",
    "    param_distributions=xgb_dist,\n",
    "    n_iter=40, scoring=\"neg_log_loss\", cv=tss_outer, n_jobs=-1, refit=True, random_state=42\n",
    ").fit(X_tr, y_tr)\n",
    "xgb_best = xgb_search.best_estimator_\n",
    "print('xgb tuned')\n",
    "\n",
    "# Cat search sapce\n",
    "cat_dist = {\n",
    "    \"depth\": [4,5,6,7],\n",
    "    \"l2_leaf_reg\": [1,3,5,7],\n",
    "    \"learning_rate\": [0.02,0.03,0.05],\n",
    "    \"iterations\": [300,500,700],\n",
    "    \"subsample\": [0.7,0.8,1.0]\n",
    "}\n",
    "cat_search = RandomizedSearchCV(\n",
    "    estimator=pipe_cat,\n",
    "    param_distributions=cat_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"neg_log_loss\",\n",
    "    cv=tss_outer,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    random_state=42\n",
    ").fit(X_tr, y_tr)\n",
    "cat_best = cat_search.best_estimator_\n",
    "print('cat tuned')\n",
    "\n",
    "# LR search space\n",
    "lr_dist = {\n",
    "    \"logisticregression__C\":      np.logspace(-5, 5, 100),\n",
    "    \"logisticregression__penalty\":[\"l2\"],\n",
    "    \"logisticregression__fit_intercept\":[True, False]\n",
    "}\n",
    "lr_search = RandomizedSearchCV(\n",
    "    estimator=pipe_lr, param_distributions=lr_dist,\n",
    "    n_iter=30, scoring=\"neg_log_loss\", cv=tss_outer, n_jobs=-1, refit=True, random_state=42\n",
    ").fit(X_tr, y_tr)\n",
    "lr_best = lr_search.best_estimator_\n",
    "print('lr tuned')\n",
    "\n",
    "\n",
    "# MLP search space (keep small to avoid overfit/compute blowup)\n",
    "mlp_dist = {\n",
    "    \"mlpclassifier__hidden_layer_sizes\":[(64,32), (128,64), (128,64,32)],\n",
    "    \"mlpclassifier__alpha\":[1e-5, 1e-4, 1e-3],\n",
    "    \"mlpclassifier__learning_rate_init\":[5e-4, 1e-3, 2e-3],\n",
    "    \"mlpclassifier__batch_size\":[64, 128, 256]\n",
    "}\n",
    "mlp_search = RandomizedSearchCV(\n",
    "    estimator=pipe_mlp, param_distributions=mlp_dist,\n",
    "    n_iter=25, scoring=\"neg_log_loss\", cv=tss_outer, n_jobs=-1, refit=True, random_state=42\n",
    ").fit(X_tr, y_tr)\n",
    "mlp_best = mlp_search.best_estimator_\n",
    "print('mlp tuned')\n",
    "\n",
    "\n",
    "# ------- 3) Build the stack with tuned bases -------\n",
    "base_models = [\n",
    "    (\"xgb\",     xgb_best),\n",
    "    (\"cat\",      cat_best),\n",
    "    (\"mlp\",     mlp_best),\n",
    "    (\"logistic\",lr_best)\n",
    "]\n",
    "\n",
    "raw_idx = [FEATS.index(n) for n in RAW_FOR_META if n in FEATS]\n",
    "\n",
    "def make_meta_slicer(n_bases: int, raw_idx: list):\n",
    "    def _slice(Z):\n",
    "        # Z shape = (n_samples, 2*n_bases + n_features), because predict_proba gives 2 cols per base\n",
    "        mcols = 2 * n_bases\n",
    "        probs = Z[:, :mcols]\n",
    "        feats = Z[:, mcols:]\n",
    "        return np.hstack([probs, feats[:, raw_idx]])\n",
    "    return FunctionTransformer(_slice, validate=False)\n",
    "\n",
    "meta = make_pipeline(\n",
    "    make_meta_slicer(n_bases=4, raw_idx=raw_idx),\n",
    "    StandardScaler(with_mean=True, with_std=True),\n",
    "    LogisticRegression(\n",
    "        solver=\"saga\",            # robust, supports elastic-net\n",
    "        penalty=\"elasticnet\",\n",
    "        l1_ratio=0.15,            # small L1 to prevent separation\n",
    "        C=0.1,                   # **stronger regularization** (try 0.02–0.2)\n",
    "        max_iter=5000,\n",
    "        tol=1e-3,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta,\n",
    "    stack_method=\"predict_proba\",   \n",
    "    passthrough=True,              # try True as an alternative search point\n",
    "    cv=tss_inner,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# ------- 4) Tune only a few stack/meta knobs -------\n",
    "stack_dist = {\n",
    "    \"final_estimator__logisticregression__C\": np.logspace(-2, 2, 15),\n",
    "    \"final_estimator__logisticregression__l1_ratio\": [0.05, 0.15, 0.3],\n",
    "    # you can also try L2 only by fixing l1_ratio=0 and penalty='l2' if you want\n",
    "}\n",
    "stack_search = RandomizedSearchCV(\n",
    "    estimator=stack,\n",
    "    param_distributions=stack_dist,\n",
    "    n_iter=20, scoring=\"neg_log_loss\", cv=tss_outer, n_jobs=-1, refit=True, random_state=42\n",
    ").fit(X_tr, y_tr)\n",
    "\n",
    "stack_best = stack_search.best_estimator_\n",
    "\n",
    "\n",
    "# ------- 5) Evaluate on held-out validation -------\n",
    "p_va = stack_best.predict_proba(X_va)[:,1]\n",
    "p_te = stack_best.predict_proba(X_te)[:,1]\n",
    "yhat = (p_va >= 0.5).astype(int)\n",
    "print(\n",
    "    \"Val LogLoss:\", log_loss(y_va, p_va),\n",
    "    \"| Val Brier:\", brier_score_loss(y_va, p_va),\n",
    "    \"| Val AUC:\", roc_auc_score(y_va, p_va),\n",
    "    \"| Val Accuracy:\", accuracy_score(y_va, yhat)\n",
    ")\n",
    "\n",
    "model = stack_best\n",
    "\n",
    "for name, model in base_models:\n",
    "    p = model.predict_proba(X_va)[:,1]\n",
    "    print(f\"{name:10s}  LogLoss={log_loss(y_va,p):.4f}  AUC={roc_auc_score(y_va,p):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95d6f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Safe, single-cell calibration utilities (no custom classes) ===\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import brier_score_loss, log_loss\n",
    "from scipy.optimize import minimize\n",
    "import joblib as jl\n",
    "\n",
    "EPS = 1e-6\n",
    "def _clip(p):  return np.clip(np.asarray(p, float), EPS, 1 - EPS)\n",
    "def _logit(p): p = _clip(p); return np.log(p/(1-p))\n",
    "\n",
    "def beta_fit_regularized(p, y, lam=1e-3):\n",
    "    \"\"\"Return theta as a plain dict {'A','B','C','lam'} (pickle-safe).\"\"\"\n",
    "    p = _clip(p); y = np.asarray(y, float); lg = _logit(p)\n",
    "    def obj(theta):\n",
    "        A,B,C = theta\n",
    "        z = A*lg + B*np.log(1-p) + C\n",
    "        q = 1/(1+np.exp(-z))\n",
    "        return np.mean((q - y)**2) + lam*(A*A + B*B + C*C)\n",
    "    A,B,C = minimize(obj, x0=[1.0,0.0,0.0], method=\"L-BFGS-B\").x\n",
    "    return [float(A),float(B), float(C)]\n",
    "\n",
    "def beta_apply(p, theta):\n",
    "    \"\"\"theta is the dict returned by beta_fit_regularized.\"\"\"\n",
    "    p = _clip(p)\n",
    "    z = theta[0]*_logit(p) + theta[1]*np.log(1-p) + theta[2]\n",
    "    return _clip(1/(1+np.exp(-z)))\n",
    "\n",
    "def oof_predict_proba(estimator, X, y, splitter, return_mask=False):\n",
    "    X = np.asarray(X); y = np.asarray(y)\n",
    "    oof  = np.full(len(y), np.nan, float)\n",
    "    mask = np.zeros(len(y), bool)\n",
    "    for tr, va in splitter.split(X):\n",
    "        m = clone(estimator).fit(X[tr], y[tr])\n",
    "        oof[va]  = m.predict_proba(X[va])[:, 1]\n",
    "        mask[va] = True\n",
    "    return (oof, mask) if return_mask else oof\n",
    "\n",
    "def train_calibrated_model(\n",
    "    estimator,\n",
    "    X, y,\n",
    "    splitter=None,          \n",
    "    reg_lambda=1e-3,\n",
    "    bundle_path=None       \n",
    "):\n",
    "    X = np.asarray(X); y = np.asarray(y)\n",
    "    if splitter is None:\n",
    "        splitter = TimeSeriesSplit(n_splits=6)\n",
    "\n",
    "    # OOF probs for calibration (time-aware)\n",
    "    p_oof, mask = oof_predict_proba(estimator, X, y, splitter, return_mask=True)\n",
    "    p_fit, y_fit = p_oof[mask], y[mask]\n",
    "\n",
    "    # Fit regularized Beta on OOF\n",
    "    theta = beta_fit_regularized(p_fit, y_fit, lam=reg_lambda)\n",
    "\n",
    "    # Refit estimator on ALL data for production\n",
    "    final_model = clone(estimator).fit(X, y)\n",
    "\n",
    "    # Diagnostics\n",
    "    diag = {\n",
    "        \"oof_cov\": int(mask.sum()),\n",
    "        \"n\": int(len(y)),\n",
    "        \"oof_brier_uncal\": float(brier_score_loss(y_fit, p_fit)),\n",
    "        \"oof_brier_cal\":   float(brier_score_loss(y_fit, beta_apply(p_fit, theta))),\n",
    "        \"oof_logloss_uncal\": float(log_loss(y_fit, p_fit)),\n",
    "        \"oof_logloss_cal\":   float(log_loss(y_fit, beta_apply(p_fit, theta))),\n",
    "    }\n",
    "\n",
    "    if bundle_path:\n",
    "        jl.dump(\n",
    "            {\"model\": final_model,\n",
    "             \"theta\": theta\n",
    "             },\n",
    "            bundle_path\n",
    "        )\n",
    "\n",
    "    return final_model, theta, diag\n",
    "\n",
    "def load_bundle(path):\n",
    "    obj = jl.load(path)  # only primitives + sklearn estimators → safe\n",
    "    return obj[\"model\"], obj[\"calibration\"][\"theta\"]\n",
    "\n",
    "def predict_calibrated(model, theta, X_new):\n",
    "    p_raw = model.predict_proba(np.asarray(X_new))[:, 1]\n",
    "    return beta_apply(p_raw, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90e098d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Uncal logloss: 0.6243844419938923 | Brier: 0.21735010638422742\n",
      "TEST Calib logloss: 0.6235022153655828 | Brier: 0.21700263725675195\n",
      "TEST AUC (uncal|cal): 0.7033911362728208 0.7033911362728208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesvournakis/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2742: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "trval_idx = np.r_[idx_tr, idx_va]\n",
    "order_trval = np.argsort(games_d.loc[trval_idx, \"date\"].to_numpy())\n",
    "\n",
    "X_trval = X.iloc[trval_idx].iloc[order_trval].to_numpy()\n",
    "y_trval = y.iloc[trval_idx].iloc[order_trval].to_numpy()\n",
    "                                 \n",
    "final_model, theta, diag = train_calibrated_model(model, X_trval, y_trval,\n",
    "     splitter=TimeSeriesSplit(n_splits=6, test_size=max(200, int(0.15*len(X_trval))), gap=0),\n",
    "     reg_lambda=1e-3)\n",
    "\n",
    "p_te = final_model.predict_proba(X_te)[:,1]\n",
    "p_cal_te = beta_apply(p_te, theta)\n",
    "print(\"TEST Uncal logloss:\", log_loss(y_te, p_te), \"| Brier:\", brier_score_loss(y_te, p_te))\n",
    "print(\"TEST Calib logloss:\", log_loss(y_te, p_cal_te),   \"| Brier:\", brier_score_loss(y_te, p_cal_te))\n",
    "print(\"TEST AUC (uncal|cal):\", roc_auc_score(y_te, p_te), roc_auc_score(y_te, p_cal_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4547dead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE: 0.024319183929561214\n"
     ]
    }
   ],
   "source": [
    "def expected_calibration_error(y_true, y_prob, n_bins=10):\n",
    "    bins = np.linspace(0, 1, n_bins+1)\n",
    "    binids = np.digitize(y_prob, bins) - 1\n",
    "    ece = 0\n",
    "    for i in range(n_bins):\n",
    "        mask = binids == i\n",
    "        if np.any(mask):\n",
    "            acc = y_true[mask].mean()\n",
    "            conf = y_prob[mask].mean()\n",
    "            ece += abs(acc - conf) * mask.mean()\n",
    "    return ece\n",
    "\n",
    "ece = expected_calibration_error(y_te, p_cal_te)\n",
    "print(\"ECE:\", ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3c84fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'log_loss': 0.6242269211932858, 'brier': 0.2172368023125577, 'roc_auc': 0.7031833890624433, 'accuracy@0.5': 0.6503811503811504, 'TP': 2498, 'FP': 1325, 'TN': 1256, 'FN': 693, 'calibration_mae(10-bins)': 0.02785439398385044}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_mean</th>\n",
       "      <th>y_rate</th>\n",
       "      <th>n</th>\n",
       "      <th>abs_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271758</td>\n",
       "      <td>0.243945</td>\n",
       "      <td>578</td>\n",
       "      <td>0.027813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.377878</td>\n",
       "      <td>0.358752</td>\n",
       "      <td>577</td>\n",
       "      <td>0.019126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.447660</td>\n",
       "      <td>0.414211</td>\n",
       "      <td>577</td>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506388</td>\n",
       "      <td>0.481802</td>\n",
       "      <td>577</td>\n",
       "      <td>0.024585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.559079</td>\n",
       "      <td>0.544194</td>\n",
       "      <td>577</td>\n",
       "      <td>0.014885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.608755</td>\n",
       "      <td>0.578856</td>\n",
       "      <td>577</td>\n",
       "      <td>0.029899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.661381</td>\n",
       "      <td>0.642981</td>\n",
       "      <td>577</td>\n",
       "      <td>0.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.718994</td>\n",
       "      <td>0.663778</td>\n",
       "      <td>577</td>\n",
       "      <td>0.055216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.782390</td>\n",
       "      <td>0.776430</td>\n",
       "      <td>577</td>\n",
       "      <td>0.005960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.872705</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>578</td>\n",
       "      <td>0.049175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p_mean    y_rate    n   abs_err\n",
       "0  0.271758  0.243945  578  0.027813\n",
       "1  0.377878  0.358752  577  0.019126\n",
       "2  0.447660  0.414211  577  0.033448\n",
       "3  0.506388  0.481802  577  0.024585\n",
       "4  0.559079  0.544194  577  0.014885\n",
       "5  0.608755  0.578856  577  0.029899\n",
       "6  0.661381  0.642981  577  0.018400\n",
       "7  0.718994  0.663778  577  0.055216\n",
       "8  0.782390  0.776430  577  0.005960\n",
       "9  0.872705  0.823529  578  0.049175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Final Model Evaluation\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    log_loss, brier_score_loss, roc_auc_score, accuracy_score, confusion_matrix\n",
    ")\n",
    "\n",
    "def evaluate_model_on_test(model, X_te, y_te, threshold=0.5, n_bins=10):\n",
    "\n",
    "    p = model.predict_proba(X_te)[:, 1]\n",
    "    p = beta_apply(p, theta)\n",
    "\n",
    "    yhat = (p >= threshold).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"log_loss\": float(log_loss(y_te, p)),\n",
    "        \"brier\": float(brier_score_loss(y_te, p)),\n",
    "        \"roc_auc\": float(roc_auc_score(y_te, p)),\n",
    "        f\"accuracy@{threshold}\": float(accuracy_score(y_te, yhat)),\n",
    "    }\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, yhat).ravel()\n",
    "    metrics.update({\"TP\": int(tp), \"FP\": int(fp), \"TN\": int(tn), \"FN\": int(fn)})\n",
    "\n",
    "    bins = pd.qcut(p, q=n_bins, duplicates=\"drop\")\n",
    "    cal_table = (\n",
    "        pd.DataFrame({\"p\": p, \"y\": y_te, \"bin\": bins})\n",
    "          .groupby(\"bin\", observed=True)\n",
    "          .agg(p_mean=(\"p\", \"mean\"), y_rate=(\"y\", \"mean\"), n=(\"y\", \"size\"))\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "    cal_table[\"abs_err\"] = (cal_table[\"p_mean\"] - cal_table[\"y_rate\"]).abs()\n",
    "    metrics[f\"calibration_mae({n_bins}-bins)\"] = float(\n",
    "        np.average(cal_table[\"abs_err\"], weights=cal_table[\"n\"])\n",
    "    )\n",
    "\n",
    "    return metrics, cal_table\n",
    "\n",
    "metrics, cal_table = evaluate_model_on_test(model, X_te, y_te, threshold=0.5, n_bins=10)\n",
    "print(metrics)\n",
    "cal_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "271d0e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Reliability Diagram')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWbJJREFUeJzt3Qd4k9UCBuCvTTe0hUIXZRTKLAUqo1iGyEa5LAURWYKAIKKCi6EgKqBeQLyCoLIUVKYgCBaRpcwKZY+yKaOTQiddSe5zzk9H2nSnK/ne54nN/+ck+XtaydczzbRarRZEREREZcS8rN6YiIiISGAYISIiojLFMEJERERlimGEiIiIyhTDCBEREZUphhEiIiIqUwwjREREVKYYRoiIiKhMMYwQERFRmWIYISrn9u/fDzMzM/k13csvvwxPT88ivZ54rddffz3fcqtXr5Zlb968mXHu6aeflrd04jFRRpQtj8S1ffTRR2V9GUSUD4YRIgNK/wBPv1lYWMDDw0OGh7t375pEXe/cubNEAoAIX+n1am5ujipVqqBZs2YYN24cjh07ZvD3I6LSY1GK70VkMj7++GPUrVsXSUlJOHr0qAwpBw8exLlz52BjY1Ps1//++++h0WhQkoYPH44XX3wR1tbWuZapU6cOHj16BEtLS50wsmTJkhIJJL6+vnj77bfl/bi4OFy8eBEbN26U9TF58mQsXLhQp7y4NhEIiah84/+lRCXgmWeeQevWreX9MWPGoHr16vj888+xbds2vPDCC8V+/awf/iVFpVLJW15EK4UhwlVBiVamYcOG6ZwT9frSSy/hyy+/RIMGDTBhwoSMx0rz2tKJvUdFCLW1tS319yaqqNhNQ1QKOnbsKL9eu3ZN5/ylS5cwcOBAODk5yQ9OEWBEYMmPvjEj8+fPR7t27VCtWjX5QdiqVSts2rQp19f46aef0KhRI/m+ouzff/+d75iR7LKPGRHXJVpFhKzdVeIDWlxvv379cryG+OB2dHTEq6++iqIQ3+uaNWtkHc6ZM0e+V25jRm7duoXXXntNft/ieaKuBg0apPd7PHPmDDp16iTL1axZE59++ilWrVqVo07E9/Wf//wHu3btkj8/Uf7bb7+Vj4nyXbp0gYuLi2xh8vb2xtKlS3O8V/priHFB6a8huqDSxwn9+uuv8jj9Z3Xy5Mki1RVRecWWEaJSkP7hVbVq1Yxz58+fR/v27eVf+1OnTkWlSpWwYcMG9O/fH5s3b8aAAQMK9R5fffUV+vbti6FDhyIlJQXr1q2TH7S///47evfurVP2wIEDWL9+Pd544w35IfnNN9+gV69eCAwMhI+PT5G/TxEo7t27h927d8uAkE58gIsWjS+++ALR0dEyOKTbvn07YmNjc7R4FEblypVlfa1YsQIXLlxA06ZN9Zb7999/cfjwYdn9JAKG+LmIcCAG5Yrn2dnZyXJifE/nzp3ldU+bNk3+bJYvX55rl1VwcDCGDBkiv/+xY8fKsCOI1xbXIn4uortIfK8iDIkutokTJ+q8xtWrV2ULj3gNURciXPbp0wfLli3D9OnT5fOEefPmydY18Z5i7AyRUdASkcGsWrVK/Fmu/euvv7SRkZHa27dvazdt2qR1dnbWWltby+N0Xbt21TZr1kyblJSUcU6j0WjbtWunbdCgQca5ffv2ydcUX9ONHDlSW6dOHZ33TkxM1DlOSUnR+vj4aLt06aJzXryWuB0/fjzj3K1bt7Q2NjbaAQMG5Phebty4kXGuU6dO8pZOPCbKiLLpJk6cKM9lFxwcLM8vXbpU53zfvn21np6e8nvPi/h+e/funevjX375pXz93377Ted7nTVrVq51JBw5ckSW+/HHHzPOTZo0SWtmZqY9efJkxrn79+9rnZycctSJuC5xLiAgIMdr63u/nj17auvVq5fjexOvcfjw4Yxzu3btkudsbW3lzyfdt99+m+P3gaiiY6wmKgHdunWDs7MzatWqJbthxF/WovtF/DUuiNaBvXv3yr9wxUDMqKgoebt//z569uyJK1euFHr2TdYxCg8ePEBMTIzsHgoKCspR1t/fXzb3p6tdu7bsQhFdDWq1GiWhYcOGaNu2reweSifq4Y8//pCtOaIVojhE64gg6rMgdZSamirru379+nJmTtZ6CggIkHUkBsymE6054jr1EYOVxc8tr/cTPw/xMxZdP9evX5fHWYkuHPGe6URdCaKbR/x8sp8Xr0FkLNhNQ1QCxLgJ8eErPnBWrlwpx2NkbeIXTfLiD/cPP/xQ3vSJiIiQXTgFJbpjxLiGU6dOITk5OeO8vg95MdAzO3G9iYmJiIyMhJubG0rCiBEj5BonYuyGmIkjZsKIUCBm7hRXfHy8/Gpvb59rGTG7RnRziLEcIuxlHV+SNRyI68saDNKJ4JJbGNHn0KFDmDVrFo4cOSLrNivxfmKsTLqsgUNIf0wEWn3nReAkMhYMI0QlwM/PL2M2jRgD0qFDBzkeQPTzi7/g06flvvPOO3r/os7rg0+ff/75R45LeOqpp+T4D3d3dznjRnzo/vzzzygvxFgNMQVXtI6IcRBr166V9ZQ+xqI4xLTp/Opt0qRJsk7eeustGTbEB7sIa+K6ijNVWt/MGTFYuWvXrmjcuLGccixChZWVlZz6LGb+ZH+/3GYu5XY+a5AiqugYRohKmPgwEX+NiwGRixcvloNV69WrJx8TgUF06RSXGPAqZlqIbpasLTDig1cf0Q2U3eXLl+UATtG9VBx5dbeIrg4xmFaEEdHlIVoOFi1aBEO0imzZskV+4Ddp0iTXcmJ20ciRI7FgwQKd2TwPHz7UKSdabUTrVXb6zuVGDFYVLVSiey5rq8e+ffsK/BpEpoJjRohKgZitIVpLxAev+PATUz3FOTEFNDQ0NEd50VVS2MAjQkDW8R5ipsjWrVv1lhfdBlnHSNy+fRu//fYbevToke/aIvkR42OE7B/w6USXjJi58u6778r3Eq0SxSG6XsRrivEnM2bMyDMMiffL3qLw9ddf5xgnI1qrRB2JLq904vWzjnfJT3o9Zu8Kyi0gEpkytowQlRLx4Sum2oo1OcaPHy/HlYjuG7F+hJgOKlpLwsPD5YfgnTt3cPr06QK/tmhtEF0BYnqu6A4S403E64suC7FeRnZi+q74wM06tVeYPXt2sb/P9IGx4rXFe2QPHOJaxfoeYryIWBxOBLOCEuM8RNdOemuICDXidcLCwuTKrPmtVSLW8hBTjkX3jBgwKur6r7/+kteT1XvvvSffp3v37rJrJ31qr2jhEKGkIINtRbAT3TJieq64LnG9YqVY8f3qC6BEpoxhhKiUPPfcc/Dy8pLrR4jwIT4Mjx8/LgOACChiZof4oHriiScwc+bMQr22mHEh1tj47LPP5HgIMaBSrEwqWkf0hRExo0OMmRDvHRISIq9FXEPz5s0N8n2KD3Cxzon4QBctA1nDiPiAHjx4sAxAhR24KloqxHNEGBADVUW3jPiwF6vcipangqzFIsKRaOEQLVRinRcRRrKP2xGvK7pTRKCaO3eu7LoS64KIUCLOFWRlVzEORnQLffDBB3JskBgULFaHFa81evToQn3fRMbOTMzvLeuLICLTIgaxivAkWjTSFxqrCETQE11ropWjuN1ZRJSJY0aIqFSJFgnRYvL888+X6yAixqJkJVquRBeP6FpjECEyLHbTEFGpEONYRJeI6LoQH+xvvvlmua550Y0lBhmL2TliLI9oyRHL1ue2LgwRFR3DCBGVCjHYVEznFeNi/ve//+msbloePfvsszI4fffdd3KMSsuWLWUgEWu5EJFhccwIERERlSmOGSEiIqIyxTBCREREZapCjBkRezjcu3dPritQ3J09iYiIqHSI1UPETto1atSAubl5xQ4jIohk37mSiIiIKgax5UTNmjUrdhhJ3xJcfDMODg5lfTlERERUAGI6vGhMSP8cr9BhJL1rRgQRhhEiIqKKJb8hFhzASkRERGWKYYSIiIjKFMMIERERlSmGESIiIipTDCNERERUphhGiIiIqEwxjBAREVGZYhghIiKiMlUhFj0jIiIiXWqNFoE3ohERlwQXexv41XWCyrxi7t/GMEJERFTBBJwLxeztFxAak5Rxzt3RBrP6eKOXjzuMvpvm77//Rp8+feQOfGJ5161bt+b7nP3796Nly5awtrZG/fr1sXr16qJeLxEREUw9iExYG6QTRISwmCR5Xjxu9GEkISEBLVq0wJIlSwpU/saNG+jduzc6d+6MU6dO4a233sKYMWOwa9euolwvERGRSXfNzN5+AVo9j6WfE4+LckbdTfPMM8/IW0EtW7YMdevWxYIFC+RxkyZNcPDgQXz55Zfo2bOn3uckJyfLW9Zd/4iIiExd4I3oHC0iWYkIIh4X5fy9qqGiKPHZNEeOHEG3bt10zokQIs7nZt68eXB0dMy4ie2HiYiITF1EXJJBy5lMGAkLC4Orq6vOOXEsWjsePXqk9znTpk1DTExMxu327dslfZlERETlnou9jWHK3b8G/D4FUKehPCiXs2nEQFdxIyIiokxi+q6YNZNbV42Y2OvmqEzzzdW5zcC2N4GUOKCyK/D0+zD6lhE3NzeEh4frnBPHDg4OsLW1Lem3JyIiMhoqczOM6VhP72PpK4yI6b161xtJfQRsfwvYNFoJIrXbAS2HwyRaRvz9/bFz506dc7t375bniYiIqOC0Wi32B0fI+9YW5khO02Q85pbXOiNRV4CNLwPh55TY0vFt4OlpgKp8dJAU+iri4+Nx9epVnam7Ysquk5MTateuLcd73L17Fz/++KN8fPz48Vi8eDHee+89jB49Gnv37sWGDRuwY8cOw34nRERERm5fcAT+uRIFK5U5/nizI8Jjk/NfgTX4D2DTK0BqAlDJGXjuO8CrC8qTQoeR48ePyzVD0k2ZMkV+HTlypFzMLDQ0FCEhIRmPi2m9InhMnjwZX331FWrWrInly5fnOq2XiIiIckpVa/Dpjovy/qj2nqjnXFne8lW1rjLp17Mj8PxywN4N5Y2ZVrT5lHNi5o2Y4itm1oixJkRERKZm1aEbckGzapWssO/dp+FgY5l74UcPAdsqmcehpwFXH8BchfL4+c1de4mIiMq5BwkpWPTXFXn/7R6Ncg8ion3h5FrgSx/gVpb1vNxblHoQKQyGESIionLuqz1XEPMoFY3d7DG4TS4LgSbHA1vGA79NVGbLnFyDiqJ8DKMlIiIiva5GxGHN0Vvy/sz/5DJtN+ycMlvm/hXAzBzoPAPooIzprAgYRoiIiMqxT3dclBvfdWviinb1q+fsljmxGgiYCqQlAfY1gIErgDrtUJEwjBAREZVT+4MjsD84EpYqM8zo3SRngWt7gN/fUu436AH0XwZUqjgb5KVjGCEiIiqH0rJM5R3p74m61SvlLOTVFfAZCLg3B/wnAeYVcygowwgREVE59HNgCK5GxKOqnSUmdW2Q2S1z6iegSR/AxhEwM1PWDhFfK7CKGaGIiIiMWExiKhbuvizvT+nRCI62lsraIRtHKrNltr2hBBOhggcRgS0jRERE5XAq78PEVDR0rYwhYirv3RPAxlHAw1uAuSVQ+0kYE4YRIiKicuRaZDx+PHJT3v/g2SawCFwG7J4JaFKBKnWAQasAj1YwJgwjRERE5ci8nReRptHiPw1s8VTQW0Dw441lm/QF+n6tu8y7keCYESIionLinyuR+OtiBCzMzTClmxdwLwhQWQHPzgde+NEog4jAlhEiIqLyMpV3+wV5f7h/HdSrU0cJICKM1PCFMWMYISIiKge2HDqD9x/MxF7bDniza3flZC0/mAKGESIiojIWf/lvPLV3JFxV0WhncRM2FtMBWMFUcMwIERFRWdFogL/nw+7n/nBFNELMPaAatR2w0rPaqhFjywgREVFZiI8EtowDru2VLQOb1R3gPHAxateoa3I/D4YRIiKi0pYUC3z7FBB3Dylm1piRMhIR9QbiBx/TCyICwwgREVFps3EAWryIxLPb0TdiLG6Y1ULAf7xN9ufAMEJERFQa4sIBdTJQpbY8VD89HUPO+uOqNhUjn6yNBq72Jvtz4ABWIiKiknZtH7CsPbBhJJCWIk9tCArF6fBUONhY4K1uDU36Z8CWESIiopKiTgP2zwP+WQBAC21lFwRdvIKrSfZy2XfhzW4NUbWS6Uzj1YdhhIiIqCTE3gM2jwFuHZKHIfUGY8Sd/rj5k7IJnqAyN4OLvbXJ1z/DCBERkaFd2Q1seRVIvA9Y2ePUEx9hwAF30TaiU0yt0eKNX07CUmWGXj7uJvtz4JgRIiIiQy9ktm+OEkTcmkM97gAmnKqbLYbomr39ggwmpophhIiIyKCfrObAwJWA/+vAK7sRGFMFoTFJuRbXAvLxwBvRJvtzYBghIiIqruA/gIOLMo+d6gE95wCWNoiIyz2IZBVRwHLGiGNGiIiIikpM090zGziyGIAZUKstUMdfp4iLvU2BXsqlgOWMEcMIERFRUTy4CWwaDdw9oRw/OQHwaJWjmF9dJ1SxtcTDR6l6X8YMgJujjSxnqhhGiIiICuvCNuC314HkGMCmCtB/KdD4Wb1Fw2OTkJSmzjWICLP6eMtpvqaKYYSIiKgwds8EDn2l3K/pBwxckbHEe3YajRbvbDyNpFQNPKvZya9hsZljQ0SLyKw+3iY9rVdgGCEiIiqM6o+Xbm//JtDlQ0BlmWvR1Ydv4vC1+7C1VGHly21Qp1olOWtGDFYVY0RE14zKhFtE0jGMEBER5ScxGrB7PKbDd6hcPwTuzfN8ypXwOHwecEnen967Ceo5V5b3/b2qsb6z4dReIiKi3KQ+Ara/BSzrqAQSwcws3yCSkqbB5A2nkJymQaeGzhjWVn83DikYRoiIiPSJugIs7wacWAXE3gWu/lXgevp67xWcuxuLKnaW+GJgc5iJAEO5YjcNERFRdmc2KC0iqQmAXXXg+e8Bry4FqqegkAdYsu+qvD+nfzO4Opju+iEFxTBCRESULiUR+OM94OQa5dizI/D8csDerUB1lJiShinrT0FsM9PftwZ6NzftWTIFxTBCRESUTmxwJ4OIGdDpfaDTe4C5qsD1M2fHRdy8nwh3RxvM7ufDei0ghhEiIqJ0T70L3PkX6DwDqNepUPWyLzgCPx0LkffnD2oBR9vcp/ySLg5gJSIi05UcD/y7HNCKvXMB2FYBRu8qdBB5kJCC9zadkfdHtfdE+/rVS+JqjRZbRoiIyDSFnwc2vgxEXQbMzIHWo5XzhZz5otVqMWPrWUTGJaO+S2W836txyVyvEWMYISIi0yJaQYJ+AP54H0hLAuxrAM5FDxBbT93FzrNhsDA3w5cv+MLGsuBjTEjBMEJERKYjKRb4/S3g3GbluH53YMC3QKWirYp67+EjzPztvLz/ZtcGaFbT0ZBXazIYRoiIyDSEngE2jgSirwNmKqDbLMB/EmBetOGT6ZvgxSWl4YnaVTDhaS+DX7KpYBghIiLTkBwLPLgJONQEBq0CavkV6+WyboK38AVfWKg4J6SoGEaIiMi4x4ekD0j17AAMXAnU7ZS56V0RiU3wPsuyCV7d6pUMcbUmizGOiIiM090gYFkHIPJy5rmmA4odRNI3wRNfuQmeYTCMEBGR8bWGHF0KrOgBhJ8D/ppl0JfPugnef7kJnkGwm4aIiIzHowfAb68Dl35Xjpv0AfouNtjLZ98Ez4Wb4BkEwwgRERmH2/8Cm0YDMSGAygroMQfwG1voRcxyw03wSg7DCBERVXy3DgM/9AE0aUDVusCg1UANX4O+BTfBKzkMI0REVPHVbAN4tAIcPIA+XwE2DgZ9eW6CV7IYRoiIqOLOlnH1ASysAJUlMGwzYFXZIN0yao0WgTeiERGXBDtLFaZtOSvPcxO8ksEwQkREFYtGAxz6Etg7B3hyAtBzjnLe2t4gLx9wLhSzt19AaEySznk3BxtugldCOLWXiIgqjvhI4KeBwJ6PAa0aSIhSwomBiCAyYW1QjiAihMUmYX9whMHeizIxjBARUcVw86CyiNm1PYCFrTJld8CyIu8to69rRrSIaHN5XHT+iMdFOTKsIv0ElyxZAk9PT9jY2KBt27YIDAzMs/yiRYvQqFEj2NraolatWpg8eTKSknKmTiIiohw0amD/58psmfgwwLkxMG4f0HK4wabtCmKMiL4WkXQigojHRTkq4zEj69evx5QpU7Bs2TIZRETQ6NmzJ4KDg+Hi4pKj/M8//4ypU6di5cqVaNeuHS5fvoyXX34ZZmZmWLhwoaG+DyIiKseyDgh1sbeBX10nqMwLGCRi7wKHvwa0GsB3GPDsF4CV4faCEcu6/305Et/sVxYzy4/4HqiMw4gIEGPHjsWoUaPksQglO3bskGFDhI7sDh8+jPbt2+Oll16Sx6JFZciQITh27Jghrp+IiMo5fQNC3R1tMKuPN3r5uOf/AlVqA/0WA2lJQIsXDRaOjl2/j22n7+GPc2GIeZRa4OeKMEVlGEZSUlJw4sQJTJs2LeOcubk5unXrhiNHjuh9jmgNWbt2rezK8fPzw/Xr17Fz504MHz481/dJTk6Wt3SxsbGFuUwiIion0geEZh9lERaTJM8vHdYyZyBRpwEHPgPqtAe8OivnmvYvdouLVqvFydsPse3UPew4G4rIuMzPGWd7azzbzA2/nw5FdEKK3nEj4lXdHJX3oDIMI1FRUVCr1XB1ddU5L44vXVK2Us5OtIiI53Xo0EH+IqSlpWH8+PGYPn16ru8zb948zJ49uzCXRkRE5UxeA0K1WQaEdvd2ywwQsfeAzWOAW4eASj8Ak07kuoBZQVtcLoXFygCy/cw93I5+lHHe0dZSBpA+LWqgbd1q8hr861WTIUlcTdbrTo834rUL3L1E5Wedkf3792Pu3Ln45ptv5BiTq1ev4s0338Qnn3yCDz/8UO9zRMuLGJeStWVEDHwlIqKKo6ADQt/bdFq2NjRJCIT30XdhkRStLF7Wa16eQSSvFpeP+zXFw8RUGUAuh8dnPG5npUJ3b1f0bVEDHRs4w8pCdx6HCDGitSZ7yHErTLcSlWwYqV69OlQqFcLDw3XOi2M3Nze9zxGBQ3TJjBkzRh43a9YMCQkJGDduHGbMmCG7ebKztraWNyIiqrgKOtDzt6BbqH9mPppbbJfH5zV18G7yFKTsdoZ74DG52Jho8XBztIV7FRu42Ftj1rbzuba4CB/+dj7jnJXKHE83ckZf3xro2tgVtlaqPK9HBA7RWlPkAbdUsmHEysoKrVq1wp49e9C/v9J/p9Fo5PHrr7+u9zmJiYk5AocINILotiEiIuNUkIGetkjCNscFaJCshId16IlZKUOQDCsgIh5XIzJbNQqrmYcDhvt7omdTN9klUxiyy8arWpHfm0q4m0Z0n4wcORKtW7eWA1LF1F7R0pE+u2bEiBHw8PCQ4z6EPn36yBk4TzzxREY3jWgtEefTQwkRERkf0ZogWjRy66oR7QxVHBzh1bApcPkO0O9rvOjdD31T0mR3i7iJ54qVT0NjHiH0oXJ8KzoBCcnqfN9/TMd66OfrUQLfGZV5GBk8eDAiIyMxc+ZMhIWFwdfXFwEBARmDWkNCQnRaQj744AO5poj4evfuXTg7O8sgMmfO470EiIjIKInWhbe6NcT7m8/onLdEGmyRgjjYYVbfpjBv8CWQGAVU9ZSP21lZoJ5zZXnT58i1+xjy/dF8359TcCsOM20F6CsRA1gdHR0RExMDBwfDbgtNREQl5/Wfg/D7mVBYmJshTaNFTbMILLb8GnEWVZEwYA16NatRpFk6HT7fK1tO8pqCe/D9LhznUUE+v7k3DRERlYi9l8JlEBHjPjeNb4ddPWOwr9KH8DW/hg5WV9CrRuY028K2uIiZLUL2IaWcglsxMYwQEZHBxSen4YMt5+T9ce084HtuLhodmADLtDigZhuYjT8IVPMq8uunT8EVLSBZiWO9C6mRaa8zQkREpmf+rmDci0mCn+NDvHv3cyDstPJAuzeArjMBVeFmt+jDKbjGg2GEiIgM6mTIA/xw5KZc9WOl7ddQhV0EbJ2AAcuAhj0N+l6cgmsc2E1DREQGk6rWYNqvZyGmRgx4oiYqD1wM1H0KEN0yBg4iZDzYMkJERAazPmAfPCP+Rrhde3zQuwlQ2RoYsQ0w4+qllDuGESIiMoiIgz9iQOA7GGipwcGOT6GaCCICgwjlg2GEiIiKJyUR2j/eg8vJNXJu7QXrFujaqglrlQqMY0aIiKjoIi4B33eB2ck10GjNsFjzPCqP2QEzh8IvZkami2GEiIiK5tQvwPedgciLiEQVDE2dDqtuM1Db2Z41SoXCbhoiIiqahyFAaiIu2bXCsOgxcPOohdHt67I2qdAYRoiIqOA0GiB9M9Sn3sGFR47ofcAD5uYqrH6uOSxUbHCnwuNvDRER5U8sHHJiNbCyB5Cq7CkTn6rFmFMNoIU5xnSoCx8PR9YkFQnDCBER5S05Dtg8Btj+JnDnXyBojc6S77Wd7PBWt4asRSoydtMQEVHuQk8DG18Goq8DZiqg64dAmzFZlnwH5gzwga2VirVIRcYwQkRE+rtl/l0O7JoOqFMAh5rAwJVA7bY6S74/19IDHRs4swapWBhGiIgopwNfAPvnKvcbPgP0/wawc5KH3/19HZfC4uBUyQof9PZm7VGxccwIERHl5PsSUMkF6DEHGPJLRhC5HhmPr/Zckfdn/sdbBhKi4mLLCBERKd0yIUeAOu2U2qhSC3jzFGBVKaN2tFotpm85i5Q0DZ5q6Ix+vlxllQyDLSNERKbu0QNg/TBg1TNAcEDm+SxBRNhw/DaOXo+GraUKc/r7wIwb4JGBsGWEiMiU3f4X2DQaiAkBVFZAQoTeYhFxSZiz46K8/3aPhqjlZFfKF0rGjGGEiMhUV1I9shjYMxvQpAFV6wKDVgE1ntBbfPb2C4hNSkMzD0e83M6z1C+XjBvDCBGRqUmMBraMB67sUo6bDgD6fAXY6F9Bdc/FcOw4EwqVuRk+e74Zl3wng2MYISIyNTf/UYKIyhroNQ9oPRrIZfxHfHIaPth6Tt4f07Eumtbgku9keAwjRESmxrsf0HkG0LAX4N48z6JiyffQ9CXfu3LJdyoZDCNERMYuPhL4cwbQ41OgsotyrtN7eouqNVoE3oiWA1ZjHqVi9WFlyfe5A5pxyXcqMQwjRETG7OZBYNMrQHwYkBQLvLQu16IB50LlQFXREpLVk3WroUOD6qVwsWSquM4IEZEx0qiB/Z8DP/RRgkj1RkDXmXkGkQlrg3IEEeHYjfvycaKSwjBCRGRs4sKBNQOUvWW0GsB3KDBuH+DqnWvXjGgR0ebxkuJxUY6oJLCbhojImISdBdY8pyxeZmkH9F4I+A7J8ylijIi+FpF0IoKIx0U5f69qJXDRZOoYRoiIjElVT8DGAajkDAxaDTjnPwMmIjb3IKJTLq5g5YgKi2GEiKiiS4gC7Kopa4VY2wNDNwH2boClbZ5PExvf7QuOwKLHu/Dmx8XexkAXTKSLYYSIqCK78hewZRzQ8R3A/zXlnFPdfEPI31eisHD3ZZy+/VCeE0ue5TYiRDzm5mgDv7pOhr56IolhhIioIlKnAns/BQ4tUo7PbQLavgqYq/IMIUeu3Zch5PitB/Kc2IF3RLs6qO9cGe9tOqOUy/Kc9HVZZ/XxlsvBE5UEhhEiooom5o6y0+7tY8pxmzFAjzl5BpFj15UQcuxGtDy2tjDH8Cfr4NVOXnC2t5bn7G0scqwzIlpERBDp5eNe0t8VmTCGESKiiiT4D2DrBODRA8DaAej7P2Wju1ycuBUtQ8ihq/flsZXKHC+1rY3XnvaCi4PuGBAROLp7u2WswCrGiIiuGbaIUEljGCEiqkgtIuuHA5pUwN0XGLQKcKqnt+ip2w9lCPn7cqQ8tlSZYXCbWpjYuT7cHXMf2CqCB6fvUmljGCEiqigcawLdZkHz8DYC67+F8BAtXB7c12m9OHc3Bl/uvow9lyLksYW5GQa1rilDSM2qdmX8DRDpxzBCRFSeXfxdWTvEzUceBjgMxOwDFxD698mMIu6ONhjdvi7+vRmNPy+Ey3MinDz3hAcmdWmA2tUYQqh8YxghIiqP0pKB3TOBY8uAag2AcfsRcCVO7h+TfQquGHA6Z+dFeV80kPTz9cAbXRugbvVKZXLpRIXFMEJEVN5EXwc2jgJCTynHDXtCbW6Z7/4xNpbm+G1iezRycyitKyUyCIYRIqLy5PwWYNsbQHIsYFsV6L8MaNQLgdfu57l/jJCUqkF0QmqpXSqRoTCMEBGVB2kpQMBU4PgK5bjWk8DAFcqg1ULsC8P9Y6giYhghIioPxIJl9x/vEdNhCtB5BqDK/CdaLFJWENw/hioihhEiorKk0QDm5koYee57IPw8UL9rjoXLZv52Ls+X4f4xVJExjBARlYWUROCP9wCVFfCfhco5sdOuuGXZS2b14ZuYs+Mi0jRauDpYIzw2Ocemdtw/hio6hhEiotIWGQxsfBmIuKBECb9xgEtjnSIJyWl4f/MZ/H4mVB73bu6Oz59vjoNXIrl/DBkdhhEiotJ06mdgx9tAaiJQyQV4/vscQeRqRBzGrw3C1Yh4uYLq9GebYFR7T5iZmXH/GDJKDCNERKUhJUEJIad/UY7rdlLGiNi76hT7/cw9vL/pDBJS1LJbZslLLdHa00mnDPePIWPDMEJEVNK0WmDNc8Dto4CZOfD0NKDj28qg1cdS1RrM23kJKw/dkMdP1nPC10Nawtnemj8fMnoMI0REJc3MDGj/BrDjFvD8csCzg87DYTFJeP3nIBy/9UAej+/khXd6NISFqmDTeYkqOoYRIqKSkBwHRF0BPFoqx417A/U6A1a6m9YdvhaFN345iaj4FNhbW2D+Cy3Qs2nmjBoiU8AwQkRkaKFngE2jgMRoYPxBwNFDOZ8liIhpu8sOXMd/d12CRgs0drPH0mGtuLkdmSSGESIiQ44NEcu5B0wH1MmAgweQEJkZRh6LTUrFOxtO488L4fL4uZYemNO/GWytMseQEJkShhEiIkNIilE2uLuwVTlu2Avqvt8gMByIOHVXLtPuV9cJl8PjMGHtCdy8nwgrlTk+6tsUQ/xqyWm7RKaKYYSIqLjuBindMg9uAuYWQLfZCLB/DrO/PqWz066jrSUSU9KQqtbCo4otvhnaEi1qVWH9k8kr0lDtJUuWwNPTEzY2Nmjbti0CAwPzLP/w4UNMnDgR7u7usLa2RsOGDbFz506Tr3wiMhIn1yhBxLE2MHoXAhyex4SfTuoEESHmUaoMIt7uDvh9UgcGEaKitoysX78eU6ZMwbJly2QQWbRoEXr27Ing4GC4uLjkKJ+SkoLu3bvLxzZt2gQPDw/cunULVarwrwEiMhI95wKWdsBT70BtXQWz1+zV2TsmuweJKXCwtSzFCyQyspaRhQsXYuzYsRg1ahS8vb1lKLGzs8PKlSv1lhfno6OjsXXrVrRv3162qHTq1AktWrQwxPUTEZW+O8eB315XdtwVLG2BnnMA26oIvBGdo0UkO/G4KEdERQgjopXjxIkT6NatW8Y5c3NzeXzkyBG9z9m2bRv8/f1lN42rqyt8fHwwd+5cqNXqXN8nOTkZsbGxOjcionIxW+bw18DKnkrXTOB3OYpExOUdRApbjsgUFCqMREVFyRAhQkVW4jgsLEzvc65fvy67Z8TzxDiRDz/8EAsWLMCnn36a6/vMmzcPjo6OGbdatWoV5jKJiAxPrBnyy4vAnx8AmjTAuz/gOyRHMTFItSDE7BoiUpT4WsMajUaOF/nuu+/QqlUrDB48GDNmzJDdO7mZNm0aYmJiMm63b98u6cskIspdyFFgWUfgcgCgsgZ6LwAGrQZsHHWL3U/EvJ0X86xJMYHX3VGZ5ktERRjAWr16dahUKoSHKwv1pBPHbm76ly8WM2gsLS3l89I1adJEtqSIbh8rK6sczxEzbsSNiKjMBf0IbH8L0KoBJy8lhLg3z1Hs78uRmPTLSTljxt7GAnFJaTJ4ZB3Imr6SyKw+3nLnXSIqQsuICA6idWPPnj06LR/iWIwL0UcMWr169aosl+7y5csypOgLIkRE5Yq7r7J2SLNBwKsHcgQRsaz70v3X8PKqQBlExLohf05+CsuGtYSbo25XjDheOqwlevm4l/I3QWRkU3vFtN6RI0eidevW8PPzk1N7ExIS5OwaYcSIEXL6rhj3IUyYMAGLFy/Gm2++iUmTJuHKlStyAOsbb7xh+O+GiMgQ4iOAyo+XKhDhQ+wvU72BsvtuFgnJaXhv0xnsOBsqj19oXRMf9/OBjaUK7o626O7tJmfNiMGq6SuwskWEyABhRIz5iIyMxMyZM2VXi6+vLwICAjIGtYaEhMgZNunE4NNdu3Zh8uTJaN68uQwqIpi8//77hX1rIqKSpVED/ywE/lkAjNqZueOuc8McRW/dT8C4H08gODwOFuZmmNW3KYa1ra2zrLsIHv5e1fhTI8qHmVa0MZZzYmqvmFUjBrM6ODiU9eUQkTGKCwd+HQvcOKAcd3wb6DpTb9H9wRF445eTiE1KQ/XK1rLrpY0nB6QSFfXzm3vTEBFd3w9sHgskRCgrqYrZMr4v5agX8bfbN/uvYf6fwXLJkSdqV8HSoa1yjA0hosJhGCEi0+6WOfA5cOALZd6LizcwcBXg0jhH0fjkNLy78TT+OKesqSR22hU77lpbZM4UJKKiYRghItN1brMSRoSWI4BenwNWdjmK3YgS40OO40pEPCxVZpjd1wcvta1d+tdLZKQYRojIdPkMBIL/ABo9CzQfpLfIvksReGPdSbluiLO9tZyy26oOx4cQGRLDCBGZDnUacGwp0Ho0YFVJbK4FDFqlt6hGI8aHXMWC3Zfl+JCWYnzIsFZwdeD4ECJDYxghItMQcwfY9Apw+ygQfgEYsFSeVmu0OdYCeZSqxtsbTmHXeWW16aFta2NWn6awsijxHTSITBLDCBEZv8u7gC2vAo8eAFb2QIPu8nTAuVDM3n4BoTGZO+g6V7aCytwcYbFJsFKZ4+N+TfGiH8eHEJUkhhEiMl7qVGDPbODw15lLu4tuGad6MohMWBuks3eMEBmfIr862lpg1Sg/tKxdtfSvm8jEMIwQkfF2y2wYCdw9rhy3HQ90/xiwsJZdM6JFJK8VH8WS7i1qVimtqyUyaewAJSLjJDa3e3ATsHEEBq8FnvlcBhFBjBHJ2jWjT3hssixHRCWPLSNEZFyLmJk/XoTM3g148SfA3h2oWkenmBisWhAFLUdExcOWESIyDtHXgeVdgfNbM8/VfjJHEBFU2XbfzY2YXUNEJY9hhIgqvvNbgG87AfdOAn/NUgau6iH2ltnw721M3Xwmz5cTUcXdUZnmS0Qlj900RFRxpSYBu6YDx1cox7XaAgNXAirLHEXDYpIw9dcz2B8cKY89q9nh5v1EGTyyDmRNbzOZ1ccbKvOCtaAQUfEwjBBRxXT/GrBxJBB2VjnuMBnoPCNHEBGtIZuD7mL29vNySXexcNmU7g0xtmM97L4QlmOdEbEDrwgivXzcS/s7IjJZDCNEVPHEhSndMilxgF01YMB3QINuOYqFxyZh+q9nsedShDxuUdMR8we1QANXe3ksAkd3b7ccK7CyRYSodDGMEFHFI2bKPDFUaRV5fjngUCNHa8jWU3fx0bYLiHmUKldSfat7A4zrWA8WKt2hciJ4+HtVK+VvgIiyYhghoooh8rKyuZ2jh3Lc/RPAzBxQ6f4zJlo4Zmw5h90XlH1lmnkorSGN3JTWECIqfxhGiKj8O/ULsGOKspz7yO1KALGwytEasu30Pczadh4PE1NhqTLDG10aYPzTXrDM1hpCROULwwgRlV8pCcDOd4FTPynHIoSkxAO2usu0R8Un44Mt5xBwPkwee7s7YMELLdDE3aEsrpqIColhhIjKp/ALwMaXgahg2R2j6TQVxzxGISI4AS726oyBpjvOhOLD384hOiEFFuZmmNSlAV7rzNYQooqEYYSIyhetFji5RmkRSUsCKrshsOXnePOIPUJj/s0o5mJvjZpVbREU8lAeN3azl60hTWs4luHFE1FRMIwQUfmiTgGOfKMEEa8u2NvkE7yy6Ra00N0nJiIuWd7EumSvd66P17s0kGuIEFHFwzBCROWL2Fl30Grg8h9Q+7+BGV/s11khNTunSlZ4s1tDrg1CVIHxzwgiKvtumX9XAIe/zjzn0liuqBp486HO6qj6RMWnyEXLiKjiYssIEZWdpFhg+xvKRndmKqBeZ8DNR2fNkIIoaDkiKp8YRoiobIgddjeOAh7cAMwtgK6zABfvHFN2C0Is405EFRfDCBGVfrdM4HfAnx8og1Udays77dZqk1EkKVWN/+4KxoqDN/J8KbPHG9uJab5EVHExjBBR6QaRzWOAc5uU40a9gf5LANuqGUXO3HmIKRtO42pEvDxu71UNh6/dV56eLYgIYoddbmxHVLExjBBR6TEzA2o/CVz4DejxCdB2vHIOQKpag8V7r2LxvqtQa7RwtrfG5883Q5fGrgg4F4rZ2y/oDGYVLSIiiIidd4moYjPTig0dyrnY2Fg4OjoiJiYGDg5c3pmoQhH/xMSHKzvtph/fvwZUr59R5GpEHCavP42zd2Pkce/m7vi0nw+qVsrcf0YEFDFrRgxWFWNE0ldgJaKK//nNlhEiKjmJ0cDW14DIi8CrfwM2jkpLyOMgotFosfLQDXyxKxgpaRo42lrik/4+6NuiRo6XEsHD36saf1pERohhhIhKRsgxYNNoIPYOoLIC7vwL1O+W8fDt6ES8u+k0jl5X1gh5qqEzvni+uex+ISLTwjBCRIal0QCHvwL2fAJo1YCTl7Kiqntz+bDoGd54/A4+/v0C4pPTYGelwozeTfCSX22YPR4/QkSmhWGEiAwnIQrYMh64uls59hkI9FkEWNvLQzHeY9rms9hzKUIet65TVW5uV6daJf4UiEwYwwgRGc6fH8ogolFZ40yz6XjkMwx+lpWhArDzbChmbDmLB4mpsFKZY0qPhhjbsR4HoRIRwwgRGc6e2q/D4cw5fJj4Ei4drQ0cPQZXB2vUcbJD4M0Hsoy3uwMWDm6Bxm6cGUdECraMEFHRxUcAZzcB/q/JtUAmbLwJLabqFAmPTZY3MRpkYuf6eKNrA1hZcI9OIsrEMEJERXP9APDrWLmGiMa2Kmb/4aKzQmp2TpWtMLl7Q3bLEFEO/POEiApHowb2zQV+7KcsZubcBGfUdXVWR9XnfnyKXLSMiCg7towQUcHFhiqtITf/UY6fGA488wVuXRDjQZT9Y/IiZtMQEWXHMEJEBXN9P7DpFSAxCrCspEzZbf6CfMjF/lGBXkIs405ElB3DCBEVjCZNCSKuzZRFzLLsLeNbq4oclCqWdNdHDF4VK6uK/WSIiLJjGCGi3KnTANXjfybEUu4v/gx4dQEsbTOLaLR4Z9PpPIOIIHbY5cZ2RKQPB7ASkX6XdwGLWwMPbmaea9xbJ4iIpd0/2HoWO86EwlJlhkld6sM9294yokVk6bCW6OXjzpomIr3YMkJEutSpwJ7ZwOGvleO/5wP9Fuutpc8CLuGXwNswNwMWDX4CvZu7461uDeWsGTFYVYwREV0zbBEhorwwjBBRpochyk67Yoddwe9VoMcnemvom/1X8e2B6/L+3AHNZBARRPDw96rGWiWiAmMYISLFpR3A1glAUgxg7ai0hnj31Vs7a4/ewhcBwfL+9Gcb40W/2qxFIioyhhEiAi5uB9YPU2qiRktg0Cqgqqfemvnt1F18+Ns5eX9iZy+Me8qLNUhExcIwQkRAgx6Auy/g2QHoOguwsNJbK3svhePtDaeh1QLDn6yDd3o0Yu0RUbExjBCZ8iJmdTooU3ctrIHRuwDL3BclO3b9PiasDUKaRot+vjUwu29TmJmlT9wlIio6Tu0lMjWpScCOd5S9ZQ58lnk+jyBy7m4MxvxwHMlpGnRt7IL5g1rAXEyhISIyALaMEJmS+9eAjS8DYWcyV1UVfS55tHBcjYjHiJWBiEtOQ9u6TlgytCUsVfw7hogMh2GEyFSc3QRsfwtIiQPsqgEDvgUadM/zKXceJGL4imOITkhBMw9HLB/ZGjaWqlK7ZCIyDQwjRMYu9REQMBU4sVo5rt0OGLgCcKiR59Mi45IxfEUgQmOS4OVcCT+M9oO9jWXpXDMRmRSGESJj9/A2cHq9skvMU+8AnaZm7jeTi5hHqbJr5kZUAjyq2GLtmLZwqqR/hg0RUXEVqeN3yZIl8PT0hI2NDdq2bYvAwMACPW/dunVy9H3//v2L8rZEVBTODZUFzIb/CnT5IN8g8ihFjVdW/4uLobGoXtlKBhF3x8z9aIiIyjyMrF+/HlOmTMGsWbMQFBSEFi1aoGfPnoiIiMjzeTdv3sQ777yDjh07Fud6iSg/KQnAtklAyNHMc80GKrvt5vfUNA3Grz2B47cewN7GAj+Obou61SuxzomofIWRhQsXYuzYsRg1ahS8vb2xbNky2NnZYeXKlbk+R61WY+jQoZg9ezbq1atX3GsmotxEXAS+7wIE/QhsHgukpRS4rtQaLSavP4UDlyNhY2mOVS+3gXcNB9Y1EZWvMJKSkoITJ06gW7dumS9gbi6Pjxw5kuvzPv74Y7i4uOCVV14p0PskJycjNjZW50ZEeRDTc4PWAN91BiIvAZVdgf7f5LqSqggeR67dl0u7i69pag1mbDmLHWdDYakyw7fDW6O1pxOrnIjK3wDWqKgo2crh6uqqc14cX7p0Se9zDh48iBUrVuDUqVMFfp958+bJVhQiKoDkeGDHFOCMGKQKpTtmwHdAZWe9xQPOhWL29gtylky6SlYqJKSoIdYxWzT4CXRqqP+5REQloURXLoqLi8Pw4cPx/fffo3r16gV+3rRp0xATE5Nxu337dkleJlHFlRAFfNdJCSJm5kCXD4Ghm/MMImJJ96xBRL5Milp+fcmvNno3dy+VSyciKlLLiAgUKpUK4eHhOufFsZubW47y165dkwNX+/Tpk3FOo9Eob2xhgeDgYHh55dzx09raWt6IKB9i8TKXJkBKorJ2SJ12uRYVXTOiRUSbx8vtuRSB2RotVFzqnYjKa8uIlZUVWrVqhT179uiEC3Hs7++fo3zjxo1x9uxZ2UWTfuvbty86d+4s79eqVcsw3wWRKUmKVW6CWMa972Jg/ME8g4gQeCM6R4tIduJxUY6IqFwveiam9Y4cORKtW7eGn58fFi1ahISEBDm7RhgxYgQ8PDzkuA+xDomPj4/O86tUqSK/Zj9PRAVw7xSwaRTg3gIYuEoJI7bK/1N50Wq1OBnyoEBVHBGXd2AhIirzMDJ48GBERkZi5syZCAsLg6+vLwICAjIGtYaEhMgZNkRk4Nkygd8Df84A1CmAOhVIiAQqu+T6FI1Gi5O3H2LX+TAEnAtDSHRigd7KxT733XuJiEqCmVb8yVTOiam9jo6OcjCrgwPXPSAT8+ghsO114OJ25bjRs0C/JYBdzqm3Yoqu6GYJOB8mQ0h4bHLGY1YqM7kCcnKaMm4rO7Fvr5ujDQ6+34VjRoioVD+/uTcNUTmmvn0cqetGwibhDjTmlkD3j2H+5ASle+axpFQ1Dl2Nkq0fuy+G42FiasZjla0t0LWJC3o1dUOnRs74+3KknE0jZP0rJP3VZvXxZhAholLHMEJUTu06E4Jmvw5BDUQgROOM15PfQOT+RphlH4aODZyxLzhCBpB9lyIypuYKYkO77k1c0cvHDe3qV4O1hSrjsV4+7lg6rGWOdUZEi4gIIuJxIqLSxm4aonIofT0QP7OLGG6xG9NTX0EsMveIsTA3Q5oms23DzcFGho+eTd3QxrMqLFR5j9sS03xFd44YrCrGiPjVdWKLCBEZHLtpiCqi24FQx4oVUivLbpRj2iY4ltokRzERROo42eKZZjVkCGnu4QjzQqwNItYR8feqZuCLJyIqGnbTEJUHYjHAw/8D9nwMqKxhm/AxgBp5PuWz55vD36vgKxsTEZVXDCNEZS3hPrDlVeDqbnkY6vo0Iq7lv3ZIRFzmTBkiooqMYYSoLN06DGx6BYi7B1jYAL0+w+0qfRB/7Vi+T+V6IERkLBhGiMrKPwuAvZ8CWg1QrQEwaDXg5oOwoDt5Pi19PRAx6JSIyBgwjBCVFbG/jAgizV8Eei8ArCtj76VwvLvpjE7w4HogRGTsGEaISpM6DVA9/t+uywdALT9lRVUzMxy7fl9O5xUzZfr71kAPbzd8soPrgRCR8WMYISoNGjVw4Avg2l7g5R2AhRWgsgQa95YPn7sbgzE/HJdLtXdt7IL/DmoBS5U5evq4cT0QIjJ6DCNEJS0uDNg8Brj5j3J86XfA57mMh69FxmPkykDEJaehbV0nLBnaUgYRgeuBEJEpYBghKklX9wC/jgMSowDLSsB/vtQJIvcePsLw5cdwPyEFPh4OWD6yNWwsM5dvJyIyBQwjRCU1NmT/XOCfhcoQVFcfYOAqwLlhRpH78ckYtuIY7sUkoZ5zJfwwyg/2Npb8eRCRyWEYISoJf7wHHF+h3G81Cug1D7C0zXg4NikVI1cF4npkAmo42mDtK21RrbI1fxZEZJLy3k2LiIrGfyJgXwN4fgXQZ5FOEElKVcvBqufuxqJaJSusGdMWNapkPk5EZGrYMkJkCOpUZYCqVxfluJoX8OYpwEK3tSNVrcHEn4LkDBl7awv8MNoPXs6V+TMgIpPGlhGi4np4G1j1LLDmOeDavszz2YKIRqPFuxtPY8+lCFhbmMvBqj4ejqx/IjJ5bBkhKo5LO4GtE4Ckh4C1I5CWpLeYVqvF7O3nsfXUPViYm2HpsJZoW68a656IiN00REWUlgL89RFwdIlyXKMlMGgVUNVTb/Evd1/GD0duiYVWseCFFujS2JVVT0T0GFtGiArrwU1g4yjgXpBy/OREoNtHyqqqeiz/5zr+t/eqvP9xPx/08/VgnRMRZcEwQlRYNw8pQcSmCtB/KdD42VyLbjx+G5/uuCjvv9OjIYY/WYf1TUSUDcMIUWH5vgTEhQLNBwNVauVabNf5MLy/WdmBd0yHupjYuT7rmohID86mIcrP/WvAL0OAxGjlWAz8eOqdPIPIoatRmPTzSWi0wKBWNTGjdxOYiecREVEObBkhysvZTcD2t4CUOGDXdGDAshxF1Bqtzs66VhbmGPvjcaSoNejV1A3znmvGIEJElAeGESJ9Uh8BAVOBE6uV49rtgK4zcxQLOBeK2dsvIDQmc0qvaADRaoH29avhqyG+sHi8Ay8REenHMEKUXdQVYOPLQPg5ES2Ajm8DT08DVBY5gsiEtUFiGzwdIogIg1rVgrUFd+AlIsoP/2QjyurGP8C3nZQgUskZGP4r0PXDHEFEdM2IFpHsQSSdGB3yecAlWY6IiPLGMEKUlZsPYFcN8OwIjD+YuddMNmKMSNaumexEBBGPi3JERJQ3dtMQxdwBHDyUwR62VYFRO5Rj89y7WMRg1YIoaDkiIlPGlhEyXWJwx8m1wNetMweqClVq5xlEBDFrpiAKWo6IyJQxjJBpSo4HtowHfpsIpD0CruzOHHlaAH51nVDZOveGRTFmxN3RRpYjIqK8sZuGTE/YOWW2zP0rgJk50HkG0GGK0k1TQL8G3UF8cprex9JfZVYfb6jMudAZEVF+GEbIdIiWD9EdI9YPSUsC7GsAA1cAddoV6mX+uRKJab+elfd7NnXFmTsxOoNZ3RxtZBDp5eNu8G+BiMgYMYyQ6Yi4COyYAmg1QIMeQP9lQKVqhXqJC/di5doiaRot+raogUWDfeXMmawrsIquGbaIEBEVHMMImQ5Xb6DzdEBlBfhPAswLN2Tq3sNHGLU6UHbPtK3rhP8Oag7zx90w/l6FCzVERJSJYYSMu1vm+Aqg7tNA9cc75j71bpFeKjYpFaNW/Yvw2GQ0cKmM74a35uqqREQGwjBCxunRQ2D7G8CF3wDXZsCYvwDLok2zTUnTYMLaEwgOj4OzvTVWjWoDRztLg18yEZGpYhgh43P3BLBxFPDwFmBuCTwxFLCwLtJLabVaTN18Boeu3oedlQqrXm6DmlXtDH7JRESmjGGEjKtb5uhSYPdMQJMKVKkDDFoFeLQq8ksu3H0Zv568KwekfjO0JXw8HA16yURExDBCxiI5Dvj1VSB4h3LcpC/Q92vAtkqRX/KXwBB8vfeqvD93gA+ebuRiqKslIqIs2DJCxsHCBkiIVGbK9JwLtBlTqEXMstsXHIEPtp6T99/oUh+D29Q24MUSEVFWDCNUcWk0ypohKgtAZQkMXAk8igbcWxTrZc/djcHEn4Kg1mjxXEsPTO7e0GCXTEREOXFvGqqYEu4Dv7wI7Pko81yVWsUOIrejEzFq9b9ITFGjQ/3q+Oy55jArRgsLERHlj2GEKp5bh4FlHYAru4DA5UDsPYO8bExiqgwikXHJaOxmj2+GtYSVBf8XISIqaeymoYrVLXNwIbBvLqBVA9UaAINWAw41iv3SyWlqjFtzHFcj4uHmYCPXEnGw4VoiRESlgWGEKob4SGDLOODaXuW4+YtA7wWAdeViv7RGo8U7G8/g2I1o2FtbyCDi7mhb/GsmIqICYRih8k+dBqzqBdy/CljYAr3nA75DizVbJqsvdgVj++l7sDA3w9JhrdDE3cEgr0tERAXDDnEq/8RsmaenAc5NgHH7gSeGGSyIrDl6C8sOXJP3P3u+OTo0qG6Q1yUiooJjywiVT3HhQOydzNVTmw1UFjKzsCryS4qpuoE3ohERlwQXexvEPUrFrN+UtUSmdG+Iga1qGurqiYioEBhGqPy5tg/4dSxgZg6MPwhUfrzyaTGCSMC5UMzefgGhMUk5HhvcuhYmdXm8qy8REZU6dtNQ+RobsucTaNcMkKupxphXQdDVO7JFozhEEJmwNkhvEBE6NqzOtUSIiMoQwwiVD2KtkB/7Av/Mhxm0+CmtK/wipuG5daHo8PleGSiKQgQZ0SKSW5wRI0/m7LhY7MBDRERFx24aKntX/lKm7SbeR5zWFtNTX8F2TbuMh8NikmTLxtJhLdHLx11nSm5cUhqiE1PwIDEFD8XXhNTH91Pl+WsRcbm2iAgigojHxVgSf69qJf6tEhFRTgwjVPbObpBB5JJZPbya/Dpuad10Hk5vs3hz3Sk0rXEdDx+lyrAhwoehGjTEoFYiIiobDCNU9novwG0zd/Q99gRSkPuqp8lpGgSFPMxxvpKVClXsrFC1kiWq2lnJ+052lvKrCCw/HLmV7yWI2TVERFSBwsiSJUvw3//+F2FhYWjRogW+/vpr+Pn56S37/fff48cff8S5c8oUylatWmHu3Lm5licTEPwHcHE70G+Jsl6ItT2C6o5DyrFT+T51dHtPdPd2yxI8LGFtocq1vBgL8ueFcNnVo81lzIibow386joV85siIqJSG8C6fv16TJkyBbNmzUJQUJAMIz179kRERITe8vv378eQIUOwb98+HDlyBLVq1UKPHj1w9+7dIl80VVBpKUDAdGW33VM/AWfWF7plQgQRMbajsZsDXB1s8gwigsrcDLP6eMv72ZdJSz8Wj4tyRERUNsy0Wm2het3btm2LNm3aYPHixfJYo9HIgDFp0iRMnTo13+er1WpUrVpVPn/EiBEFes/Y2Fg4OjoiJiYGDg5cqrtCenAT2DQauHtCOX5yItDto4y1Q5b/cx2f7riY69PTWzAOvt+lSMFB3zoj7o42MohkHRRLRESGU9DP70J106SkpODEiROYNm1axjlzc3N069ZNtnoURGJiIlJTU+HklHuzeHJysrxl/WaoAruwDfjtdSA5BrCpAvRfCjR+Vj4ksvCXf13B//ZcySguoobWwC0YInCIVpWsK7CKrhm2iBARlb1ChZGoqCjZsuHq6qpzXhxfunSpQK/x/vvvo0aNGjLA5GbevHmYPXt2YS6NyqsD/wX2farcr+kHDFwBVKmdMTX3498vYPXhm/L4nR4N4eVcWZ7L2oLhZqAWDBE8OH2XiMjEZ9N89tlnWLdunRxHYmOT+xgB0fIixqVkbRkRXUFUAdV7GjjwOeD/GtDlQ0ClzJZJVWvw/qYz+PWkMnbo435NMcLfU97v0ZQtGEREpqRQYaR69epQqVQIDw/XOS+O3dx014bIbv78+TKM/PXXX2jevHmeZa2treWNKqiHIRmtH6jVBngjKPMYQFKqGq//fBJ/XQyXrRULBrVA/yc8Mh5nCwYRkWkp1GwaKysrOTV3z549GefEAFZx7O/vn+vzvvjiC3zyyScICAhA69ati3fFVH6lPgJ+nwwsbgOEn888nyWIxCenYdSqf2UQsbYwx7fDWukEESIiMj2F7qYR3ScjR46UoUKsFbJo0SIkJCRg1KhR8nExQ8bDw0OO+xA+//xzzJw5Ez///DM8PT3l2iRC5cqV5Y2MRNQVYOPLQLhYT8YMuHUYcG2qUyQ6IQUvrwrEmTsxqGxtgeUjW+PJelyCnYjI1BU6jAwePBiRkZEyYIhg4evrK1s80ge1hoSEyBk26ZYuXSpn4QwcOFDndcQ6JR999JEhvgcqa2c2ANvfAlITgErOwHPfAV5ddIqIRceGrTiGqxHxqGpniR9G+6F5zSpldslERFSB1xkpC1xnpJxKSQT+eA84uUY59uwIPL8csNcdP3QzKgFDlx/D3YeP5Noea17xQ30X+7K5ZiIiqtjrjBDpECFEBhEz4OmpwFPvAua6K6JeuBeLESsDERWfDM9qdlg7pi1qVrVjRRIRUQaGESq6NmOAO/8CLUcAdZ/K8fCJW9FysGpsUhqauDvgx9F+cLbnLCkiIirm3jRkwpLjgX1zgdTHC5KJVhDRLaMniBy4HIlhywNlEGldpyrWjXuSQYSIiPRiywgVjJiqK2bLRF0GEqOB3vNzLbrjTCjeWn8SqWotOjV0xrJhrWBrlfeGdkREZLoYRihvYnxz0A/AH+8DaUmAvTvQdIB8SK3R5tjrZePx25i+5Sw0WqB3c3d8+YIvrCzYAEdERLljGKHcJccpU3bPbVKO63cHBiwDKlXXuwuuvY0F4pLS5P0hfrXxaX8fbkRHRET5Yhgh/SIuAuteAqKvA2YqoNsswH+S2KZZBpEJa4N0dtYV0oNID29XzB3gAzOzou2wS0REpoVhhPSzqqSMDXGoCQxaBdTyy+iaES0ieS1Oc/ZujOymUTGLEBFRATCMUKa0FMDCKnM/mZc2ANUbAHZOGUXEGJGsXTP6iMdFOX8vLvVORET548hCUtwNApb4AZd3ZdZI7bY6QUQQg1ULoqDliIiIGEZMnZgtc3QpsKIH8OAGsH+eci4XjraWBXpZMbuGiIioINhNY8oePQB+ex249Lty3KQP0HcxkMvA039vRmPmb2JX3tyJZ7o5KtN8iYiICoJhxFTd/hfYNBqICQFUVkDPucry7nqCSFKqGgv+DMbygzdko4nYdfdBYqoMHlnbUNKfOauPN6f0EhFRgTGMmKKoK8CqXoAmDahaFxi0Gqjhq7foqdsP8faGU7gWmSCPB7WqiQ/7eOPw1agc64yIFhERRHr5uJfat0JERBUfw4gpEjNkfF9S9prp8xVgk3Nb5+Q0Nf635wqW7r8mp+mKDe4+e64ZujZxlY+LwNHd2y3HCqwqc87nJSKiwmEYMRUhRwEnL6Cys3LceyFgbqG3W+b8vRi8veE0LoXFyeN+vjXwUZ+mqFrp8bTfx0Tw4PRdIiIqLoYRY6fRAIe+BPbOAep1AoZulquoQpVzVkyqWiNbQkSLSJpGC6dKVpjT3wfPNGO3CxERlRyGEWMWHwlseRW4tkc5tqsOqJMBc9scRS+Hx8nWELF6qtCrqRs+HeCD6pWtS/uqiYjIxDCMGKubB4FNrwDxYYCFLfDsf4EnhuXolhHLu3//z3Us/PMyUtQauY7Ix/2aom+LGtxbhoiISgXDiLHRqIG/5wMHPgO0GsC5sTJbxqVJjqLXI+PxzsbTCAp5KI87N3LGZ883h6sDFywjIqLSwzBibFIfAWfWKUHEdxjw7BfKpndZaDRa/HDkJj4PuISkVA0qW1tg5n+8Mah1TbaGEBFRqWMYMTbWlZWWkIiLQIsXczx8OzoR7246jaPXo+Vxh/rV8fnA5vCoknMcCRERUWlgGKno1GlKl0wlF6DtOOWUa3MEJtZExKm7Get/iOU/fgm8jTk7LiAhRQ1bSxWm926CYW1rszWEiIjKFMNIRRZ7D9g8Brh1CDC3BBr1QsAdyxwro7rYW8tZMRdCY+Wxn6cT/juoOepU0+2+ISIiKgsMIxXVlb+ALeOAxPuAVWW5kqoIIhPWBunsFyNExCXLm4W5GaY+0xij2tflSqlERFRuMIxUNOpUYO+nwKFFyrFbczlGRF21HmZ/vjdHEMlKrKDKIEJEROWNeVlfABVyNdUf+2cGkTZjgVd2A9W85B4xWbtm9ImMS5bliIiIyhO2jFQkYhn3Bt2BsDNA36+Bpv0zHhKb1RVEQcsRERGVFoaR8i4tBUiIABxrKsft3gCavwA41NApJmbNFERByxEREZUWdtOUZw9uAqt6AWueA1ISMltHsgURQUzfdXe0Qc49eBXivHhclCMiIipPGEbKq4vbgWVPAXdPKPvLRF7Ks7jK3Ayz+njL+9kDSfqxeFyUIyIiKk8YRsqbtGRg53vA+mFAcgxQsw0w/iDg0Srfp/byccfSYS3h5qjbFSOOxXnxOBERUXnDMSPlSfR1YOMoIPRU5viQrjMBlWWBX0IEju7ebnLWjBismr4CK1tEiIiovGIYKU92faAEEVsnYMAyoGHPIr2MCB7+XtUMfnlEREQlgWGkPOm9ADAzA575AnD0KOurISIiKhUcM1KWoq4Ah/6XeezgDrz4E4MIERGZFLaMlJUzG4DtbwGpCUBVT8C7b5ldChERUVliGCltKYnAH+8BJ9cox54dlRkzREREJophpDRFBgMbXwYiLiirf3R6H+j0HmCuKtXLICIiKk8YRkrL2U3AtklAaiJQ2RV47nugXqdSe3siIqLyimGk1GraRgki9Z5Wgkhll1J7ayIiovKMYaSkV1O1sFbuN/kPMOxXJYywW4aIiCgDp/aWBK0WOLEa+F9LIOZu5vn6XRlEiIiIsmEYMbTkOGDzGGD7m0DsHeD4CoO/BRERkTFhN40hhZ5RZstEXwPMVMq+MmJ/GSIiIsoVw4ihumVEC0jAdECdDDjUBAauBGq3NcjLExERGTOGEUM4sQrY8bZyv+EzQP9vADsng7w0ERGRsWMYMYTmLwLHVwEtXgSefE3Z7I6IiIgKhGGkqN0yF7cBjfsA5uaAlR0wdh+gYnUSEREVFmfTFNajB8D6YcCGEcChLzPPM4gQEREVCf+UL4w7x4GNo4CYEEBlBVg7FK3WiYiIKAPDSEG7ZY4sBv76CNCkAVXrAoNWATWeKNDTiYiIKHcMI/lJjAa2TgAuByjHTQcAfb4CbBzzfSoRERHlj2EkPzG3gWt7AZU18MxnQKtRnC1DRERkQAwj+XFvAfT7BnBpDLg1M2TdExEREWfT6BEfCfwyBLgblHmu+SAGESIiohLClpGsbh4ENr0CxIcBD24C4w8p64gQERFRiSnSJ+2SJUvg6ekJGxsbtG3bFoGBgXmW37hxIxo3bizLN2vWDDt37kS5olED+z8HfuijBJHqjYDnVzCIEBERlccwsn79ekyZMgWzZs1CUFAQWrRogZ49eyIiIkJv+cOHD2PIkCF45ZVXcPLkSfTv31/ezp07h3IhLhxY0x/YPxfQagDfocC4fYCrd1lfGRERkUkw02rFIhoFJ1pC2rRpg8WLF8tjjUaDWrVqYdKkSZg6dWqO8oMHD0ZCQgJ+//33jHNPPvkkfH19sWzZMr3vkZycLG/pYmNj5XvExMTAwcGAC42Jrpjl3YGECMDSDui9EPAdYrjXJyIiMmGxsbFwdHTM9/O7UC0jKSkpOHHiBLp165b5Aubm8vjIkSN6nyPOZy0viJaU3MoL8+bNkxeffhNBpEQ41lZmy7h4A+MOMIgQERGVgUKFkaioKKjVari6uuqcF8dhYWF6nyPOF6a8MG3aNJmi0m+3b99GiRCDU5//HhizB3BuWDLvQURERBVvNo21tbW8lQrbqqXzPkRERFT8lpHq1atDpVIhPDxc57w4dnNz0/sccb4w5YmIiMi0FCqMWFlZoVWrVtizZ0/GOTGAVRz7+/vrfY44n7W8sHv37lzLExERkWkpdDeNmNY7cuRItG7dGn5+fli0aJGcLTNq1Cj5+IgRI+Dh4SEHoQpvvvkmOnXqhAULFqB3795Yt24djh8/ju+++87w3w0REREZfxgRU3UjIyMxc+ZMOQhVTNENCAjIGKQaEhIiZ9ika9euHX7++Wd88MEHmD59Oho0aICtW7fCx8fHsN8JERERmcY6I+V5njIREREZ+TojRERERIbGMEJERERlimGEiIiIyhTDCBEREZUphhEiIiIqUwwjREREVKYYRoiIiKhMMYwQERFRmSqXu/Zml74um1g8hYiIiCqG9M/t/NZXrRBhJC4uTn6tVatWWV8KERERFeFzXKzEWqGXgxc7A9+7dw/29vYwMzMzaGITAef27dtcZr4EsZ5LD+ua9WxM+Ptc8etZRAwRRGrUqKGzb12FbBkR30DNmjVL7PVF5XPPm5LHei49rGvWszHh73PFrue8WkTScQArERERlSmGESIiIipTJh1GrK2tMWvWLPmVWM/GgL/TrGdjwt9n06nnCjGAlYiIiIyXSbeMEBERUdljGCEiIqIyxTBCREREZYphhIiIiMoUwwgRERGVKaMPI0uWLIGnpydsbGzQtm1bBAYG5ll+48aNaNy4sSzfrFkz7Ny5s9Su1VTq+fvvv0fHjh1RtWpVeevWrVu+PxcqWl1ntW7dOrmdQv/+/VmdBv6dFh4+fIiJEyfC3d1dTpFs2LAh//0ogXpetGgRGjVqBFtbW7mE+eTJk5GUlMTf6Tz8/fff6NOnj1ySXfwbsHXrVuRn//79aNmypfxdrl+/PlavXo0SpTVi69at01pZWWlXrlypPX/+vHbs2LHaKlWqaMPDw/WWP3TokFalUmm/+OIL7YULF7QffPCB1tLSUnv27NlSv3ZjrueXXnpJu2TJEu3Jkye1Fy9e1L788staR0dH7Z07d0r92o29rtPduHFD6+Hhoe3YsaO2X79+pXa9plLPycnJ2tatW2ufffZZ7cGDB2V979+/X3vq1KlSv3ZjrueffvpJa21tLb+KOt61a5fW3d1dO3ny5FK/9opk586d2hkzZmh//fVXsZSHdsuWLXmWv379utbOzk47ZcoU+Vn49ddfy8/GgICAErtGow4jfn5+2okTJ2Ycq9VqbY0aNbTz5s3TW/6FF17Q9u7dW+dc27Ztta+++mqJX6sp1XN2aWlpWnt7e+0PP/xQgldpunUt6rddu3ba5cuXa0eOHMkwUgL1vHTpUm29evW0KSkphfuBmrjC1rMo26VLF51z4gOzffv2JX6txgIFCCPvvfeetmnTpjrnBg8erO3Zs2eJXZfRdtOkpKTgxIkTsgsg64Z74vjIkSN6nyPOZy0v9OzZM9fyVLR6zi4xMRGpqalwcnJilRr4d1r4+OOP4eLigldeeYX1W0L1vG3bNvj7+8tuGldXV/j4+GDu3LlQq9WscwPWc7t27eRz0rtyrl+/LrvCnn32WdazAZXFZ2GF2LW3KKKiouQ/BOIfhqzE8aVLl/Q+JywsTG95cZ4MV8/Zvf/++7IvM/svPxW/rg8ePIgVK1bg1KlTrM4SrGfxobh3714MHTpUfjhevXoVr732mgzZYpltMkw9v/TSS/J5HTp0kFvTp6WlYfz48Zg+fTqr2IBy+yyMjY3Fo0eP5HgdQzPalhGqGD777DM5sHLLli1yABsZTlxcHIYPHy4HDFevXp1VW4I0Go1sffruu+/QqlUrDB48GDNmzMCyZctY7wYkBlWKFqdvvvkGQUFB+PXXX7Fjxw588sknrOcKzmhbRsQ/viqVCuHh4TrnxbGbm5ve54jzhSlPRavndPPnz5dh5K+//kLz5s1ZnQb+nb527Rpu3rwpR9Fn/dAULCwsEBwcDC8vL9Z7MetZEDNoLC0t5fPSNWnSRP6FKbojrKysWM8GqOcPP/xQBuwxY8bIYzHjMSEhAePGjZPhT3TzUPHl9lno4OBQIq0igtH+5MT//OIvlD179uj8QyyORd+uPuJ81vLC7t27cy1PRatn4YsvvpB/zQQEBKB169asyhL4nRZT1M+ePSu7aNJvffv2RefOneV9MS2Sil/PQvv27WXXTHrYEy5fvixDCoOIYX6f08eXZQ8c6QGQe74aTpl8FmqNfNqYmAa2evVqOT1p3LhxctpYWFiYfHz48OHaqVOn6kzttbCw0M6fP19OOZ01axan9pZAPX/22WdyOt+mTZu0oaGhGbe4uDjD/xKYeF1nx9k0JVPPISEhckbY66+/rg0ODtb+/vvvWhcXF+2nn35azJ+4cStsPYt/k0U9//LLL3L66Z9//qn18vKSMyEpd+LfVrGUgriJj/2FCxfK+7du3ZKPizoWdZ19au+7774rPwvFUgyc2ltMYn507dq15YefmEZ29OjRjMc6deok/3HOasOGDdqGDRvK8mJq044dO4p7CSahMPVcp04d+T9E9pv4h4YMW9fZMYyUzO+0cPjwYbkUgPhwFdN858yZI6dVk+HqOTU1VfvRRx/JAGJjY6OtVauW9rXXXtM+ePCA1ZyHffv26f03N71uxVdR19mf4+vrK38u4vd51apV2pJkJv5Tcu0uRERERCY6ZoSIiIgqBoYRIiIiKlMMI0RERFSmGEaIiIioTDGMEBERUZliGCEiIqIyxTBCREREZYphhIiIiMoUwwgRERGVKYYRIiIiKlMMI0RERISy9H+VG7+W6E9jOQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_te, p_cal_te, n_bins=20)\n",
    "plt.plot(prob_pred, prob_true, 'o-')\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.title('Reliability Diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2af3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving Initial Elo states\n",
    "\"\"\"\n",
    "\n",
    "from importlib import reload\n",
    "import utils \n",
    "from datetime import datetime\n",
    "reload(utils)\n",
    "from utils import SeasonState, save_state\n",
    "\n",
    "elos_25 = {}\n",
    "\n",
    "for team, rating in elos.items():\n",
    "    elos_25[team] = alpha_star * rating + (1-alpha_star) * 1500\n",
    "\n",
    "elo_params = {\n",
    "    'K' : K,\n",
    "    'HCA' : HCA\n",
    "}\n",
    "\n",
    "state = SeasonState(\n",
    "    season=\"2025-26\",\n",
    "    last_updated=datetime.now(),\n",
    "    init_elo=elos_25,\n",
    "    params={\"K\": K_star, \"HCA\": HCA_star, \"scale\": scale_star}\n",
    ")\n",
    "\n",
    "save_state(state, \"../states/2025-26_season_state.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c7f3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model, theta, diag = train_calibrated_model(model, X, y,\n",
    "     splitter=TimeSeriesSplit(n_splits=6, test_size=max(200, int(0.15*len(X))), gap=0),\n",
    "     reg_lambda=1e-3, bundle_path=\"../models/elo_model_ensemble_prod.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c884d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
