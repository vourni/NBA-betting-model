{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5c41ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Downloading data\n",
    "\"\"\"\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "years = range(1, 26)\n",
    "seasons = [f\"20{i:02d}-{(i+1)%100:02d}\" for i in years]\n",
    "\n",
    "to_merge = []\n",
    "for s in seasons:\n",
    "    time.sleep(1)\n",
    "    finder = leaguegamefinder.LeagueGameFinder(\n",
    "        season_nullable=s,\n",
    "        season_type_nullable=\"Regular Season\",\n",
    "        league_id_nullable='00'\n",
    "    )\n",
    "\n",
    "    game_df = finder.get_data_frames()[0]\n",
    "    to_merge.append(game_df)\n",
    "\n",
    "games_df = pd.concat(to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "purged_group_split",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Time-aware splitter that purges a gap between train and validation groups.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "class PurgedGroupTimeSeriesSplit:\n",
    "    \"\"\"Drop-in replacement for TimeSeriesSplit with group-aware purging.\"\"\"\n",
    "    def __init__(self, n_splits=5, *, group_gap=1, max_train_group_size=None, test_group_size=None):\n",
    "        if n_splits < 2:\n",
    "            raise ValueError(\"n_splits must be at least 2\")\n",
    "        self.n_splits = n_splits\n",
    "        self.group_gap = int(group_gap)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.test_group_size = test_group_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\"PurgedGroupTimeSeriesSplit requires 'groups' (e.g. normalized dates)\")\n",
    "        groups = np.asarray(groups)\n",
    "        unique, first_idx = np.unique(groups, return_index=True)\n",
    "        order = np.argsort(first_idx)\n",
    "        unique_groups = unique[order]\n",
    "        group_to_pos = {g: i for i, g in enumerate(unique_groups)}\n",
    "        group_ids = np.fromiter((group_to_pos[g] for g in groups), dtype=int, count=len(groups))\n",
    "        n_groups = len(unique_groups)\n",
    "        if self.n_splits >= n_groups:\n",
    "            raise ValueError(\"Too few unique groups for the requested number of splits\")\n",
    "\n",
    "        test_size = self.test_group_size or max(1, n_groups // (self.n_splits + 1))\n",
    "\n",
    "        for fold in range(self.n_splits):\n",
    "            test_start = n_groups - (self.n_splits - fold) * test_size\n",
    "            test_end = min(test_start + test_size, n_groups)\n",
    "            if test_start <= 0:\n",
    "                continue\n",
    "            train_end = max(0, test_start - self.group_gap)\n",
    "            if self.max_train_group_size is not None:\n",
    "                train_start = max(0, train_end - int(self.max_train_group_size))\n",
    "            else:\n",
    "                train_start = 0\n",
    "\n",
    "            train_mask = (group_ids >= train_start) & (group_ids < train_end)\n",
    "            val_mask = (group_ids >= test_start) & (group_ids < test_end)\n",
    "            train_idx = np.flatnonzero(train_mask)\n",
    "            val_idx = np.flatnonzero(val_mask)\n",
    "            if len(train_idx) == 0 or len(val_idx) == 0:\n",
    "                continue\n",
    "            yield train_idx, val_idx\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14763311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sid', 'team_home', 'date', 'MIN_home', 'score_home', 'FGM_home',\n",
      "       'FGA_home', 'FG_PCT_home', 'FG3M_home', 'FG3A_home', 'FG3_PCT_home',\n",
      "       'FTM_home', 'FTA_home', 'FT_PCT_home', 'OREB_home', 'DREB_home',\n",
      "       'REB_home', 'AST_home', 'STL_home', 'BLK_home', 'TOV_home', 'PF_home',\n",
      "       'PLUS_MINUS_home', 'SEASON_ID_away', 'team_away', 'GAME_DATE_away',\n",
      "       'MIN_away', 'score_away', 'FGM_away', 'FGA_away', 'FG_PCT_away',\n",
      "       'FG3M_away', 'FG3A_away', 'FG3_PCT_away', 'FTM_away', 'FTA_away',\n",
      "       'FT_PCT_away', 'OREB_away', 'DREB_away', 'REB_away', 'AST_away',\n",
      "       'STL_away', 'BLK_away', 'TOV_away', 'PF_away', 'PLUS_MINUS_away',\n",
      "       'win_home', 'margin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>team_home</th>\n",
       "      <th>date</th>\n",
       "      <th>MIN_home</th>\n",
       "      <th>score_home</th>\n",
       "      <th>FGM_home</th>\n",
       "      <th>FGA_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FG3M_home</th>\n",
       "      <th>FG3A_home</th>\n",
       "      <th>...</th>\n",
       "      <th>DREB_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>STL_away</th>\n",
       "      <th>BLK_away</th>\n",
       "      <th>TOV_away</th>\n",
       "      <th>PF_away</th>\n",
       "      <th>PLUS_MINUS_away</th>\n",
       "      <th>win_home</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22001</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>239</td>\n",
       "      <td>93</td>\n",
       "      <td>32</td>\n",
       "      <td>75</td>\n",
       "      <td>0.427</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001</td>\n",
       "      <td>MIN</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>239</td>\n",
       "      <td>83</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>0.420</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22001</td>\n",
       "      <td>UTA</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>264</td>\n",
       "      <td>112</td>\n",
       "      <td>43</td>\n",
       "      <td>81</td>\n",
       "      <td>0.531</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22001</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>240</td>\n",
       "      <td>89</td>\n",
       "      <td>39</td>\n",
       "      <td>90</td>\n",
       "      <td>0.433</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22001</td>\n",
       "      <td>SAS</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>240</td>\n",
       "      <td>109</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "      <td>0.463</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28933</th>\n",
       "      <td>22025</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>127</td>\n",
       "      <td>40</td>\n",
       "      <td>72</td>\n",
       "      <td>0.556</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28934</th>\n",
       "      <td>22025</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>118</td>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>0.494</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28935</th>\n",
       "      <td>22025</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>241</td>\n",
       "      <td>128</td>\n",
       "      <td>44</td>\n",
       "      <td>91</td>\n",
       "      <td>0.484</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28936</th>\n",
       "      <td>22025</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>116</td>\n",
       "      <td>43</td>\n",
       "      <td>90</td>\n",
       "      <td>0.478</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28937</th>\n",
       "      <td>22025</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>242</td>\n",
       "      <td>107</td>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>0.413</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28938 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid team_home       date  MIN_home  score_home  FGM_home  FGA_home  \\\n",
       "0      22001       NYK 2001-10-30       239          93        32        75   \n",
       "1      22001       MIN 2001-10-30       239          83        34        81   \n",
       "2      22001       UTA 2001-10-30       264         112        43        81   \n",
       "3      22001       CLE 2001-10-30       240          89        39        90   \n",
       "4      22001       SAS 2001-10-30       240         109        37        80   \n",
       "...      ...       ...        ...       ...         ...       ...       ...   \n",
       "28933  22025       ATL 2025-11-04       240         127        40        72   \n",
       "28934  22025       GSW 2025-11-04       240         118        41        83   \n",
       "28935  22025       TOR 2025-11-04       241         128        44        91   \n",
       "28936  22025       NOP 2025-11-04       240         116        43        90   \n",
       "28937  22025       LAC 2025-11-04       242         107        33        80   \n",
       "\n",
       "       FG_PCT_home  FG3M_home  FG3A_home  ...  DREB_away  REB_away  AST_away  \\\n",
       "0            0.427          6         20  ...         30        39        23   \n",
       "1            0.420          3          9  ...         26        41        16   \n",
       "2            0.531          5         16  ...         21        31        25   \n",
       "3            0.433          3         17  ...         38        48        24   \n",
       "4            0.463         11         24  ...         31        42         9   \n",
       "...            ...        ...        ...  ...        ...       ...       ...   \n",
       "28933        0.556         13         30  ...         27        41        26   \n",
       "28934        0.494         19         42  ...         30        46        25   \n",
       "28935        0.484         17         38  ...         32        41        26   \n",
       "28936        0.478         17         38  ...         34        49        20   \n",
       "28937        0.413         18         43  ...         32        40        28   \n",
       "\n",
       "       STL_away  BLK_away  TOV_away  PF_away  PLUS_MINUS_away  win_home  \\\n",
       "0            11         4        14       27             -2.0         1   \n",
       "1             4         6        18       20             -9.0         1   \n",
       "2            11         3        13       28              7.0         0   \n",
       "3             6         2        14       14             19.0         0   \n",
       "4            11         3        18       31            -11.0         1   \n",
       "...         ...       ...       ...      ...              ...       ...   \n",
       "28933         9         1        17       30            -15.0         1   \n",
       "28934        10         5        17       17            -11.0         1   \n",
       "28935         5         4        12       26            -28.0         1   \n",
       "28936         8         6        19       23             -4.0         1   \n",
       "28937        12         6        10       23             19.0         0   \n",
       "\n",
       "       margin  \n",
       "0           2  \n",
       "1           9  \n",
       "2          -7  \n",
       "3         -19  \n",
       "4          11  \n",
       "...       ...  \n",
       "28933      15  \n",
       "28934      11  \n",
       "28935      28  \n",
       "28936       4  \n",
       "28937     -19  \n",
       "\n",
       "[28938 rows x 48 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Merging games into single rows\n",
    "\"\"\"\n",
    "\n",
    "def merge_games(df):\n",
    "    df['HOME'] = df['MATCHUP'].str.contains('vs.') \n",
    "    home_df = df[df['HOME']].copy()\n",
    "    away_df = df[~df['HOME']].copy()\n",
    "\n",
    "    merged = home_df.merge(\n",
    "        away_df,\n",
    "        on='GAME_ID',\n",
    "        suffixes=('_home', '_away')\n",
    "    )\n",
    "    merged = merged.rename(columns={\n",
    "        'SEASON_ID_home' : 'sid',\n",
    "        'GAME_DATE_home': 'date',\n",
    "        'TEAM_ABBREVIATION_home': 'team_home',\n",
    "        'TEAM_ABBREVIATION_away': 'team_away',\n",
    "        'PTS_home': 'score_home',\n",
    "        'PTS_away': 'score_away'\n",
    "    })\n",
    "\n",
    "    merged[\"win_home\"] = (merged[\"score_home\"] > merged[\"score_away\"]).astype(int)\n",
    "    merged['margin'] = (merged['score_home'] - merged['score_away'])\n",
    "\n",
    "    merged['date'] = pd.to_datetime(merged['date'])\n",
    "    merged = merged.sort_values('date').reset_index(drop=True)\n",
    "    drop_cols = [\n",
    "    'TEAM_ID_home', 'TEAM_ID_away', 'TEAM_NAME_home', 'TEAM_NAME_away',\n",
    "    'MATCHUP_home', 'MATCHUP_away', 'GAME_ID',\n",
    "    'WL_home', 'WL_away', 'HOME_home', 'HOME_away']\n",
    "    merged.drop(drop_cols, axis=1, inplace=True)\n",
    "    return merged\n",
    "\n",
    "games_df = merge_games(games_df)\n",
    "print(games_df.columns)\n",
    "games_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20ffa8e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     72\u001b[39m train_df = games_df.loc[tr_idx].sort_values(\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# a reasonable HCA starting guess from your earlier empirical calc\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m K_star, HCA_star, alpha_star, scale_star = \u001b[43mfit_elo_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK0\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHCA0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHCA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha0\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.55\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale0\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400.0\u001b[39;49m\n\u001b[32m     77\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLearned params:\u001b[39m\u001b[33m\"\u001b[39m, K_star, HCA_star, alpha_star, scale_star)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mfit_elo_params\u001b[39m\u001b[34m(games_train, K0, HCA0, alpha0, scale0)\u001b[39m\n\u001b[32m     64\u001b[39m     K, HCA, alpha, scale = x\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _elo_logloss_for_params(games_train, K, HCA, alpha, scale)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m res = \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m K, HCA, alpha, scale = res.x\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(K), \u001b[38;5;28mfloat\u001b[39m(HCA), \u001b[38;5;28mfloat\u001b[39m(alpha), \u001b[38;5;28mfloat\u001b[39m(scale)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/scipy/optimize/_minimize.py:784\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    781\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    782\u001b[39m                              **options)\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    787\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    788\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/scipy/optimize/_lbfgsb_py.py:469\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    461\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    472\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:404\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m    403\u001b[39m \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:366\u001b[39m, in \u001b[36mScalarFunction._update_grad\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._orig_grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28mself\u001b[39m.g = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[38;5;28mself\u001b[39m.g_updated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:41\u001b[39m, in \u001b[36m_ScalarGradWrapper.__call__\u001b[39m\u001b[34m(self, x, f0, **kwds)\u001b[39m\n\u001b[32m     39\u001b[39m     g = np.atleast_1d(\u001b[38;5;28mself\u001b[39m.grad(np.copy(x), *\u001b[38;5;28mself\u001b[39m.args))\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     g, dct = \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += dct[\u001b[33m'\u001b[39m\u001b[33mnfev\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.ngev += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/scipy/optimize/_numdiff.py:593\u001b[39m, in \u001b[36mapprox_derivative\u001b[39m\u001b[34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs, full_output, workers)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m MapWrapper(workers) \u001b[38;5;28;01mas\u001b[39;00m mf:\n\u001b[32m    592\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m         J, _nfev = \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    597\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/scipy/optimize/_numdiff.py:686\u001b[39m, in \u001b[36m_dense_difference\u001b[39m\u001b[34m(fun, x0, f0, h, use_one_sided, method, workers)\u001b[39m\n\u001b[32m    684\u001b[39m f_evals = workers(fun, x_generator2(x0, h))\n\u001b[32m    685\u001b[39m dx = [(x0[i] + h[i]) - x0[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n)]\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m df = \u001b[43m[\u001b[49m\u001b[43mf_eval\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf_eval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf_evals\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    687\u001b[39m df_dx = [delf / delx \u001b[38;5;28;01mfor\u001b[39;00m delf, delx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df, dx)]\n\u001b[32m    688\u001b[39m nfev += \u001b[38;5;28mlen\u001b[39m(df_dx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/scipy/optimize/_numdiff.py:879\u001b[39m, in \u001b[36m_Fun_Wrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xp.isdtype(x.dtype, \u001b[33m\"\u001b[39m\u001b[33mreal floating\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    877\u001b[39m     x = xp.astype(x, \u001b[38;5;28mself\u001b[39m.x0.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m f = np.atleast_1d(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`fun` return value has \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    882\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mmore than 1 dimension.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/scipy/_lib/_util.py:590\u001b[39m, in \u001b[36m_ScalarFunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    588\u001b[39m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    589\u001b[39m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m     fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    593\u001b[39m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mfit_elo_params.<locals>.objective\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(x):\n\u001b[32m     64\u001b[39m     K, HCA, alpha, scale = x\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_elo_logloss_for_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgames_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHCA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36m_elo_logloss_for_params\u001b[39m\u001b[34m(games_df, K, HCA, alpha, scale)\u001b[39m\n\u001b[32m     22\u001b[39m prev_sid = \u001b[38;5;28mobject\u001b[39m()\n\u001b[32m     23\u001b[39m nll = \u001b[32m0.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgames_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# season reset (shrink to mean)\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_sid\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melo\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/pandas/core/frame.py:1563\u001b[39m, in \u001b[36mDataFrame.iterrows\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1561\u001b[39m using_cow = using_copy_on_write()\n\u001b[32m   1562\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.index, \u001b[38;5;28mself\u001b[39m.values):\n\u001b[32m-> \u001b[39m\u001b[32m1563\u001b[39m     s = \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1564\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mgr.is_single_block:\n\u001b[32m   1565\u001b[39m         s._mgr.add_references(\u001b[38;5;28mself\u001b[39m._mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/pandas/core/series.py:591\u001b[39m, in \u001b[36mSeries.__init__\u001b[39m\u001b[34m(self, data, index, dtype, name, copy, fastpath)\u001b[39m\n\u001b[32m    589\u001b[39m manager = _get_option(\u001b[33m\"\u001b[39m\u001b[33mmode.data_manager\u001b[39m\u001b[33m\"\u001b[39m, silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    590\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m     data = \u001b[43mSingleBlockManager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    593\u001b[39m     data = SingleArrayManager.from_array(data, index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:1892\u001b[39m, in \u001b[36mSingleBlockManager.from_array\u001b[39m\u001b[34m(cls, array, index, refs)\u001b[39m\n\u001b[32m   1890\u001b[39m bp = BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(index)))\n\u001b[32m   1891\u001b[39m block = new_block(array, placement=bp, ndim=\u001b[32m1\u001b[39m, refs=refs)\n\u001b[32m-> \u001b[39m\u001b[32m1892\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "EPS = 1e-12\n",
    "\n",
    "games_sorted = games_df.sort_values(\"date\").reset_index(drop=False)\n",
    "cut1 = games_sorted[\"date\"].quantile(0.8)\n",
    "tr_idx = games_sorted.loc[games_sorted[\"date\"] < cut1, \"index\"].to_numpy()\n",
    "\n",
    "p_home = (games_df[\"win_home\"] == 1).mean()\n",
    "HCA = 400 * math.log10(p_home / (1 - p_home))\n",
    "\n",
    "def _elo_logloss_for_params(games_df, K, HCA, alpha, scale=400.0):\n",
    "    \"\"\"\n",
    "    Compute total negative log-likelihood for given Elo params on a chronologically\n",
    "    ordered DataFrame with columns: sid, date, team_home, team_away, score_home, score_away.\n",
    "    \"\"\"\n",
    "    teams = pd.unique(games_df[['team_home','team_away']].values.ravel())\n",
    "    elo = {t: 1500.0 for t in teams}\n",
    "    prev_sid = object()\n",
    "    nll = 0.0\n",
    "\n",
    "    for _, r in games_df.iterrows():\n",
    "        # season reset (shrink to mean)\n",
    "        if r['sid'] != prev_sid:\n",
    "            for t in elo:\n",
    "                elo[t] = alpha * elo[t] + (1.0 - alpha) * 1500.0\n",
    "\n",
    "        Ra, Rb = elo[r.team_home], elo[r.team_away]\n",
    "\n",
    "        # probability of home win using learned scale (400 by default)\n",
    "        # elo_diff = Ra - Rb + HCA\n",
    "        Ea = 1.0 / (1.0 + 10.0 ** ((Rb - (Ra + HCA)) / scale))\n",
    "\n",
    "        y = 1.0 if r.score_home > r.score_away else 0.0\n",
    "        nll += -(y * np.log(Ea + EPS) + (1 - y) * np.log(1 - Ea + EPS))\n",
    "\n",
    "        # update ratings with margin-of-victory multiplier\n",
    "        margin = abs(r.score_home - r.score_away)\n",
    "        mult = np.log1p(margin) * 2.2 / ((Ra+HCA - Rb) * 0.001 + 2.2)\n",
    "        delta = K * mult * (y - Ea)\n",
    "\n",
    "        elo[r.team_home] = Ra + delta\n",
    "        elo[r.team_away] = Rb - delta\n",
    "        prev_sid = r['sid']\n",
    "\n",
    "    return nll\n",
    "\n",
    "def fit_elo_params(games_train, K0=20.0, HCA0=60.0, alpha0=0.55, scale0=400.0):\n",
    "    \"\"\"\n",
    "    Learn K, HCA, alpha (season reset), and scale by ML on the TRAIN window only.\n",
    "    games_train must be chronologically sorted.\n",
    "    \"\"\"\n",
    "    bounds = [(5.0, 80.0),     # K\n",
    "              (0.0, 120.0),    # HCA (Elo points)\n",
    "              (0.20, 0.95),    # alpha (keep some shrink)\n",
    "              (250.0, 550.0)]  # scale in the Elo->prob sigmoid (400 standard)\n",
    "\n",
    "    x0 = np.array([K0, HCA0, alpha0, scale0], dtype=float)\n",
    "\n",
    "    def objective(x):\n",
    "        K, HCA, alpha, scale = x\n",
    "        return _elo_logloss_for_params(games_train, K, HCA, alpha, scale)\n",
    "\n",
    "    res = minimize(objective, x0=x0, method=\"L-BFGS-B\", bounds=bounds)\n",
    "    K, HCA, alpha, scale = res.x\n",
    "    return float(K), float(HCA), float(alpha), float(scale)\n",
    "\n",
    "# build the TRAIN slice and ensure chronological order\n",
    "train_df = games_df.loc[tr_idx].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# a reasonable HCA starting guess from your earlier empirical calc\n",
    "K_star, HCA_star, alpha_star, scale_star = fit_elo_params(\n",
    "    train_df, K0=20.0, HCA0=HCA, alpha0=0.55, scale0=400.0\n",
    ")\n",
    "print(\"Learned params:\", K_star, HCA_star, alpha_star, scale_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5936cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>team_home</th>\n",
       "      <th>date</th>\n",
       "      <th>MIN_home</th>\n",
       "      <th>score_home</th>\n",
       "      <th>FGM_home</th>\n",
       "      <th>FGA_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FG3M_home</th>\n",
       "      <th>FG3A_home</th>\n",
       "      <th>...</th>\n",
       "      <th>TOV_away</th>\n",
       "      <th>PF_away</th>\n",
       "      <th>PLUS_MINUS_away</th>\n",
       "      <th>win_home</th>\n",
       "      <th>margin</th>\n",
       "      <th>elo_pre_home</th>\n",
       "      <th>elo_pre_away</th>\n",
       "      <th>elo_post_home</th>\n",
       "      <th>elo_post_away</th>\n",
       "      <th>elo_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22001</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>239</td>\n",
       "      <td>93</td>\n",
       "      <td>32</td>\n",
       "      <td>75</td>\n",
       "      <td>0.427</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1504.035469</td>\n",
       "      <td>1495.964531</td>\n",
       "      <td>75.917651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001</td>\n",
       "      <td>MIN</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>239</td>\n",
       "      <td>83</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>0.420</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1508.457953</td>\n",
       "      <td>1491.542047</td>\n",
       "      <td>75.917651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22001</td>\n",
       "      <td>UTA</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>264</td>\n",
       "      <td>112</td>\n",
       "      <td>43</td>\n",
       "      <td>81</td>\n",
       "      <td>0.531</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1488.175682</td>\n",
       "      <td>1511.824318</td>\n",
       "      <td>75.917651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22001</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>240</td>\n",
       "      <td>89</td>\n",
       "      <td>39</td>\n",
       "      <td>90</td>\n",
       "      <td>0.433</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1482.965383</td>\n",
       "      <td>1517.034617</td>\n",
       "      <td>75.917651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22001</td>\n",
       "      <td>SAS</td>\n",
       "      <td>2001-10-30</td>\n",
       "      <td>240</td>\n",
       "      <td>109</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "      <td>0.463</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1509.127665</td>\n",
       "      <td>1490.872335</td>\n",
       "      <td>75.917651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28933</th>\n",
       "      <td>22025</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>241</td>\n",
       "      <td>128</td>\n",
       "      <td>44</td>\n",
       "      <td>91</td>\n",
       "      <td>0.484</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1449.149385</td>\n",
       "      <td>1577.107186</td>\n",
       "      <td>1468.328494</td>\n",
       "      <td>1557.928077</td>\n",
       "      <td>-52.040150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28934</th>\n",
       "      <td>22025</td>\n",
       "      <td>CHI</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>113</td>\n",
       "      <td>42</td>\n",
       "      <td>89</td>\n",
       "      <td>0.472</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1542.823145</td>\n",
       "      <td>1427.068849</td>\n",
       "      <td>1545.260822</td>\n",
       "      <td>1424.631172</td>\n",
       "      <td>191.671948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28935</th>\n",
       "      <td>22025</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>242</td>\n",
       "      <td>107</td>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>0.413</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>1563.195444</td>\n",
       "      <td>1691.366159</td>\n",
       "      <td>1550.556904</td>\n",
       "      <td>1704.004699</td>\n",
       "      <td>-52.253064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28936</th>\n",
       "      <td>22025</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>118</td>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>0.494</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1566.505744</td>\n",
       "      <td>1464.445835</td>\n",
       "      <td>1572.385845</td>\n",
       "      <td>1458.565734</td>\n",
       "      <td>177.977560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28937</th>\n",
       "      <td>22025</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>127</td>\n",
       "      <td>40</td>\n",
       "      <td>72</td>\n",
       "      <td>0.556</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1486.865208</td>\n",
       "      <td>1491.732552</td>\n",
       "      <td>1497.245662</td>\n",
       "      <td>1481.352099</td>\n",
       "      <td>71.050307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28938 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid team_home       date  MIN_home  score_home  FGM_home  FGA_home  \\\n",
       "0      22001       NYK 2001-10-30       239          93        32        75   \n",
       "1      22001       MIN 2001-10-30       239          83        34        81   \n",
       "2      22001       UTA 2001-10-30       264         112        43        81   \n",
       "3      22001       CLE 2001-10-30       240          89        39        90   \n",
       "4      22001       SAS 2001-10-30       240         109        37        80   \n",
       "...      ...       ...        ...       ...         ...       ...       ...   \n",
       "28933  22025       TOR 2025-11-04       241         128        44        91   \n",
       "28934  22025       CHI 2025-11-04       240         113        42        89   \n",
       "28935  22025       LAC 2025-11-04       242         107        33        80   \n",
       "28936  22025       GSW 2025-11-04       240         118        41        83   \n",
       "28937  22025       ATL 2025-11-04       240         127        40        72   \n",
       "\n",
       "       FG_PCT_home  FG3M_home  FG3A_home  ...  TOV_away  PF_away  \\\n",
       "0            0.427          6         20  ...        14       27   \n",
       "1            0.420          3          9  ...        18       20   \n",
       "2            0.531          5         16  ...        13       28   \n",
       "3            0.433          3         17  ...        14       14   \n",
       "4            0.463         11         24  ...        18       31   \n",
       "...            ...        ...        ...  ...       ...      ...   \n",
       "28933        0.484         17         38  ...        12       26   \n",
       "28934        0.472         13         34  ...        16       21   \n",
       "28935        0.413         18         43  ...        10       23   \n",
       "28936        0.494         19         42  ...        17       17   \n",
       "28937        0.556         13         30  ...        17       30   \n",
       "\n",
       "       PLUS_MINUS_away  win_home  margin  elo_pre_home  elo_pre_away  \\\n",
       "0                 -2.0         1       2   1500.000000   1500.000000   \n",
       "1                 -9.0         1       9   1500.000000   1500.000000   \n",
       "2                  7.0         0      -7   1500.000000   1500.000000   \n",
       "3                 19.0         0     -19   1500.000000   1500.000000   \n",
       "4                -11.0         1      11   1500.000000   1500.000000   \n",
       "...                ...       ...     ...           ...           ...   \n",
       "28933            -28.0         1      28   1449.149385   1577.107186   \n",
       "28934             -2.0         1       2   1542.823145   1427.068849   \n",
       "28935             19.0         0     -19   1563.195444   1691.366159   \n",
       "28936            -11.0         1      11   1566.505744   1464.445835   \n",
       "28937            -15.0         1      15   1486.865208   1491.732552   \n",
       "\n",
       "       elo_post_home  elo_post_away    elo_diff  \n",
       "0        1504.035469    1495.964531   75.917651  \n",
       "1        1508.457953    1491.542047   75.917651  \n",
       "2        1488.175682    1511.824318   75.917651  \n",
       "3        1482.965383    1517.034617   75.917651  \n",
       "4        1509.127665    1490.872335   75.917651  \n",
       "...              ...            ...         ...  \n",
       "28933    1468.328494    1557.928077  -52.040150  \n",
       "28934    1545.260822    1424.631172  191.671948  \n",
       "28935    1550.556904    1704.004699  -52.253064  \n",
       "28936    1572.385845    1458.565734  177.977560  \n",
       "28937    1497.245662    1481.352099   71.050307  \n",
       "\n",
       "[28938 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Updating Elos\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "p_home = (games_df[\"win_home\"] == 1).mean()\n",
    "HCA = 400 * math.log10(p_home / (1 - p_home))\n",
    "K = 20\n",
    "\n",
    "\n",
    "def update_elo(games_df, K=K, HCA=HCA, alpha=0.55, scale=400):\n",
    "    elo = {team: 1500 for team in pd.unique(games_df[['team_home', 'team_away']].values.ravel())}\n",
    "    records = []\n",
    "\n",
    "    prev_sid = object() \n",
    "    for idx, row in games_df.iterrows():\n",
    "        if row['sid'] != prev_sid:\n",
    "            for team, rating in elo.items():\n",
    "                elo[team] = alpha * rating + (1-alpha)* 1500\n",
    "\n",
    "        home, away = row['team_home'], row['team_away']\n",
    "        score_home, score_away = row['score_home'], row['score_away']\n",
    "        win_home = 1 if score_home > score_away else 0\n",
    "\n",
    "        Ra, Rb = elo[home], elo[away]\n",
    "        Ea = 1 / (1 + 10 ** ((Rb - (Ra + HCA)) / scale))\n",
    "        margin = abs(score_home - score_away)\n",
    "        mult = np.log1p(margin) * 2.2 / ((Ra+HCA - Rb) * 0.001 + 2.2)\n",
    "        delta = K * mult * (win_home - Ea)\n",
    "\n",
    "        elo[home] += delta\n",
    "        elo[away] -= delta\n",
    "\n",
    "        games_df.loc[idx, 'elo_pre_home'] = Ra\n",
    "        games_df.loc[idx, 'elo_pre_away'] = Rb\n",
    "        games_df.loc[idx, 'elo_post_home'] = elo[home]\n",
    "        games_df.loc[idx, 'elo_post_away'] = elo[away]\n",
    "\n",
    "        prev_sid = row['sid']\n",
    "\n",
    "    games_df['elo_diff'] = games_df['elo_pre_home'] - games_df['elo_pre_away'] + HCA\n",
    "\n",
    "    return elo\n",
    "\n",
    "elos = update_elo(games_df, K_star, HCA_star, alpha_star, scale_star)\n",
    "games_df.reset_index(drop=True, inplace=True)\n",
    "games_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0ae6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  logs = logs.groupby([\"team\",\"sid\"], group_keys=False).apply(_streak_from_prev)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:185: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  logs = logs.groupby([\"team\",\"sid\"], group_keys=False).apply(_elo_roll)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:257: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(**{f\"{b}_prev\": g[b].shift(1) for b in bases}))\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:263: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(**{\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:263: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(**{\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:312: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"rest_diff\"]          = out[\"rest_h\"] - out[\"rest_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:313: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"rw_pct_diff\"]        = out[\"rw_pct_h\"] - out[\"rw_pct_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"streak_diff\"]        = out[\"streak_h\"] - out[\"streak_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:315: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"spdiff_diff\"]        = out[\"spdiff_h\"] - out[\"spdiff_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"off_eff_diff\"]       = out[\"off_eff_h\"] - out[\"off_eff_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:317: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"def_eff_diff\"]       = out[\"def_eff_h\"] - out[\"def_eff_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:318: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['off_def_rtg_diff']   = out['off_rtg_h'] - out['def_rtg_a']\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:319: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['def_off_rtg_diff']   = out['def_rtg_h'] - out['off_rtg_a']\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:320: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"net_off_diff\"]       = out[\"off_eff_h\"] - out[\"def_eff_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:321: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"net_def_diff\"]       = out[\"def_eff_h\"] - out[\"off_eff_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:322: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"hvenue_winpct_diff\"] = out[\"home_win_pct_h\"] - out[\"away_win_pct_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:323: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"hvenue_pdiff_diff\"]  = out[\"home_point_diff_h\"] - out[\"away_point_diff_a\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:324: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"b2b_home\"] = (out[\"rest_h\"] == 0).astype(int)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:325: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"b2b_away\"] = (out[\"rest_a\"] == 0).astype(int)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:328: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"elo_pre_ma5_diff\"]    = out.get(\"elo_pre_ma5_h\", np.nan)    - out.get(\"elo_pre_ma5_a\", np.nan)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:329: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"elo_pre_slope5_diff\"] = out.get(\"elo_pre_slope5_h\", np.nan) - out.get(\"elo_pre_slope5_a\", np.nan)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:330: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"elo_momentum_diff\"]   = out.get(\"elo_momentum_h\", np.nan)   - out.get(\"elo_momentum_a\", np.nan)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:331: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"elo_volatility_diff\"] = out.get(\"elo_volatility_h\", np.nan) - out.get(\"elo_volatility_a\", np.nan)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:332: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['elo_vs_opp_roll5_diff'] = out.get('elo_vs_opp_roll5_h', np.nan) - out.get('elo_vs_opp_roll5_a', np.nan)\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:334: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"momentum_index\"] = (\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:340: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"elo_x_momentum\"] = out[\"elo_diff\"] * out[\"momentum_index\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:341: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"elo_x_rest\"]     = out[\"elo_diff\"] * out[\"rest_diff\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:342: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"off_def_product\"] = out[\"off_eff_diff\"] * out[\"def_eff_diff\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:343: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[\"venue_x_streak\"]  = out[\"hvenue_winpct_diff\"] * out[\"streak_diff\"]\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:344: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['elo_vs_opp_x_streak'] = out['elo_vs_opp_roll5_diff'] * out['streak_diff']\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:345: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['elo_vs_opp_x_winpct'] = out['elo_vs_opp_roll5_diff'] * out['rw_pct_diff']\n",
      "/var/folders/vc/9pky90h50tjdhdw9xnj_zsbc0000gn/T/ipykernel_54010/3110720185.py:346: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['elo_vs_opp_x_PLUS_MINUS'] = out['elo_vs_opp_roll5_diff'] * out['PLUS_MINUS_roll5_diff']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>team_home</th>\n",
       "      <th>date</th>\n",
       "      <th>MIN_home</th>\n",
       "      <th>score_home</th>\n",
       "      <th>FGM_home</th>\n",
       "      <th>FGA_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FG3M_home</th>\n",
       "      <th>FG3A_home</th>\n",
       "      <th>...</th>\n",
       "      <th>elo_vs_opp_x_PLUS_MINUS</th>\n",
       "      <th>atk_pre_home</th>\n",
       "      <th>def_pre_home</th>\n",
       "      <th>atk_pre_away</th>\n",
       "      <th>def_pre_away</th>\n",
       "      <th>hca_est_pre</th>\n",
       "      <th>atk_diff</th>\n",
       "      <th>def_diff</th>\n",
       "      <th>atk_minus_oppdef</th>\n",
       "      <th>def_minus_oppatk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22001</td>\n",
       "      <td>PHX</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>100</td>\n",
       "      <td>41</td>\n",
       "      <td>81</td>\n",
       "      <td>0.506</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>100.130967</td>\n",
       "      <td>0.154003</td>\n",
       "      <td>-0.506988</td>\n",
       "      <td>-0.284133</td>\n",
       "      <td>0.395589</td>\n",
       "      <td>0.489983</td>\n",
       "      <td>0.438135</td>\n",
       "      <td>-0.902577</td>\n",
       "      <td>-0.241586</td>\n",
       "      <td>-0.222855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>22001</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>113</td>\n",
       "      <td>37</td>\n",
       "      <td>76</td>\n",
       "      <td>0.487</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>198.958641</td>\n",
       "      <td>-0.030573</td>\n",
       "      <td>-0.259023</td>\n",
       "      <td>0.430312</td>\n",
       "      <td>0.142993</td>\n",
       "      <td>0.489983</td>\n",
       "      <td>-0.460885</td>\n",
       "      <td>-0.402016</td>\n",
       "      <td>-0.173566</td>\n",
       "      <td>-0.689335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>22001</td>\n",
       "      <td>LAL</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>0.515</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>257.882486</td>\n",
       "      <td>0.566321</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.268092</td>\n",
       "      <td>-0.161084</td>\n",
       "      <td>0.489983</td>\n",
       "      <td>0.298229</td>\n",
       "      <td>0.280756</td>\n",
       "      <td>0.727404</td>\n",
       "      <td>-0.148420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>22001</td>\n",
       "      <td>DET</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>241</td>\n",
       "      <td>100</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>22.269377</td>\n",
       "      <td>-0.173624</td>\n",
       "      <td>0.507527</td>\n",
       "      <td>-0.157780</td>\n",
       "      <td>0.575967</td>\n",
       "      <td>0.489983</td>\n",
       "      <td>-0.015845</td>\n",
       "      <td>-0.068440</td>\n",
       "      <td>-0.749592</td>\n",
       "      <td>0.665307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>22001</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>241</td>\n",
       "      <td>96</td>\n",
       "      <td>35</td>\n",
       "      <td>91</td>\n",
       "      <td>0.385</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>36.127405</td>\n",
       "      <td>0.163076</td>\n",
       "      <td>-0.335211</td>\n",
       "      <td>-0.391568</td>\n",
       "      <td>-0.024879</td>\n",
       "      <td>0.489983</td>\n",
       "      <td>0.554644</td>\n",
       "      <td>-0.310333</td>\n",
       "      <td>0.187955</td>\n",
       "      <td>0.056356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28933</th>\n",
       "      <td>22025</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>241</td>\n",
       "      <td>128</td>\n",
       "      <td>44</td>\n",
       "      <td>91</td>\n",
       "      <td>0.484</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>552.360748</td>\n",
       "      <td>0.771735</td>\n",
       "      <td>-0.868387</td>\n",
       "      <td>1.025689</td>\n",
       "      <td>-0.501629</td>\n",
       "      <td>0.777029</td>\n",
       "      <td>-0.253954</td>\n",
       "      <td>-0.366758</td>\n",
       "      <td>1.273364</td>\n",
       "      <td>-1.894076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28934</th>\n",
       "      <td>22025</td>\n",
       "      <td>CHI</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>113</td>\n",
       "      <td>42</td>\n",
       "      <td>89</td>\n",
       "      <td>0.472</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>171.564587</td>\n",
       "      <td>-1.184662</td>\n",
       "      <td>1.705085</td>\n",
       "      <td>-0.874954</td>\n",
       "      <td>1.621152</td>\n",
       "      <td>0.777029</td>\n",
       "      <td>-0.309708</td>\n",
       "      <td>0.083933</td>\n",
       "      <td>-2.805814</td>\n",
       "      <td>2.580040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28935</th>\n",
       "      <td>22025</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>242</td>\n",
       "      <td>107</td>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>0.413</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>2038.881132</td>\n",
       "      <td>-2.205860</td>\n",
       "      <td>2.044057</td>\n",
       "      <td>1.048258</td>\n",
       "      <td>0.366034</td>\n",
       "      <td>0.777029</td>\n",
       "      <td>-3.254118</td>\n",
       "      <td>1.678024</td>\n",
       "      <td>-2.571894</td>\n",
       "      <td>0.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28936</th>\n",
       "      <td>22025</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>118</td>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>0.494</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>270.507079</td>\n",
       "      <td>0.445750</td>\n",
       "      <td>-0.179876</td>\n",
       "      <td>0.588531</td>\n",
       "      <td>-0.894624</td>\n",
       "      <td>0.777029</td>\n",
       "      <td>-0.142780</td>\n",
       "      <td>0.714748</td>\n",
       "      <td>1.340374</td>\n",
       "      <td>-0.768407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28937</th>\n",
       "      <td>22025</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>240</td>\n",
       "      <td>127</td>\n",
       "      <td>40</td>\n",
       "      <td>72</td>\n",
       "      <td>0.556</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>412.550707</td>\n",
       "      <td>0.195272</td>\n",
       "      <td>-0.497423</td>\n",
       "      <td>0.445768</td>\n",
       "      <td>-0.340492</td>\n",
       "      <td>0.777029</td>\n",
       "      <td>-0.250496</td>\n",
       "      <td>-0.156932</td>\n",
       "      <td>0.535763</td>\n",
       "      <td>-0.943191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27740 rows Ã— 493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid team_home       date  MIN_home  score_home  FGM_home  FGA_home  \\\n",
       "44     22001       PHX 2001-11-04       240         100        41        81   \n",
       "45     22001       TOR 2001-11-04       240         113        37        76   \n",
       "47     22001       LAL 2001-11-04       240         100        35        68   \n",
       "49     22001       DET 2001-11-04       241         100        37        80   \n",
       "50     22001       GSW 2001-11-04       241          96        35        91   \n",
       "...      ...       ...        ...       ...         ...       ...       ...   \n",
       "28933  22025       TOR 2025-11-04       241         128        44        91   \n",
       "28934  22025       CHI 2025-11-04       240         113        42        89   \n",
       "28935  22025       LAC 2025-11-04       242         107        33        80   \n",
       "28936  22025       GSW 2025-11-04       240         118        41        83   \n",
       "28937  22025       ATL 2025-11-04       240         127        40        72   \n",
       "\n",
       "       FG_PCT_home  FG3M_home  FG3A_home  ...  elo_vs_opp_x_PLUS_MINUS  \\\n",
       "44           0.506          1          7  ...               100.130967   \n",
       "45           0.487          6         15  ...               198.958641   \n",
       "47           0.515          2         11  ...               257.882486   \n",
       "49           0.463          9         23  ...                22.269377   \n",
       "50           0.385          4         10  ...                36.127405   \n",
       "...            ...        ...        ...  ...                      ...   \n",
       "28933        0.484         17         38  ...               552.360748   \n",
       "28934        0.472         13         34  ...               171.564587   \n",
       "28935        0.413         18         43  ...              2038.881132   \n",
       "28936        0.494         19         42  ...               270.507079   \n",
       "28937        0.556         13         30  ...               412.550707   \n",
       "\n",
       "       atk_pre_home  def_pre_home  atk_pre_away  def_pre_away  hca_est_pre  \\\n",
       "44         0.154003     -0.506988     -0.284133      0.395589     0.489983   \n",
       "45        -0.030573     -0.259023      0.430312      0.142993     0.489983   \n",
       "47         0.566321      0.119672      0.268092     -0.161084     0.489983   \n",
       "49        -0.173624      0.507527     -0.157780      0.575967     0.489983   \n",
       "50         0.163076     -0.335211     -0.391568     -0.024879     0.489983   \n",
       "...             ...           ...           ...           ...          ...   \n",
       "28933      0.771735     -0.868387      1.025689     -0.501629     0.777029   \n",
       "28934     -1.184662      1.705085     -0.874954      1.621152     0.777029   \n",
       "28935     -2.205860      2.044057      1.048258      0.366034     0.777029   \n",
       "28936      0.445750     -0.179876      0.588531     -0.894624     0.777029   \n",
       "28937      0.195272     -0.497423      0.445768     -0.340492     0.777029   \n",
       "\n",
       "       atk_diff  def_diff  atk_minus_oppdef  def_minus_oppatk  \n",
       "44     0.438135 -0.902577         -0.241586         -0.222855  \n",
       "45    -0.460885 -0.402016         -0.173566         -0.689335  \n",
       "47     0.298229  0.280756          0.727404         -0.148420  \n",
       "49    -0.015845 -0.068440         -0.749592          0.665307  \n",
       "50     0.554644 -0.310333          0.187955          0.056356  \n",
       "...         ...       ...               ...               ...  \n",
       "28933 -0.253954 -0.366758          1.273364         -1.894076  \n",
       "28934 -0.309708  0.083933         -2.805814          2.580040  \n",
       "28935 -3.254118  1.678024         -2.571894          0.995800  \n",
       "28936 -0.142780  0.714748          1.340374         -0.768407  \n",
       "28937 -0.250496 -0.156932          0.535763         -0.943191  \n",
       "\n",
       "[27740 rows x 493 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "WIN_WINDOW = 10\n",
    "\n",
    "def add_features(games: pd.DataFrame, win_window: int = WIN_WINDOW, fill_rest: int = 7,\n",
    "                 roll_windows=(3, 5)) -> pd.DataFrame:\n",
    "    df = games.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    if \"sid\" not in df.columns:\n",
    "        raise ValueError(\"Input must include 'sid' (season id).\")\n",
    "    df[\"sid\"] = pd.to_numeric(df[\"sid\"], errors=\"coerce\")\n",
    "\n",
    "    if \"win_home\" not in df.columns:\n",
    "        if {\"score_home\", \"score_away\"}.issubset(df.columns):\n",
    "            df[\"win_home\"] = (df[\"score_home\"] > df[\"score_away\"]).astype(int)\n",
    "        else:\n",
    "            raise ValueError(\"Need 'win_home' or both 'score_home' and 'score_away'.\")\n",
    "\n",
    "    # stable row id\n",
    "    df = df.reset_index(drop=False).rename(columns={\"index\": \"row_id\"})\n",
    "\n",
    "    # ------- Box-score efficiency (same-game) -------\n",
    "    df[\"off_eff_home\"] = df[\"score_home\"] / df[\"FGA_home\"]\n",
    "    df[\"off_eff_away\"] = df[\"score_away\"] / df[\"FGA_away\"]\n",
    "    df['def_eff_home'] = (df['BLK_home'] + df['STL_home'] - df['PF_home']) / df['score_away']\n",
    "    df['def_eff_away'] = (df['BLK_away'] + df['STL_away'] - df['PF_away']) / df['score_home']\n",
    "\n",
    "    df['poss_home'] = 0.96 * (df['FGA_home'] + 0.44*df['FTA_home'] - df['OREB_home'] + df['TOV_home'])\n",
    "    df['poss_away'] = 0.96 * (df['FGA_away'] + 0.44*df['FTA_away'] - df['OREB_away'] + df['TOV_away'])\n",
    "    df['pace_home'] = (df['poss_home'] + df['poss_away']) / (2 * df['MIN_home'])\n",
    "    df['pace_away'] = (df['poss_home'] + df['poss_away']) / (2 * df['MIN_away'])\n",
    "\n",
    "    df['off_rtg_home'] = df['score_home'] / df['poss_home'] * 100\n",
    "    df['def_rtg_home'] = df['score_away'] / df['poss_away'] * 100\n",
    "    df['off_rtg_away'] = df['score_away'] / df['poss_away'] * 100\n",
    "    df['def_rtg_away'] = df['score_home'] / df['poss_home'] * 100\n",
    "\n",
    "    df['fgp_home'] = df['FGM_home'] / df['FGA_home']\n",
    "    df['fgp_away'] = df['FGM_away'] / df['FGA_away']\n",
    "    df['tpp_home'] = df['FG3M_home'] / df['FG3A_home']\n",
    "    df['tpp_away'] = df['FG3M_away'] / df['FG3A_away']\n",
    "\n",
    "    df[\"efg_home\"]     = (df[\"FGM_home\"] + 0.5 * df[\"FG3M_home\"]) / df[\"FGA_home\"]\n",
    "    df[\"efg_away\"]     = (df[\"FGM_away\"] + 0.5 * df[\"FG3M_away\"]) / df[\"FGA_away\"]\n",
    "\n",
    "    df[\"tov_rate_home\"] = df[\"TOV_home\"] * 100 / (df[\"FGA_home\"] + 0.44 * df[\"FTA_home\"] + df['AST_home'] + df[\"TOV_home\"])\n",
    "    df[\"tov_rate_away\"] = df[\"TOV_away\"] * 100 / (df[\"FGA_away\"] + 0.44 * df[\"FTA_away\"] + df['AST_away'] + df[\"TOV_away\"])\n",
    "    df['ast_tov_ratio_home'] = df['AST_home'] / df['TOV_home']\n",
    "    df['ast_tov_ratio_away'] = df['AST_away'] / df['TOV_away']\n",
    "\n",
    "    df[\"reb_rate_home\"] = df[\"REB_home\"] / (df[\"REB_home\"] + df[\"REB_away\"])\n",
    "    df[\"reb_rate_away\"] = 1 - df[\"reb_rate_home\"]\n",
    "\n",
    "    df['orbp_home'] = df['OREB_home'] / (df['OREB_home'] + df['DREB_away']) \n",
    "    df['orbp_away'] = df['OREB_away'] / (df['OREB_away'] + df['DREB_home']) \n",
    "    df['drbp_home'] = df['DREB_home'] / (df['DREB_home'] + df['OREB_away'])\n",
    "    df['drbp_away'] = df['DREB_away'] / (df['DREB_away'] + df['OREB_home'])\n",
    "\n",
    "    df[\"ft_eff_home\"]   = df[\"FTM_home\"] / df[\"FTA_home\"].replace(0, np.nan)\n",
    "    df[\"ft_eff_away\"]   = df[\"FTM_away\"] / df[\"FTA_away\"].replace(0, np.nan)\n",
    "\n",
    "    df['ff_home'] = 0.4*df['efg_home'] + 0.25*df['tov_rate_home'] + 0.2 * (df['orbp_home'] + df['drbp_home']) / 2 + 0.15*df['ft_eff_home']\n",
    "    df['ff_away'] = 0.4*df['efg_away'] + 0.25*df['tov_rate_away'] + 0.2 * (df['orbp_away'] + df['drbp_away']) / 2 + 0.15*df['ft_eff_away']\n",
    "\n",
    "\n",
    "    # ------- Per-team logs (vectorized) -------\n",
    "    home = df[[\n",
    "    \"sid\",\"date\",\"team_home\",\"score_home\",\"score_away\",\"win_home\",\"row_id\",\n",
    "    \"off_rtg_home\",\"def_rtg_home\"\n",
    "    ]].rename(columns={\n",
    "        \"team_home\":\"team\",\n",
    "        \"score_home\":\"pf\",\n",
    "        \"score_away\":\"pa\",\n",
    "        \"win_home\":\"win\",\n",
    "        \"off_rtg_home\":\"off_rtg\",\n",
    "        \"def_rtg_home\":\"def_rtg\",\n",
    "    })\n",
    "    home[\"is_home\"] = 1\n",
    "\n",
    "    away = df[[\n",
    "        \"sid\",\"date\",\"team_away\",\"score_home\",\"score_away\",\"win_home\",\"row_id\",\n",
    "        \"off_rtg_away\",\"def_rtg_away\"\n",
    "    ]].rename(columns={\n",
    "        \"team_away\":\"team\",\n",
    "        \"score_home\":\"pa\",\n",
    "        \"score_away\":\"pf\",\n",
    "        \"win_home\":\"win\",\n",
    "        \"off_rtg_away\":\"off_rtg\",\n",
    "        \"def_rtg_away\":\"def_rtg\",\n",
    "    })\n",
    "    away[\"is_home\"] = 0\n",
    "    away[\"win\"] = 1 - away[\"win\"]\n",
    "\n",
    "    logs = pd.concat([home, away], ignore_index=True)\n",
    "    logs = logs.sort_values([\"team\",\"sid\",\"date\",\"row_id\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "    logs[\"pt_diff\"] = (logs[\"pf\"] - logs[\"pa\"]).astype(float)\n",
    "    g = logs.groupby([\"team\",\"sid\"], sort=False)\n",
    "\n",
    "    # ------- Season-to-date BEFORE this game -------\n",
    "    logs[\"spdiff\"] = (g[\"pt_diff\"].cumsum() - logs[\"pt_diff\"]).astype(float)\n",
    "    gp_incl   = g.cumcount() + 1\n",
    "    gp_prev   = gp_incl - 1\n",
    "    pf_cum_in = g[\"pf\"].cumsum()\n",
    "    pa_cum_in = g[\"pa\"].cumsum()\n",
    "    pf_pre    = pf_cum_in - logs[\"pf\"]\n",
    "    pa_pre    = pa_cum_in - logs[\"pa\"]\n",
    "    logs[\"off_eff\"] = np.where(gp_prev > 0, pf_pre / gp_prev, np.nan)\n",
    "    logs[\"def_eff\"] = np.where(gp_prev > 0, pa_pre / gp_prev, np.nan)\n",
    "\n",
    "    logs[\"home_game\"]  = (logs[\"is_home\"] == 1).astype(int)\n",
    "    logs[\"away_game\"]  = (logs[\"is_home\"] == 0).astype(int)\n",
    "    logs[\"home_win\"]   = logs[\"win\"] * logs[\"home_game\"]\n",
    "    logs[\"away_win\"]   = logs[\"win\"] * logs[\"away_game\"]\n",
    "    logs[\"home_pdiff\"] = logs[\"pt_diff\"] * logs[\"home_game\"]\n",
    "    logs[\"away_pdiff\"] = logs[\"pt_diff\"] * logs[\"away_game\"]\n",
    "\n",
    "    h_games_in = g[\"home_game\"].cumsum()\n",
    "    a_games_in = g[\"away_game\"].cumsum()\n",
    "    h_wins_in  = g[\"home_win\"].cumsum()\n",
    "    a_wins_in  = g[\"away_win\"].cumsum()\n",
    "    h_pd_in    = g[\"home_pdiff\"].cumsum()\n",
    "    a_pd_in    = g[\"away_pdiff\"].cumsum()\n",
    "\n",
    "    h_games = h_games_in - logs[\"home_game\"]\n",
    "    a_games = a_games_in - logs[\"away_game\"]\n",
    "    h_wins  = h_wins_in  - logs[\"home_win\"]\n",
    "    a_wins  = a_wins_in  - logs[\"away_win\"]\n",
    "    h_pd    = h_pd_in    - logs[\"home_pdiff\"]\n",
    "    a_pd    = a_pd_in    - logs[\"away_pdiff\"]\n",
    "\n",
    "    logs[\"home_win_pct\"]    = np.where(h_games > 0, h_wins / h_games, np.nan)\n",
    "    logs[\"away_win_pct\"]    = np.where(a_games > 0, a_wins / a_games, np.nan)\n",
    "    logs[\"home_point_diff\"] = np.where(h_games > 0, h_pd / h_games, np.nan)\n",
    "    logs[\"away_point_diff\"] = np.where(a_games > 0, a_pd / a_games, np.nan)\n",
    "\n",
    "    # ------- Rest / rw_pct / streak -------\n",
    "    logs[\"prev_date\"] = g[\"date\"].shift(1)\n",
    "    logs[\"rest_days\"] = ((logs[\"date\"] - logs[\"prev_date\"]).dt.days - 1).clip(lower=0)\n",
    "    logs[\"prev_win\"]  = g[\"win\"].shift(1)\n",
    "    logs[\"rw_pct\"]    = (g[\"prev_win\"].rolling(win_window, min_periods=1).mean()\n",
    "                         .reset_index(level=[0,1], drop=True))\n",
    "\n",
    "    logs[\"prev_sign\"] = logs[\"prev_win\"].map({1: 1, 0: -1})\n",
    "    def _streak_from_prev(gr):\n",
    "        cur, out = 0, []\n",
    "        for s in gr[\"prev_sign\"]:\n",
    "            if pd.isna(s):\n",
    "                cur = 0\n",
    "            else:\n",
    "                s = int(s)\n",
    "                cur = (cur + 1 if cur > 0 else 1) if s > 0 else (cur - 1 if cur < 0 else -1)\n",
    "            out.append(cur)\n",
    "        gr = gr.copy()\n",
    "        gr[\"streak\"] = out\n",
    "        return gr\n",
    "    logs = logs.groupby([\"team\",\"sid\"], group_keys=False).apply(_streak_from_prev)\n",
    "\n",
    "    # ------- Elo PRE rolling (uses df['elo_pre_home'], df['elo_pre_away'] if present) -------\n",
    "    if {\"elo_pre_home\", \"elo_pre_away\"}.issubset(df.columns):\n",
    "        logs[\"elo_pre\"] = np.where(\n",
    "            logs[\"is_home\"] == 1,\n",
    "            df.loc[logs[\"row_id\"].values, \"elo_pre_home\"].values,\n",
    "            df.loc[logs[\"row_id\"].values, \"elo_pre_away\"].values\n",
    "        ).astype(float)\n",
    "        logs[\"opp_elo_pre\"] = np.where(\n",
    "                logs[\"is_home\"] == 1,\n",
    "                df.loc[logs[\"row_id\"].values, \"elo_pre_away\"].values,\n",
    "                df.loc[logs[\"row_id\"].values, \"elo_pre_home\"].values).astype(float)\n",
    "        logs[\"elo_vs_opp\"] = logs[\"elo_pre\"] - logs[\"opp_elo_pre\"]\n",
    "    \n",
    "\n",
    "        def _elo_roll(gr, w=5):\n",
    "            e = gr[\"elo_pre\"].astype(float)\n",
    "            gr = gr.copy()\n",
    "            gr[\"elo_pre_ma5\"]       = e.rolling(w, min_periods=3).mean()\n",
    "            gr[\"elo_pre_slope5\"]    = e.rolling(w, min_periods=3).apply(\n",
    "                lambda x: np.polyfit(np.arange(len(x)), x, 1)[0], raw=False\n",
    "            )\n",
    "            de = e.diff()\n",
    "            gr[\"elo_pre_diff_ma5\"]  = de.rolling(w, min_periods=3).mean()\n",
    "            gr[\"elo_pre_diff_std5\"] = de.rolling(w, min_periods=3).std()\n",
    "            return gr\n",
    "\n",
    "        logs = logs.groupby([\"team\",\"sid\"], group_keys=False).apply(_elo_roll)\n",
    "        logs[\"elo_vs_opp_roll5\"] = logs.groupby([\"team\",\"sid\"])['elo_vs_opp'].transform(lambda s: s.shift(1).rolling(5, min_periods=1).mean())\n",
    "    \n",
    "    else:\n",
    "        logs[\"elo_pre_ma5\"] = np.nan\n",
    "        logs[\"elo_pre_slope5\"] = np.nan\n",
    "        logs[\"elo_pre_diff_ma5\"] = np.nan\n",
    "        logs[\"elo_pre_diff_std5\"] = np.nan\n",
    "        logs[\"elo_vs_opp\"] = np.nan\n",
    "        logs[\"elo_vs_opp_roll5\"] = np.nan\n",
    "    \n",
    "\n",
    "    # ------- Spread back to game rows -------\n",
    "    h = logs.rename(columns={\n",
    "        \"team\":\"team_home\",\n",
    "        \"rest_days\":\"rest_h\",\"rw_pct\":\"rw_pct_h\",\"streak\":\"streak_h\",\n",
    "        \"spdiff\":\"spdiff_h\",\n",
    "        \"off_eff\":\"off_eff_h\",\"def_eff\":\"def_eff_h\",\n",
    "        \"home_win_pct\":\"home_win_pct_h\",\n",
    "        \"home_point_diff\":\"home_point_diff_h\",\n",
    "        \"elo_pre_ma5\":\"elo_pre_ma5_h\",\n",
    "        \"elo_pre_slope5\":\"elo_pre_slope5_h\",\n",
    "        \"elo_pre_diff_ma5\":\"elo_momentum_h\",\n",
    "        'elo_vs_opp_roll5' : 'elo_vs_opp_roll5_h',\n",
    "        \"elo_pre_diff_std5\":\"elo_volatility_h\",\n",
    "        'off_rtg' : 'off_rtg_h',\n",
    "        'def_rtg' : 'def_rtg_h',\n",
    "    })[[\"sid\",\"date\",\"team_home\",\n",
    "        \"rest_h\",\"rw_pct_h\",\"streak_h\",\"spdiff_h\",\n",
    "        \"off_eff_h\",\"def_eff_h\",\n",
    "        \"home_win_pct_h\",\"home_point_diff_h\", 'elo_vs_opp_roll5_h',\n",
    "        \"elo_pre_ma5_h\",\"elo_pre_slope5_h\",\"elo_momentum_h\",\"elo_volatility_h\", 'def_rtg_h', 'off_rtg_h']]\n",
    "\n",
    "    a = logs.rename(columns={\n",
    "        \"team\":\"team_away\",\n",
    "        \"rest_days\":\"rest_a\",\"rw_pct\":\"rw_pct_a\",\"streak\":\"streak_a\",\n",
    "        \"spdiff\":\"spdiff_a\",\n",
    "        \"off_eff\":\"off_eff_a\",\"def_eff\":\"def_eff_a\",\n",
    "        \"away_win_pct\":\"away_win_pct_a\",\n",
    "        \"away_point_diff\":\"away_point_diff_a\",\n",
    "        \"elo_pre_ma5\":\"elo_pre_ma5_a\",\n",
    "        \"elo_pre_slope5\":\"elo_pre_slope5_a\",\n",
    "        \"elo_pre_diff_ma5\":\"elo_momentum_a\",\n",
    "        'elo_vs_opp_roll5' : 'elo_vs_opp_roll5_a',\n",
    "        \"elo_pre_diff_std5\":\"elo_volatility_a\",\n",
    "        'off_rtg' : 'off_rtg_a',\n",
    "        'def_rtg' : 'def_rtg_a',\n",
    "    })[[\"sid\",\"date\",\"team_away\",\n",
    "        \"rest_a\",\"rw_pct_a\",\"streak_a\",\"spdiff_a\",\n",
    "        \"off_eff_a\",\"def_eff_a\",\n",
    "        \"away_win_pct_a\",\"away_point_diff_a\", 'elo_vs_opp_roll5_a',\n",
    "        \"elo_pre_ma5_a\",\"elo_pre_slope5_a\",\"elo_momentum_a\",\"elo_volatility_a\", 'def_rtg_a', 'off_rtg_a']]\n",
    "\n",
    "    out = (df.drop(columns=\"row_id\")\n",
    "             .merge(h, on=[\"sid\",\"date\",\"team_home\"], how=\"left\")\n",
    "             .merge(a, on=[\"sid\",\"date\",\"team_away\"], how=\"left\"))\n",
    "\n",
    "    # ------- Box-score prev & rolling (3,5) for ALL numeric _home/_away bases -------\n",
    "    numeric_cols = out.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    home_bases = {c[:-5] for c in out.columns if c.endswith(\"_home\") and c in numeric_cols}\n",
    "    away_bases = {c[:-5] for c in out.columns if c.endswith(\"_away\") and c in numeric_cols}\n",
    "    bases = sorted(home_bases & away_bases)\n",
    "\n",
    "    H = out[[\"date\",\"team_home\"] + [f\"{b}_home\" for b in bases]].rename(\n",
    "        columns={\"team_home\":\"team\", **{f\"{b}_home\": b for b in bases}}\n",
    "    )\n",
    "    A = out[[\"date\",\"team_away\"] + [f\"{b}_away\" for b in bases]].rename(\n",
    "        columns={\"team_away\":\"team\", **{f\"{b}_away\": b for b in bases}}\n",
    "    )\n",
    "    long = pd.concat([H, A], ignore_index=True).sort_values([\"team\",\"date\"])\n",
    "\n",
    "    prev = (long.groupby(\"team\", group_keys=False)\n",
    "                 .apply(lambda g: g.assign(**{f\"{b}_prev\": g[b].shift(1) for b in bases}))\n",
    "                 [[\"team\",\"date\"] + [f\"{b}_prev\" for b in bases]])\n",
    "\n",
    "    rolls = []\n",
    "    for w in roll_windows:\n",
    "        r = (long.groupby(\"team\", group_keys=False)\n",
    "                  .apply(lambda g: g.assign(**{\n",
    "                      f\"{b}_roll{w}\": g[b].ewm(w, min_periods=1).mean().shift(1)\n",
    "                      for b in bases\n",
    "                  }))\n",
    "                  [[\"team\",\"date\"] + [f\"{b}_roll{w}\" for b in bases]])\n",
    "        rolls.append(r)\n",
    "\n",
    "    long_roll = prev\n",
    "    for r in rolls:\n",
    "        long_roll = long_roll.merge(r, on=[\"team\",\"date\"], how=\"left\")\n",
    "\n",
    "    home_feat = long_roll.rename(columns={\n",
    "        **{f\"{b}_prev\": f\"{b}_home_prev\" for b in bases},\n",
    "        **{c: c.replace(\"_roll\", \"_home_roll\") for c in long_roll.columns if \"_roll\" in c}\n",
    "    })\n",
    "    away_feat = long_roll.rename(columns={\n",
    "        **{f\"{b}_prev\": f\"{b}_away_prev\" for b in bases},\n",
    "        **{c: c.replace(\"_roll\", \"_away_roll\") for c in long_roll.columns if \"_roll\" in c}\n",
    "    })\n",
    "\n",
    "    out = out.merge(home_feat, left_on=[\"team_home\",\"date\"], right_on=[\"team\",\"date\"], how=\"left\").drop(columns=[\"team\"])\n",
    "    out = out.merge(away_feat, left_on=[\"team_away\",\"date\"], right_on=[\"team\",\"date\"], how=\"left\").drop(columns=[\"team\"])\n",
    "\n",
    "    # diffs for prev and rolling\n",
    "    for b in bases:\n",
    "        out[f\"{b}_prev_diff\"] = out[f\"{b}_home_prev\"] - out[f\"{b}_away_prev\"]\n",
    "    for w in roll_windows:\n",
    "        for b in bases:\n",
    "            out[f\"{b}_roll{w}_diff\"] = out[f\"{b}_home_roll{w}\"] - out[f\"{b}_away_roll{w}\"]\n",
    "\n",
    "    # ------- Fills -------\n",
    "    out[\"rest_h\"]   = out[\"rest_h\"].fillna(fill_rest)\n",
    "    out[\"rest_a\"]   = out[\"rest_a\"].fillna(fill_rest)\n",
    "    out[\"rw_pct_h\"] = out[\"rw_pct_h\"].fillna(0.5)\n",
    "    out[\"rw_pct_a\"] = out[\"rw_pct_a\"].fillna(0.5)\n",
    "    out[\"streak_h\"] = out[\"streak_h\"].fillna(0).astype(int)\n",
    "    out[\"streak_a\"] = out[\"streak_a\"].fillna(0).astype(int)\n",
    "    out[\"home_win_pct_h\"]    = out[\"home_win_pct_h\"].fillna(0.5)\n",
    "    out[\"away_win_pct_a\"]    = out[\"away_win_pct_a\"].fillna(0.5)\n",
    "    out[\"home_point_diff_h\"] = out[\"home_point_diff_h\"].fillna(0.0)\n",
    "    out[\"away_point_diff_a\"] = out[\"away_point_diff_a\"].fillna(0.0)\n",
    "    out[\"off_eff_h\"] = out[\"off_eff_h\"].fillna(0.0)\n",
    "    out[\"off_eff_a\"] = out[\"off_eff_a\"].fillna(0.0)\n",
    "    out[\"def_eff_h\"] = out[\"def_eff_h\"].fillna(0.0)\n",
    "    out[\"def_eff_a\"] = out[\"def_eff_a\"].fillna(0.0)\n",
    "    out['elo_vs_opp_roll5_h'] = out['elo_vs_opp_roll5_h'].fillna(0.0)\n",
    "    out['elo_vs_opp_roll5_a'] = out['elo_vs_opp_roll5_a'].fillna(0.0)\n",
    "\n",
    "    # ------- Diffs & interactions (incl. Elo diffs you asked for) -------\n",
    "    out[\"rest_diff\"]          = out[\"rest_h\"] - out[\"rest_a\"]\n",
    "    out[\"rw_pct_diff\"]        = out[\"rw_pct_h\"] - out[\"rw_pct_a\"]\n",
    "    out[\"streak_diff\"]        = out[\"streak_h\"] - out[\"streak_a\"]\n",
    "    out[\"spdiff_diff\"]        = out[\"spdiff_h\"] - out[\"spdiff_a\"]\n",
    "    out[\"off_eff_diff\"]       = out[\"off_eff_h\"] - out[\"off_eff_a\"]\n",
    "    out[\"def_eff_diff\"]       = out[\"def_eff_h\"] - out[\"def_eff_a\"]\n",
    "    out['off_def_rtg_diff']   = out['off_rtg_h'] - out['def_rtg_a']\n",
    "    out['def_off_rtg_diff']   = out['def_rtg_h'] - out['off_rtg_a']\n",
    "    out[\"net_off_diff\"]       = out[\"off_eff_h\"] - out[\"def_eff_a\"]\n",
    "    out[\"net_def_diff\"]       = out[\"def_eff_h\"] - out[\"off_eff_a\"]\n",
    "    out[\"hvenue_winpct_diff\"] = out[\"home_win_pct_h\"] - out[\"away_win_pct_a\"]\n",
    "    out[\"hvenue_pdiff_diff\"]  = out[\"home_point_diff_h\"] - out[\"away_point_diff_a\"]\n",
    "    out[\"b2b_home\"] = (out[\"rest_h\"] == 0).astype(int)\n",
    "    out[\"b2b_away\"] = (out[\"rest_a\"] == 0).astype(int)\n",
    "\n",
    "    # Elo diffs (these four are guaranteed present via the Elo block above, else NaN)\n",
    "    out[\"elo_pre_ma5_diff\"]    = out.get(\"elo_pre_ma5_h\", np.nan)    - out.get(\"elo_pre_ma5_a\", np.nan)\n",
    "    out[\"elo_pre_slope5_diff\"] = out.get(\"elo_pre_slope5_h\", np.nan) - out.get(\"elo_pre_slope5_a\", np.nan)\n",
    "    out[\"elo_momentum_diff\"]   = out.get(\"elo_momentum_h\", np.nan)   - out.get(\"elo_momentum_a\", np.nan)\n",
    "    out[\"elo_volatility_diff\"] = out.get(\"elo_volatility_h\", np.nan) - out.get(\"elo_volatility_a\", np.nan)\n",
    "    out['elo_vs_opp_roll5_diff'] = out.get('elo_vs_opp_roll5_h', np.nan) - out.get('elo_vs_opp_roll5_a', np.nan)\n",
    "\n",
    "    out[\"momentum_index\"] = (\n",
    "        0.4 * out[\"rw_pct_diff\"] +\n",
    "        0.3 * out[\"streak_diff\"]/5 +\n",
    "        0.3 * np.tanh(out[\"spdiff_diff\"]/20)\n",
    "    )\n",
    "    if \"elo_diff\" in out.columns:\n",
    "        out[\"elo_x_momentum\"] = out[\"elo_diff\"] * out[\"momentum_index\"]\n",
    "        out[\"elo_x_rest\"]     = out[\"elo_diff\"] * out[\"rest_diff\"]\n",
    "    out[\"off_def_product\"] = out[\"off_eff_diff\"] * out[\"def_eff_diff\"]\n",
    "    out[\"venue_x_streak\"]  = out[\"hvenue_winpct_diff\"] * out[\"streak_diff\"]\n",
    "    out['elo_vs_opp_x_streak'] = out['elo_vs_opp_roll5_diff'] * out['streak_diff']\n",
    "    out['elo_vs_opp_x_winpct'] = out['elo_vs_opp_roll5_diff'] * out['rw_pct_diff']\n",
    "    out['elo_vs_opp_x_PLUS_MINUS'] = out['elo_vs_opp_roll5_diff'] * out['PLUS_MINUS_roll5_diff']\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _fit_atk_def_ridge(gsub: pd.DataFrame,\n",
    "                       teams: list[str],\n",
    "                       lam: float = 50.0,\n",
    "                       constraint_w: float = 100.0):\n",
    "\n",
    "    T = len(teams)\n",
    "    idx = {t:i for i,t in enumerate(teams)}\n",
    "    G = len(gsub)\n",
    "\n",
    "    # Design: variables = [atk_0..atk_{T-1}, def_0..def_{T-1}, hca]\n",
    "    P = 2*T + 1\n",
    "    rows = 2*G + 2  # 2 eqns per game + 2 constraints\n",
    "\n",
    "    X = np.zeros((rows, P), dtype=float)\n",
    "    y = np.zeros(rows, dtype=float)\n",
    "\n",
    "    r = 0\n",
    "    # Per-game equations\n",
    "    for h, a, ph, pa in zip(gsub[\"team_home\"], gsub[\"team_away\"], gsub[\"score_home\"], gsub[\"score_away\"]):\n",
    "        ih, ia = idx[h], idx[a]\n",
    "\n",
    "        # home points: ph = atk[h] - def[a] + hca\n",
    "        X[r, ih] = 1.0                 # atk[h]\n",
    "        X[r, T + ia] = -1.0            # -def[a]\n",
    "        X[r, 2*T] = 1.0                # +hca\n",
    "        y[r] = float(ph); r += 1\n",
    "\n",
    "        # away points: pa = atk[a] - def[h] - hca\n",
    "        X[r, ia] = 1.0                 # atk[a]\n",
    "        X[r, T + ih] = -1.0            # -def[h]\n",
    "        X[r, 2*T] = -1.0               # -hca\n",
    "        y[r] = float(pa); r += 1\n",
    "\n",
    "    # Soft constraints: mean(atk)=0 and mean(def)=0\n",
    "    # weight them so they behave like strong pseudo-observations\n",
    "    X[r, :T] = constraint_w / np.sqrt(T)\n",
    "    y[r] = 0.0; r += 1\n",
    "\n",
    "    X[r, T:2*T] = constraint_w / np.sqrt(T)\n",
    "    y[r] = 0.0; r += 1\n",
    "\n",
    "    # Ridge solve: (X^T X + lam I)x = X^T y\n",
    "    XtX = X.T @ X\n",
    "    Xty = X.T @ y\n",
    "    XtX += lam * np.eye(P)\n",
    "\n",
    "    coef = np.linalg.solve(XtX, Xty)\n",
    "\n",
    "    atk = coef[:T]\n",
    "    deff = coef[T:2*T]\n",
    "    hca = float(coef[2*T])\n",
    "\n",
    "    # enforce exact mean-zero post-hoc (numerical nicety)\n",
    "    atk -= atk.mean()\n",
    "    deff -= deff.mean()\n",
    "\n",
    "    return atk, deff, hca, idx\n",
    "\n",
    "# ----- main feature builder: leak-free pre-game ratings per game -----\n",
    "def add_sched_adjust_features(\n",
    "    games: pd.DataFrame,\n",
    "    lam: float = 50.0,\n",
    "    constraint_w: float = 100.0,\n",
    "    season_col: str = \"sid\",\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    df = games.copy()\n",
    "    if season_col not in df.columns:\n",
    "        raise ValueError(\"Need season id column (sid).\")\n",
    "\n",
    "    # normalize date\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    # stable ordering (no leakage on same day â€” we exclude same-day games entirely)\n",
    "    df = df.sort_values([season_col, \"date\"]).reset_index(drop=True)\n",
    "\n",
    "    # allocate outputs\n",
    "    df[\"atk_pre_home\"] = np.nan\n",
    "    df[\"def_pre_home\"] = np.nan\n",
    "    df[\"atk_pre_away\"] = np.nan\n",
    "    df[\"def_pre_away\"] = np.nan\n",
    "    df[\"hca_est_pre\"]  = np.nan\n",
    "\n",
    "    # process each season independently\n",
    "    for sid, g_season in df.groupby(season_col, sort=False):\n",
    "        # teams present this season\n",
    "        teams = pd.Index(\n",
    "            pd.unique(pd.concat([g_season[\"team_home\"], g_season[\"team_away\"]], ignore_index=True)),\n",
    "            name=\"team\"\n",
    "        ).tolist()\n",
    "\n",
    "        # iterate over unique dates in ascending order\n",
    "        dates = np.sort(g_season[\"date\"].unique())\n",
    "\n",
    "        # For each game day, fit ratings on games strictly before that day, then assign to all games of that day\n",
    "        for d in dates:\n",
    "            hist = g_season[g_season[\"date\"] < d]\n",
    "            if len(hist) < max(10, len(teams)):  # too early in season, skip (leave NaNs)\n",
    "                continue\n",
    "\n",
    "            atk, deff, hca, idx = _fit_atk_def_ridge(hist, teams, lam=lam, constraint_w=constraint_w)\n",
    "            # map to dicts for quick lookup\n",
    "            atk_d = {t: atk[i] for t,i in idx.items()}\n",
    "            def_d = {t: deff[i] for t,i in idx.items()}\n",
    "\n",
    "            mask_today = (df[season_col] == sid) & (df[\"date\"] == d)\n",
    "            # fill all games on that calendar day (pre-game estimates)\n",
    "            df.loc[mask_today, \"atk_pre_home\"] = df.loc[mask_today, \"team_home\"].map(atk_d).astype(float)\n",
    "            df.loc[mask_today, \"def_pre_home\"] = df.loc[mask_today, \"team_home\"].map(def_d).astype(float)\n",
    "            df.loc[mask_today, \"atk_pre_away\"] = df.loc[mask_today, \"team_away\"].map(atk_d).astype(float)\n",
    "            df.loc[mask_today, \"def_pre_away\"] = df.loc[mask_today, \"team_away\"].map(def_d).astype(float)\n",
    "            df.loc[mask_today, \"hca_est_pre\"]  = hca\n",
    "\n",
    "    # engineered diffs (home - away)\n",
    "    df[\"atk_diff\"]            = df[\"atk_pre_home\"] - df[\"atk_pre_away\"]\n",
    "    df[\"def_diff\"]            = df[\"def_pre_home\"] - df[\"def_pre_away\"]\n",
    "    df[\"atk_minus_oppdef\"]    = df[\"atk_pre_home\"] - df[\"def_pre_away\"]\n",
    "    df[\"def_minus_oppatk\"]    = df[\"def_pre_home\"] - df[\"atk_pre_away\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "games_feat = add_features(games_df)\n",
    "games_feat = add_sched_adjust_features(games_feat)\n",
    "games_feat = games_feat.dropna()\n",
    "games_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411492ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elo_diff</th>\n",
       "      <th>elo_vs_opp_roll5_diff</th>\n",
       "      <th>elo_pre_ma5_diff</th>\n",
       "      <th>elo_pre_slope5_diff</th>\n",
       "      <th>elo_momentum_diff</th>\n",
       "      <th>elo_volatility_diff</th>\n",
       "      <th>elo_x_momentum</th>\n",
       "      <th>elo_x_rest</th>\n",
       "      <th>elo_vs_opp_x_streak</th>\n",
       "      <th>elo_vs_opp_x_winpct</th>\n",
       "      <th>...</th>\n",
       "      <th>tov_rate_roll5_diff</th>\n",
       "      <th>reb_rate_roll3_diff</th>\n",
       "      <th>reb_rate_roll5_diff</th>\n",
       "      <th>ft_eff_roll3_diff</th>\n",
       "      <th>ft_eff_roll5_diff</th>\n",
       "      <th>sid</th>\n",
       "      <th>date</th>\n",
       "      <th>team_home</th>\n",
       "      <th>team_away</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>61.033252</td>\n",
       "      <td>-9.531295</td>\n",
       "      <td>-9.859936</td>\n",
       "      <td>-4.027965</td>\n",
       "      <td>-4.961466</td>\n",
       "      <td>4.530715</td>\n",
       "      <td>-24.537882</td>\n",
       "      <td>61.033252</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3.177098</td>\n",
       "      <td>...</td>\n",
       "      <td>2.685034</td>\n",
       "      <td>-0.041978</td>\n",
       "      <td>-0.041715</td>\n",
       "      <td>0.092657</td>\n",
       "      <td>0.094855</td>\n",
       "      <td>22001</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>PHX</td>\n",
       "      <td>HOU</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>48.960973</td>\n",
       "      <td>-14.111642</td>\n",
       "      <td>-15.668812</td>\n",
       "      <td>-10.589736</td>\n",
       "      <td>-8.985560</td>\n",
       "      <td>-0.201864</td>\n",
       "      <td>-23.861730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.111642</td>\n",
       "      <td>4.703881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106386</td>\n",
       "      <td>-0.019881</td>\n",
       "      <td>-0.018718</td>\n",
       "      <td>-0.168043</td>\n",
       "      <td>-0.173075</td>\n",
       "      <td>22001</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>TOR</td>\n",
       "      <td>IND</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>108.416559</td>\n",
       "      <td>25.902104</td>\n",
       "      <td>22.997912</td>\n",
       "      <td>11.508550</td>\n",
       "      <td>10.832969</td>\n",
       "      <td>-14.674813</td>\n",
       "      <td>71.898310</td>\n",
       "      <td>108.416559</td>\n",
       "      <td>51.804208</td>\n",
       "      <td>17.268069</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.954680</td>\n",
       "      <td>-0.077141</td>\n",
       "      <td>-0.075889</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-0.010991</td>\n",
       "      <td>22001</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>LAL</td>\n",
       "      <td>UTA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>74.039453</td>\n",
       "      <td>-16.212106</td>\n",
       "      <td>-2.208186</td>\n",
       "      <td>-0.538349</td>\n",
       "      <td>-0.626066</td>\n",
       "      <td>2.399280</td>\n",
       "      <td>-5.440093</td>\n",
       "      <td>74.039453</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.058700</td>\n",
       "      <td>-0.007427</td>\n",
       "      <td>-0.004823</td>\n",
       "      <td>0.145270</td>\n",
       "      <td>0.151862</td>\n",
       "      <td>22001</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>DET</td>\n",
       "      <td>WAS</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>82.587019</td>\n",
       "      <td>7.024773</td>\n",
       "      <td>-1.655532</td>\n",
       "      <td>0.210157</td>\n",
       "      <td>2.223123</td>\n",
       "      <td>-2.661540</td>\n",
       "      <td>24.074198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.049546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.368870</td>\n",
       "      <td>0.054313</td>\n",
       "      <td>0.051884</td>\n",
       "      <td>-0.074090</td>\n",
       "      <td>-0.073662</td>\n",
       "      <td>22001</td>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>GSW</td>\n",
       "      <td>POR</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28933</th>\n",
       "      <td>-52.040150</td>\n",
       "      <td>-104.619451</td>\n",
       "      <td>-136.037677</td>\n",
       "      <td>-1.298727</td>\n",
       "      <td>-2.347954</td>\n",
       "      <td>6.225181</td>\n",
       "      <td>17.975776</td>\n",
       "      <td>-52.040150</td>\n",
       "      <td>-104.619451</td>\n",
       "      <td>29.891272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061937</td>\n",
       "      <td>-0.012637</td>\n",
       "      <td>-0.011551</td>\n",
       "      <td>0.077217</td>\n",
       "      <td>0.051677</td>\n",
       "      <td>22025</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>TOR</td>\n",
       "      <td>MIL</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28934</th>\n",
       "      <td>191.671948</td>\n",
       "      <td>58.150120</td>\n",
       "      <td>132.053334</td>\n",
       "      <td>-3.858101</td>\n",
       "      <td>-3.094745</td>\n",
       "      <td>1.983512</td>\n",
       "      <td>-55.872563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-116.300240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232334</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>0.046688</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>22025</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>CHI</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28935</th>\n",
       "      <td>-52.253064</td>\n",
       "      <td>-176.291387</td>\n",
       "      <td>-116.791655</td>\n",
       "      <td>-5.747661</td>\n",
       "      <td>-4.714294</td>\n",
       "      <td>4.375361</td>\n",
       "      <td>51.204836</td>\n",
       "      <td>52.253064</td>\n",
       "      <td>1410.331096</td>\n",
       "      <td>88.145693</td>\n",
       "      <td>...</td>\n",
       "      <td>3.435928</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.011362</td>\n",
       "      <td>-0.029584</td>\n",
       "      <td>-0.018227</td>\n",
       "      <td>22025</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>LAC</td>\n",
       "      <td>OKC</td>\n",
       "      <td>-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28936</th>\n",
       "      <td>177.977560</td>\n",
       "      <td>62.729947</td>\n",
       "      <td>120.199981</td>\n",
       "      <td>-2.098045</td>\n",
       "      <td>-3.275657</td>\n",
       "      <td>2.499068</td>\n",
       "      <td>15.279502</td>\n",
       "      <td>177.977560</td>\n",
       "      <td>-250.919788</td>\n",
       "      <td>8.961421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337703</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>0.019150</td>\n",
       "      <td>0.022629</td>\n",
       "      <td>0.020475</td>\n",
       "      <td>22025</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>GSW</td>\n",
       "      <td>PHX</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28937</th>\n",
       "      <td>71.050307</td>\n",
       "      <td>-115.076606</td>\n",
       "      <td>-1.797920</td>\n",
       "      <td>4.726167</td>\n",
       "      <td>3.245665</td>\n",
       "      <td>-2.218412</td>\n",
       "      <td>-30.870299</td>\n",
       "      <td>-71.050307</td>\n",
       "      <td>345.229818</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.081662</td>\n",
       "      <td>-0.026999</td>\n",
       "      <td>-0.022964</td>\n",
       "      <td>-0.031196</td>\n",
       "      <td>-0.026036</td>\n",
       "      <td>22025</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORL</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27740 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         elo_diff  elo_vs_opp_roll5_diff  elo_pre_ma5_diff  \\\n",
       "44      61.033252              -9.531295         -9.859936   \n",
       "45      48.960973             -14.111642        -15.668812   \n",
       "47     108.416559              25.902104         22.997912   \n",
       "49      74.039453             -16.212106         -2.208186   \n",
       "50      82.587019               7.024773         -1.655532   \n",
       "...           ...                    ...               ...   \n",
       "28933  -52.040150            -104.619451       -136.037677   \n",
       "28934  191.671948              58.150120        132.053334   \n",
       "28935  -52.253064            -176.291387       -116.791655   \n",
       "28936  177.977560              62.729947        120.199981   \n",
       "28937   71.050307            -115.076606         -1.797920   \n",
       "\n",
       "       elo_pre_slope5_diff  elo_momentum_diff  elo_volatility_diff  \\\n",
       "44               -4.027965          -4.961466             4.530715   \n",
       "45              -10.589736          -8.985560            -0.201864   \n",
       "47               11.508550          10.832969           -14.674813   \n",
       "49               -0.538349          -0.626066             2.399280   \n",
       "50                0.210157           2.223123            -2.661540   \n",
       "...                    ...                ...                  ...   \n",
       "28933            -1.298727          -2.347954             6.225181   \n",
       "28934            -3.858101          -3.094745             1.983512   \n",
       "28935            -5.747661          -4.714294             4.375361   \n",
       "28936            -2.098045          -3.275657             2.499068   \n",
       "28937             4.726167           3.245665            -2.218412   \n",
       "\n",
       "       elo_x_momentum  elo_x_rest  elo_vs_opp_x_streak  elo_vs_opp_x_winpct  \\\n",
       "44         -24.537882   61.033252            -0.000000             3.177098   \n",
       "45         -23.861730    0.000000            14.111642             4.703881   \n",
       "47          71.898310  108.416559            51.804208            17.268069   \n",
       "49          -5.440093   74.039453            -0.000000            -0.000000   \n",
       "50          24.074198    0.000000            14.049546             0.000000   \n",
       "...               ...         ...                  ...                  ...   \n",
       "28933       17.975776  -52.040150          -104.619451            29.891272   \n",
       "28934      -55.872563    0.000000          -116.300240             0.000000   \n",
       "28935       51.204836   52.253064          1410.331096            88.145693   \n",
       "28936       15.279502  177.977560          -250.919788             8.961421   \n",
       "28937      -30.870299  -71.050307           345.229818            -0.000000   \n",
       "\n",
       "       ...  tov_rate_roll5_diff  reb_rate_roll3_diff  reb_rate_roll5_diff  \\\n",
       "44     ...             2.685034            -0.041978            -0.041715   \n",
       "45     ...             0.106386            -0.019881            -0.018718   \n",
       "47     ...            -1.954680            -0.077141            -0.075889   \n",
       "49     ...             4.058700            -0.007427            -0.004823   \n",
       "50     ...             1.368870             0.054313             0.051884   \n",
       "...    ...                  ...                  ...                  ...   \n",
       "28933  ...             0.061937            -0.012637            -0.011551   \n",
       "28934  ...            -0.232334             0.042013             0.046688   \n",
       "28935  ...             3.435928             0.006682             0.011362   \n",
       "28936  ...             0.337703             0.021903             0.019150   \n",
       "28937  ...            -1.081662            -0.026999            -0.022964   \n",
       "\n",
       "       ft_eff_roll3_diff  ft_eff_roll5_diff    sid       date  team_home  \\\n",
       "44              0.092657           0.094855  22001 2001-11-04        PHX   \n",
       "45             -0.168043          -0.173075  22001 2001-11-04        TOR   \n",
       "47              0.000938          -0.010991  22001 2001-11-04        LAL   \n",
       "49              0.145270           0.151862  22001 2001-11-04        DET   \n",
       "50             -0.074090          -0.073662  22001 2001-11-04        GSW   \n",
       "...                  ...                ...    ...        ...        ...   \n",
       "28933           0.077217           0.051677  22025 2025-11-04        TOR   \n",
       "28934           0.009471           0.021761  22025 2025-11-04        CHI   \n",
       "28935          -0.029584          -0.018227  22025 2025-11-04        LAC   \n",
       "28936           0.022629           0.020475  22025 2025-11-04        GSW   \n",
       "28937          -0.031196          -0.026036  22025 2025-11-04        ATL   \n",
       "\n",
       "       team_away  margin  \n",
       "44           HOU      -3  \n",
       "45           IND      13  \n",
       "47           UTA       4  \n",
       "49           WAS      22  \n",
       "50           POR      10  \n",
       "...          ...     ...  \n",
       "28933        MIL      28  \n",
       "28934        PHI       2  \n",
       "28935        OKC     -19  \n",
       "28936        PHX      11  \n",
       "28937        ORL      15  \n",
       "\n",
       "[27740 rows x 74 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_COLS = [\"sid\",\"date\",\"team_home\",\"team_away\"]\n",
    "TARGET  = 'margin'\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    # Elo\n",
    "    \"elo_diff\", 'elo_vs_opp_roll5_diff',\n",
    "    \"elo_pre_ma5_diff\", \"elo_pre_slope5_diff\", \"elo_momentum_diff\", \"elo_volatility_diff\",\n",
    "    \"elo_x_momentum\", \"elo_x_rest\", 'elo_vs_opp_x_streak', 'elo_vs_opp_x_winpct', 'elo_vs_opp_x_PLUS_MINUS',\n",
    "\n",
    "    # Schedule Adjusted\n",
    "    \"atk_diff\", \"def_diff\",\n",
    "    \"atk_minus_oppdef\", \"def_minus_oppatk\",\n",
    "    \"atk_pre_home\",\"def_pre_home\",\"atk_pre_away\",\"def_pre_away\",\"hca_est_pre\",\n",
    "\n",
    "    # possesion stats\n",
    "    'off_rtg_roll3_diff', 'off_rtg_roll5_diff',\n",
    "    'def_rtg_roll3_diff', 'def_rtg_roll5_diff',\n",
    "\n",
    "    # Context / venue / rest\n",
    "    \"rest_diff\", \"rw_pct_diff\", \"streak_diff\", \"spdiff_diff\",\n",
    "    \"hvenue_winpct_diff\", \"hvenue_pdiff_diff\",\n",
    "    \"b2b_home\", \"b2b_away\",\n",
    "    \"momentum_index\",\n",
    "\n",
    "    # Four factors\n",
    "    'ff_prev_diff', 'ff_roll3_diff', 'ff_roll5_diff',\n",
    "\n",
    "    # Prev (lag-1) diffs\n",
    "    'PLUS_MINUS_prev_diff','off_rtg_prev_diff', 'def_rtg_prev_diff' ,\"off_eff_prev_diff\", 'def_eff_prev_diff',\n",
    "    'pace_prev_diff', \"efg_prev_diff\", \"tov_rate_prev_diff\", \"reb_rate_prev_diff\", \"ft_eff_prev_diff\", 'ast_tov_ratio_prev_diff',\n",
    "\n",
    "    # Rolling 3 & 5 (shifted)\n",
    "    'pace_roll3_diff', 'pace_roll5_diff',\n",
    "    'ast_tov_ratio_roll3_diff', 'ast_tov_ratio_roll5_diff',\n",
    "    'PLUS_MINUS_roll3_diff', 'PLUS_MINUS_roll5_diff',\n",
    "    'fgp_roll3_diff', 'fgp_roll5_diff',\n",
    "    'tpp_roll3_diff', 'tpp_roll5_diff',\n",
    "    \"off_eff_roll3_diff\", \"off_eff_roll5_diff\",\n",
    "    'def_eff_roll3_diff', 'def_eff_roll5_diff',\n",
    "    \"efg_roll3_diff\", \"efg_roll5_diff\",\n",
    "    \"tov_rate_roll3_diff\", \"tov_rate_roll5_diff\",\n",
    "    \"reb_rate_roll3_diff\", \"reb_rate_roll5_diff\",\n",
    "    \"ft_eff_roll3_diff\", \"ft_eff_roll5_diff\",\n",
    "]\n",
    "\n",
    "\n",
    "ALL = FEATURE_COLS + ID_COLS + ['margin']\n",
    "games_f = games_feat[ALL]\n",
    "games_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96853f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FEATS = FEATURE_COLS\n",
    "\n",
    "monos = \"(\" + \",\".join([\"1\"] + [\"0\"]*(len(FEATS)-1)) + \")\"\n",
    "\n",
    "def time_splits(df, date_col=\"date\", splits=(0.6, 0.2, 0.2)):\n",
    "    assert abs(sum(splits) - 1.0) < 1e-9\n",
    "    d = df.sort_values(date_col).reset_index(drop=True)\n",
    "    cut1 = d[date_col].quantile(splits[0])\n",
    "    cut2 = d[date_col].quantile(splits[0] + splits[1])\n",
    "    idx_tr = np.flatnonzero(d[date_col] <  cut1)\n",
    "    idx_va = np.flatnonzero((d[date_col] >= cut1) & (d[date_col] < cut2))\n",
    "    idx_te = np.flatnonzero(d[date_col] >= cut2)\n",
    "    return idx_tr, idx_va, idx_te\n",
    "\n",
    "games_sorted = games_f.sort_values(\"date\").reset_index(drop=True)\n",
    "idx_tr, idx_va, idx_te = time_splits(games_sorted, \"date\", (0.6, 0.2, 0.2))\n",
    "\n",
    "X = games_sorted.loc[:, FEATS]\n",
    "y = games_sorted[\"margin\"]\n",
    "\n",
    "X_tr, y_tr = X.iloc[idx_tr], y.iloc[idx_tr]\n",
    "X_va, y_va = X.iloc[idx_va], y.iloc[idx_va]\n",
    "X_te, y_te = X.iloc[idx_te], y.iloc[idx_te]\n",
    "\n",
    "X_va = X_va.reindex(columns=X_tr.columns)\n",
    "X_te = X_te.reindex(columns=X_tr.columns)\n",
    "\n",
    "date_series = games_sorted[\"date\"].dt.normalize()\n",
    "\n",
    "groups_tr = date_series.iloc[idx_tr].to_numpy()\n",
    "groups_va = date_series.iloc[idx_va].to_numpy()\n",
    "groups_te = date_series.iloc[idx_te].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99f10fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 80 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesvournakis/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Î¼ params (XGB): {'colsample_bytree': np.float64(0.7673108077373452), 'gamma': np.float64(0.008601587656840977), 'learning_rate': np.float64(0.01551254285558905), 'max_depth': 4, 'min_child_weight': np.float64(4.261133996481091), 'n_estimators': 685, 'reg_alpha': np.float64(0.00016270574291440775), 'reg_lambda': np.float64(0.02104914217006881), 'subsample': np.float64(0.9226318201849737)}\n",
      "CV MAE: 9.384044329325357\n",
      "Fitting 6 folds for each of 80 candidates, totalling 480 fits\n",
      "Best quantile(0.50) params (XGB): {'colsample_bytree': np.float64(0.9214701248594064), 'gamma': np.float64(0.08982808891680345), 'learning_rate': np.float64(0.030539932325755536), 'max_depth': 8, 'min_child_weight': np.float64(0.7005326744482511), 'n_estimators': 1359, 'reg_alpha': np.float64(9.009866832998004e-05), 'reg_lambda': np.float64(3.2921891287053415), 'subsample': np.float64(0.7051987514668574)}\n",
      "CV pinball(0.50): 5.365166266759236\n",
      "Fitting 6 folds for each of 80 candidates, totalling 480 fits\n",
      "Best quantile(0.16) params (XGB): {'colsample_bytree': np.float64(0.7912763957556734), 'gamma': np.float64(0.013112689107363063), 'learning_rate': np.float64(0.03441331435048037), 'max_depth': 7, 'min_child_weight': np.float64(5.5661395487572864), 'n_estimators': 761, 'reg_alpha': np.float64(0.00011785486089331784), 'reg_lambda': np.float64(0.06814813443747608), 'subsample': np.float64(0.7937190416263051)}\n",
      "CV pinball(0.16): 4.4935676256815595\n",
      "Fitting 6 folds for each of 80 candidates, totalling 480 fits\n",
      "Best quantile(0.84) params (XGB): {'colsample_bytree': np.float64(0.7262930318044187), 'gamma': np.float64(0.0020769613004599716), 'learning_rate': np.float64(0.01736343054257359), 'max_depth': 8, 'min_child_weight': np.float64(1.3755043292978584), 'n_estimators': 809, 'reg_alpha': np.float64(0.00010155171887979748), 'reg_lambda': np.float64(0.13502537086659105), 'subsample': np.float64(0.8131825976670318)}\n",
      "CV pinball(0.84): 6.236764589945476\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n",
      "Best MLP params: {'mlp__activation': 'tanh', 'mlp__alpha': np.float64(0.0001715450310232563), 'mlp__batch_size': 256, 'mlp__hidden_layer_sizes': (192, 96), 'mlp__learning_rate_init': np.float64(0.00013483565073257994)}\n",
      "CV MAE (MLP-only): 9.289648364764568\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n",
      "Best Î¼ params (HGB): {'l2_regularization': np.float64(1.815145649657759e-05), 'learning_rate': np.float64(0.04435424810484039), 'max_depth': 3, 'max_leaf_nodes': 132, 'min_samples_leaf': 132}\n",
      "CV MAE (HGB): 9.29700173269285\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesvournakis/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Î¼ params (ETR): {'max_depth': 6, 'max_features': np.float64(0.754535765912945), 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 810}\n",
      "CV MAE (ETR): 9.27568242460656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesvournakis/Desktop/Projects/nba_model/.venv/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:1622: FutureWarning: 'n_alphas' was deprecated in 1.7 and will be removed in 1.9. 'alphas' now accepts an integer value which removes the need to pass 'n_alphas'. The default value of 'alphas' will change from None to 100 in 1.9. Pass an explicit value to 'alphas' and leave 'n_alphas' to its default value to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation]\n",
      "MAE = 9.969   RMSE = 12.767\n",
      "Coverage @1Ïƒ = 0.638 (target â‰ˆ 0.683)   @2Ïƒ = 0.920 (target â‰ˆ 0.954)\n",
      "Mean CRPS = 7.152\n",
      "Bias (mean error) = -0.000 | Median error = -0.057\n",
      "Sigma source: residual | blend weight (quantiles) = 0.000\n",
      "Mu calibration: slope=1.3911, intercept=-0.1872\n",
      "Diag preview: {'sigma_source': 'residual', 'blend_weight_quantile': 0.0, 'fallback_used': True}\n",
      "Mu calib params: {'slope': 1.391073113871251, 'intercept': -0.18717800001879992}\n",
      "\n",
      "[Test] Head:\n",
      "       mu_margin  sigma_margin  p_home_win  model_spread_home sigma_source  \\\n",
      "22192  -4.120032     11.316211    0.357898           4.120032     residual   \n",
      "22193   2.640865     12.215816    0.585578          -2.640865     residual   \n",
      "22194   5.170536     11.091322    0.679456          -5.170536     residual   \n",
      "22195   2.447408     11.093875    0.587302          -2.447408     residual   \n",
      "22196   4.289424     11.440736    0.646142          -4.289424     residual   \n",
      "\n",
      "       sigma_weight_quantile  \n",
      "22192                    0.0  \n",
      "22193                    0.0  \n",
      "22194                    0.0  \n",
      "22195                    0.0  \n",
      "22196                    0.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# NBA Spread (Margin) Stack â€” XGBoost + MLP tuning\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "from scipy.stats import norm, randint, uniform, loguniform\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge, ElasticNetCV, LinearRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_pinball_loss\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import xgboost as xgb\n",
    "\n",
    "ABS_NORMAL_FACTOR = np.sqrt(2.0 / np.pi)\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def mae_rmse(y_true, y_pred) -> Tuple[float, float]:\n",
    "    err = y_true - y_pred\n",
    "    mae = float(np.mean(np.abs(err)))\n",
    "    rmse = float(np.sqrt(np.mean(err**2)))\n",
    "    return mae, rmse\n",
    "\n",
    "def gaussian_crps(y, mu, sigma):\n",
    "    z = (y - mu) / sigma\n",
    "    return sigma * ( z*(2*norm.cdf(z)-1) + 2*norm.pdf(z) - 1/np.sqrt(np.pi) )\n",
    "\n",
    "def coverage(y, mu, sigma, k=1.0) -> float:\n",
    "    return float(np.mean(np.abs(y - mu) <= k * sigma))\n",
    "\n",
    "def prob_home_win_from_margin(mu, sigma):\n",
    "    return 1.0 - norm.cdf((0.0 - mu) / sigma)\n",
    "\n",
    "def fit_sigma_affine(y_true, mu_pred, sigma_pred, mode=\"constrained\"):\n",
    "    \"\"\"\n",
    "    Calibrate sigma on validation. Modes:\n",
    "      - \"scale\":     sigma' = a * sigma        (no intercept)\n",
    "      - \"constrained\": sigma' = a * sigma + b  with a >= 0.2 (keeps relative variation)\n",
    "    Returns (a, b).\n",
    "    \"\"\"\n",
    "    r = np.abs(y_true - mu_pred)\n",
    "    s = np.asarray(sigma_pred)\n",
    "\n",
    "    if mode == \"scale\":\n",
    "        denom = np.dot(s, s) + 1e-12\n",
    "        a = float(np.dot(s, r) / denom)\n",
    "        a = max(a, 1e-6)\n",
    "        return a, 0.0\n",
    "\n",
    "    X = np.column_stack([s, np.ones_like(s)])\n",
    "    a_b, *_ = np.linalg.lstsq(X, r, rcond=None)\n",
    "    a, b = map(float, a_b)\n",
    "    a = max(a, 0.2)\n",
    "    b = max(b, 0.0)\n",
    "    return a, b\n",
    "\n",
    "# ----------------------------\n",
    "# Custom Quantile-XGB wrapper\n",
    "# ----------------------------\n",
    "class QuantileXGBRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, alpha=0.5, hess_eps=1e-6, **xgb_params):\n",
    "        self.alpha = alpha\n",
    "        self.hess_eps = hess_eps\n",
    "        self.xgb_params = xgb_params\n",
    "        self._booster = None\n",
    "        self._num_boost_round = None\n",
    "\n",
    "    def _pinball_obj(self, preds: np.ndarray, dtrain: xgb.DMatrix):\n",
    "        y = dtrain.get_label()\n",
    "        u = y - preds\n",
    "        grad = np.where(u > 0.0, -self.alpha, 1.0 - self.alpha)\n",
    "        hess = np.full_like(grad, self.hess_eps)\n",
    "        return grad, hess\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"alpha\": self.alpha, \"hess_eps\": self.hess_eps, **self.xgb_params}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        if \"alpha\" in params:\n",
    "            self.alpha = params.pop(\"alpha\")\n",
    "        if \"hess_eps\" in params:\n",
    "            self.hess_eps = params.pop(\"hess_eps\")\n",
    "        self.xgb_params.update(params)\n",
    "        return self\n",
    "\n",
    "    def _to_train_params(self):\n",
    "        params = self.xgb_params.copy()\n",
    "        self._num_boost_round = int(params.pop(\"n_estimators\", 800))\n",
    "        if \"learning_rate\" in params:\n",
    "            params[\"eta\"] = params.pop(\"learning_rate\")\n",
    "        if \"n_jobs\" in params:\n",
    "            params[\"nthread\"] = params.pop(\"n_jobs\")\n",
    "        if \"random_state\" in params:\n",
    "            params[\"seed\"] = params.pop(\"random_state\")\n",
    "        params.setdefault(\"tree_method\", \"hist\")\n",
    "        params.setdefault(\"objective\", \"reg:squarederror\")\n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        params = self._to_train_params()\n",
    "        self._booster = xgb.train(params=params, dtrain=dtrain,\n",
    "                                  num_boost_round=self._num_boost_round,\n",
    "                                  obj=self._pinball_obj, verbose_eval=False)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self._booster.predict(xgb.DMatrix(X))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Time-aware stacking regressor\n",
    "# ----------------------------\n",
    "class TwoStageStackTSRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, base_estimators, meta_estimator, n_splits=6, group_gap=1, verbose=False):\n",
    "        self.base_estimators = base_estimators\n",
    "        self.meta_estimator = meta_estimator\n",
    "        self.n_splits = n_splits\n",
    "        self.group_gap = group_gap\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _safe_slice(self, X, idx):\n",
    "        return X.iloc[idx] if hasattr(X, \"iloc\") else X[idx]\n",
    "\n",
    "    def fit(self, X, y, groups=None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\"TwoStageStackTSRegressor requires 'groups' for time-aware CV\")\n",
    "\n",
    "        y_arr = np.asarray(y, dtype=float)\n",
    "        groups_arr = np.asarray(groups)\n",
    "        if groups_arr.shape[0] != y_arr.shape[0]:\n",
    "            raise ValueError(\"groups must align with y\")\n",
    "\n",
    "        splitter = PurgedGroupTimeSeriesSplit(n_splits=self.n_splits, group_gap=self.group_gap)\n",
    "        dummy_X = np.zeros((len(y_arr), 1))\n",
    "        splits = list(splitter.split(dummy_X, y_arr, groups_arr))\n",
    "\n",
    "        oof_cols = []\n",
    "        self.base_fitted_ = []\n",
    "        for name, est in self.base_estimators:\n",
    "            oof = np.full(len(y_arr), np.nan, dtype=float)\n",
    "            for fold_idx, (tr_idx, va_idx) in enumerate(splits):\n",
    "                model = clone(est)\n",
    "                model.fit(self._safe_slice(X, tr_idx), y_arr[tr_idx])\n",
    "                oof[va_idx] = model.predict(self._safe_slice(X, va_idx))\n",
    "            mask = ~np.isnan(oof)\n",
    "            if not np.any(mask):\n",
    "                raise RuntimeError(f\"No validation coverage for base estimator '{name}'\")\n",
    "            oof_cols.append(oof)\n",
    "            fitted = clone(est)\n",
    "            fitted.fit(X, y_arr)\n",
    "            self.base_fitted_.append((name, fitted))\n",
    "\n",
    "        Z = np.column_stack(oof_cols)\n",
    "        mask_all = np.all(~np.isnan(Z), axis=1)\n",
    "        if not np.any(mask_all):\n",
    "            raise RuntimeError(\"No overlapping OOF coverage across base estimators\")\n",
    "        self.meta_ = clone(self.meta_estimator).fit(Z[mask_all], y_arr[mask_all])\n",
    "        self.mask_ = mask_all\n",
    "        self.base_names_ = [name for name, _ in self.base_estimators]\n",
    "        self.n_features_in_ = Z.shape[1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, [\"meta_\", \"base_fitted_\"])\n",
    "        preds = [est.predict(X) for _, est in self.base_fitted_]\n",
    "        Z = np.column_stack(preds)\n",
    "        return self.meta_.predict(Z)\n",
    "\n",
    "# ----------------------------\n",
    "# Small search spaces & tuners (XGB + MLP + HGB)\n",
    "# ----------------------------\n",
    "pinball50 = make_scorer(mean_pinball_loss, alpha=0.50, greater_is_better=False)\n",
    "neg_mae   = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "def small_space_xgb_mu():\n",
    "    return {\n",
    "        \"n_estimators\": randint(600, 1400),\n",
    "        \"learning_rate\": loguniform(0.015, 0.08),\n",
    "        \"max_depth\": randint(4, 9),\n",
    "        \"min_child_weight\": loguniform(0.7, 6.0),\n",
    "        \"subsample\": uniform(0.7, 0.25),\n",
    "        \"colsample_bytree\": uniform(0.7, 0.25),\n",
    "        \"gamma\": loguniform(1e-3, 3e-1),\n",
    "        \"reg_alpha\": loguniform(1e-5, 5e-2),\n",
    "        \"reg_lambda\": loguniform(1e-2, 5.0)\n",
    "    }\n",
    "\n",
    "def small_space_xgb_quantile():\n",
    "    return {\n",
    "        \"n_estimators\": randint(600, 1400),\n",
    "        \"learning_rate\": loguniform(0.015, 0.08),\n",
    "        \"max_depth\": randint(4, 9),\n",
    "        \"min_child_weight\": loguniform(0.7, 6.0),\n",
    "        \"subsample\": uniform(0.7, 0.25),\n",
    "        \"colsample_bytree\": uniform(0.7, 0.25),\n",
    "        \"gamma\": loguniform(1e-3, 3e-1),\n",
    "        \"reg_alpha\": loguniform(1e-5, 5e-2),\n",
    "        \"reg_lambda\": loguniform(1e-2, 5.0)\n",
    "    }\n",
    "\n",
    "def small_space_mlp():\n",
    "    return {\n",
    "        \"mlp__hidden_layer_sizes\": [(128, 64), (192, 96), (128, 64, 32), (256, 128)],\n",
    "        \"mlp__activation\": [\"relu\", \"tanh\"],\n",
    "        \"mlp__alpha\": loguniform(1e-5, 5e-2),\n",
    "        \"mlp__learning_rate_init\": loguniform(1e-4, 2e-2),\n",
    "        \"mlp__batch_size\": [64, 128, 256]\n",
    "    }\n",
    "\n",
    "def small_space_hgb():\n",
    "    return {\n",
    "        \"learning_rate\": loguniform(0.01, 0.2),\n",
    "        \"max_depth\": randint(3, 9),\n",
    "        \"max_leaf_nodes\": randint(32, 180),\n",
    "        \"min_samples_leaf\": randint(20, 140),\n",
    "        \"l2_regularization\": loguniform(1e-6, 1e-1)\n",
    "    }\n",
    "\n",
    "def small_space_etr():\n",
    "    return {\n",
    "        \"n_estimators\": randint(300, 900),\n",
    "        \"max_depth\": randint(4, 16),\n",
    "        \"min_samples_split\": randint(2, 20),\n",
    "        \"min_samples_leaf\": randint(1, 10),\n",
    "        \"max_features\": uniform(0.4, 0.6)\n",
    "    }\n",
    "\n",
    "def tune_mlp(X, y, n_iter=40, n_splits=6, random_state=42):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"mlp\", MLPRegressor(solver=\"adam\", early_stopping=True, max_iter=700,\n",
    "                             random_state=random_state))\n",
    "    ])\n",
    "    rs = RandomizedSearchCV(\n",
    "        pipe, param_distributions=small_space_mlp(), n_iter=n_iter,\n",
    "        scoring=neg_mae, cv=tscv, verbose=1, random_state=random_state, n_jobs=-1\n",
    "    )\n",
    "    rs.fit(X, y)\n",
    "    print(\"Best MLP params:\", rs.best_params_)\n",
    "    print(\"CV MAE (MLP-only):\", -rs.best_score_)\n",
    "    best = {k.split(\"mlp__\")[1]: v for k, v in rs.best_params_.items() if k.startswith(\"mlp__\")}\n",
    "    best.update(dict(solver=\"adam\", early_stopping=True, max_iter=700, random_state=random_state))\n",
    "    return best\n",
    "\n",
    "def tune_xgb_mu(X, y, n_iter=80, n_splits=6, random_state=42):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    base = xgb.XGBRegressor(objective=\"reg:squarederror\",\n",
    "                            random_state=random_state, n_jobs=-1, tree_method=\"hist\")\n",
    "    rs = RandomizedSearchCV(\n",
    "        base, param_distributions=small_space_xgb_mu(), n_iter=n_iter,\n",
    "        scoring=neg_mae, cv=tscv, verbose=1, random_state=random_state, n_jobs=-1\n",
    "    )\n",
    "    rs.fit(X, y)\n",
    "    print(\"Best Î¼ params (XGB):\", rs.best_params_)\n",
    "    print(\"CV MAE:\", -rs.best_score_)\n",
    "    return rs.best_params_\n",
    "\n",
    "def tune_xgb_quantile(X, y, alpha, n_iter=80, n_splits=6, random_state=42):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    search_seed = random_state + int(round(alpha * 100))\n",
    "    base = QuantileXGBRegressor(alpha=alpha, random_state=search_seed, n_jobs=-1, tree_method=\"hist\")\n",
    "    rs = RandomizedSearchCV(\n",
    "        base, param_distributions=small_space_xgb_quantile(), n_iter=n_iter,\n",
    "        scoring=make_scorer(mean_pinball_loss, alpha=alpha, greater_is_better=False),\n",
    "        cv=tscv, verbose=1, random_state=search_seed, n_jobs=-1\n",
    "    )\n",
    "    rs.fit(X, y)\n",
    "    print(f\"Best quantile({alpha:.2f}) params (XGB):\", rs.best_params_)\n",
    "    print(f\"CV pinball({alpha:.2f}):\", -rs.best_score_)\n",
    "    return {k: v for k, v in rs.best_params_.items() if k not in (\"alpha\", \"hess_eps\")}\n",
    "\n",
    "def tune_hgb_mu(X, y, n_iter=40, n_splits=6, random_state=42):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    base = HistGradientBoostingRegressor(loss=\"squared_error\", random_state=random_state)\n",
    "    rs = RandomizedSearchCV(\n",
    "        base, param_distributions=small_space_hgb(), n_iter=n_iter,\n",
    "        scoring=neg_mae, cv=tscv, verbose=1, random_state=random_state, n_jobs=-1\n",
    "    )\n",
    "    rs.fit(X, y)\n",
    "    print(\"Best Î¼ params (HGB):\", rs.best_params_)\n",
    "    print(\"CV MAE (HGB):\", -rs.best_score_)\n",
    "    return rs.best_params_\n",
    "\n",
    "def tune_etr_mu(X, y, n_iter=40, n_splits=6, random_state=42):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    base = ExtraTreesRegressor(random_state=random_state, n_jobs=-1)\n",
    "    rs = RandomizedSearchCV(\n",
    "        base, param_distributions=small_space_etr(), n_iter=n_iter,\n",
    "        scoring=neg_mae, cv=tscv, verbose=1, random_state=random_state, n_jobs=-1\n",
    "    )\n",
    "    rs.fit(X, y)\n",
    "    print(\"Best Î¼ params (ETR):\", rs.best_params_)\n",
    "    print(\"CV MAE (ETR):\", -rs.best_score_)\n",
    "    return rs.best_params_\n",
    "\n",
    "# ----------------------------\n",
    "# Model\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class SpreadStackXGB:\n",
    "    xgb_mu_params: Optional[dict] = None\n",
    "    xgb_q50_params: Optional[dict] = None\n",
    "    xgb_q16_params: Optional[dict] = None\n",
    "    xgb_q84_params: Optional[dict] = None\n",
    "    mlp_params: Optional[dict] = None\n",
    "    hgb_params: Optional[dict] = None\n",
    "    etr_params: Optional[dict] = None\n",
    "    sigma_model_params: Optional[dict] = None\n",
    "    tune_mu_iter: int = 80\n",
    "    tune_q_iter: int = 80\n",
    "    tune_mlp_iter: int = 40\n",
    "    tune_hgb_iter: int = 40\n",
    "    tscv_splits: int = 6\n",
    "    random_state: int = 42\n",
    "    sigma_min_range: float = 0.3\n",
    "    sigma_min_rel: float = 0.03\n",
    "    stack_splits: int = 6\n",
    "    stack_gap: int = 1\n",
    "    stack_verbose: bool = False\n",
    "    sigma_blend_grid: Tuple[float, float, int] = (0.0, 1.0, 11)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.mu_stack_: Optional[TwoStageStackTSRegressor] = None\n",
    "        self.q16_: Optional[QuantileXGBRegressor] = None\n",
    "        self.q50_: Optional[QuantileXGBRegressor] = None\n",
    "        self.q84_: Optional[QuantileXGBRegressor] = None\n",
    "        self.sigma_model_: Optional[xgb.XGBRegressor] = None\n",
    "        self.fallback_sigma_: bool = False\n",
    "        self.sigma_source_: str = \"quantiles\"\n",
    "        self.sigma_blend_weight_: float = 1.0\n",
    "        self.sigma_cal_: Tuple[float, float] = (1.0, 0.0)\n",
    "        self.mu_calibration_: Tuple[float, float] = (1.0, 0.0)\n",
    "        self._va_diag_: Optional[dict] = None\n",
    "\n",
    "    def fit(self, X_tr: pd.DataFrame, y_tr: np.ndarray,\n",
    "                  X_va: pd.DataFrame, y_va: np.ndarray,\n",
    "                  *, groups_tr: Optional[np.ndarray] = None,\n",
    "                  groups_va: Optional[np.ndarray] = None):\n",
    "        if groups_tr is None:\n",
    "            raise ValueError(\"SpreadStackXGB.fit requires groups_tr for time-aware stacking\")\n",
    "\n",
    "        # --- Tune params if not provided ---\n",
    "        if self.xgb_mu_params is None:\n",
    "            self.xgb_mu_params = tune_xgb_mu(X_tr, y_tr,\n",
    "                                             n_iter=self.tune_mu_iter,\n",
    "                                             n_splits=self.tscv_splits,\n",
    "                                             random_state=self.random_state)\n",
    "            self.xgb_mu_params.update(dict(objective=\"reg:squarederror\",\n",
    "                                           random_state=self.random_state, n_jobs=-1, tree_method=\"hist\"))\n",
    "        if self.xgb_q50_params is None:\n",
    "            q50_best = tune_xgb_quantile(X_tr, y_tr, 0.5,\n",
    "                                           n_iter=self.tune_q_iter,\n",
    "                                           n_splits=self.tscv_splits,\n",
    "                                           random_state=self.random_state)\n",
    "            self.xgb_q50_params = {**q50_best, \"random_state\": self.random_state, \"n_jobs\": -1, \"tree_method\": \"hist\"}\n",
    "\n",
    "        if self.xgb_q16_params is None:\n",
    "            q16_best = tune_xgb_quantile(X_tr, y_tr, 0.16,\n",
    "                                           n_iter=self.tune_q_iter,\n",
    "                                           n_splits=self.tscv_splits,\n",
    "                                           random_state=self.random_state)\n",
    "            self.xgb_q16_params = {**q16_best, \"random_state\": self.random_state, \"n_jobs\": -1, \"tree_method\": \"hist\"}\n",
    "\n",
    "        if self.xgb_q84_params is None:\n",
    "            q84_best = tune_xgb_quantile(X_tr, y_tr, 0.84,\n",
    "                                           n_iter=self.tune_q_iter,\n",
    "                                           n_splits=self.tscv_splits,\n",
    "                                           random_state=self.random_state)\n",
    "            self.xgb_q84_params = {**q84_best, \"random_state\": self.random_state, \"n_jobs\": -1, \"tree_method\": \"hist\"}\n",
    "\n",
    "        if self.mlp_params is None:\n",
    "            self.mlp_params = tune_mlp(X_tr, y_tr,\n",
    "                                       n_iter=self.tune_mlp_iter,\n",
    "                                       n_splits=self.tscv_splits,\n",
    "                                       random_state=self.random_state)\n",
    "\n",
    "        if self.hgb_params is None:\n",
    "            self.hgb_params = tune_hgb_mu(X_tr, y_tr,\n",
    "                                          n_iter=self.tune_hgb_iter,\n",
    "                                          n_splits=self.tscv_splits,\n",
    "                                          random_state=self.random_state)\n",
    "\n",
    "        if self.etr_params is None:\n",
    "            self.etr_params = tune_etr_mu(X_tr, y_tr,\n",
    "                                          n_iter=self.tune_hgb_iter,\n",
    "                                          n_splits=self.tscv_splits,\n",
    "                                          random_state=self.random_state)\n",
    "\n",
    "        # --- Î¼ via time-aware stacking (XGB + tuned MLP + HGB) ---\n",
    "        xgb_mu = xgb.XGBRegressor(**self.xgb_mu_params)\n",
    "        mlp_mu = make_pipeline(StandardScaler(with_mean=True, with_std=True),\n",
    "                               MLPRegressor(**self.mlp_params))\n",
    "        hgb_mu = HistGradientBoostingRegressor(**self.hgb_params)\n",
    "        etr_mu = ExtraTreesRegressor(**self.etr_params)\n",
    "        meta = make_pipeline(\n",
    "            StandardScaler(with_mean=True, with_std=True),\n",
    "            ElasticNetCV(l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 1.0],\n",
    "                         n_alphas=40,\n",
    "                         cv=5,\n",
    "                         random_state=self.random_state,\n",
    "                         n_jobs=-1,\n",
    "                         selection=\"random\")\n",
    "        )\n",
    "\n",
    "        base_estimators = [\n",
    "            (\"xgb_mu\", xgb_mu),\n",
    "            (\"mlp_mu\", mlp_mu),\n",
    "            (\"hgb_mu\", hgb_mu),\n",
    "            (\"etr_mu\", etr_mu)\n",
    "        ]\n",
    "\n",
    "        self.mu_stack_ = TwoStageStackTSRegressor(\n",
    "            base_estimators=base_estimators,\n",
    "            meta_estimator=meta,\n",
    "            n_splits=self.stack_splits,\n",
    "            group_gap=self.stack_gap,\n",
    "            verbose=self.stack_verbose\n",
    "        )\n",
    "        self.mu_stack_.fit(X_tr, y_tr, groups=groups_tr)\n",
    "\n",
    "        # --- Ïƒ via quantiles (q16/q50/q84) and residual model ---\n",
    "        self.q50_ = QuantileXGBRegressor(alpha=0.50, **self.xgb_q50_params).fit(X_tr, y_tr)\n",
    "        self.q16_ = QuantileXGBRegressor(alpha=0.16, **self.xgb_q16_params).fit(X_tr, y_tr)\n",
    "        self.q84_ = QuantileXGBRegressor(alpha=0.84, **self.xgb_q84_params).fit(X_tr, y_tr)\n",
    "\n",
    "        mu_va_stack = self.mu_stack_.predict(X_va)\n",
    "        q50_va = self.q50_.predict(X_va)\n",
    "        mu_va_blend = 0.7 * mu_va_stack + 0.3 * q50_va\n",
    "\n",
    "        lr_mu = LinearRegression()\n",
    "        lr_mu.fit(mu_va_blend.reshape(-1, 1), y_va)\n",
    "        slope = float(lr_mu.coef_[0])\n",
    "        intercept = float(lr_mu.intercept_)\n",
    "        self.mu_calibration_ = (slope, intercept)\n",
    "        mu_va_cal = slope * mu_va_blend + intercept\n",
    "\n",
    "        sigma_quant_va = (self.q84_.predict(X_va) - self.q16_.predict(X_va)) / 2.0\n",
    "        sigma_quant_va = np.asarray(sigma_quant_va, dtype=float)\n",
    "\n",
    "        mu_tr_stack = self.mu_stack_.predict(X_tr)\n",
    "        q50_tr = self.q50_.predict(X_tr)\n",
    "        mu_tr_blend = 0.7 * mu_tr_stack + 0.3 * q50_tr\n",
    "        mu_tr_cal = slope * mu_tr_blend + intercept\n",
    "        resid_tr = np.abs(y_tr - mu_tr_cal)\n",
    "        target_sigma_tr = resid_tr / ABS_NORMAL_FACTOR\n",
    "\n",
    "        sigma_params = dict(self.sigma_model_params) if self.sigma_model_params is not None else {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"random_state\": self.random_state,\n",
    "            \"n_estimators\": 800,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"max_depth\": 6,\n",
    "            \"subsample\": 0.85,\n",
    "            \"colsample_bytree\": 0.85,\n",
    "            \"min_child_weight\": 1.0,\n",
    "            \"n_jobs\": -1,\n",
    "            \"tree_method\": \"hist\",\n",
    "        }\n",
    "\n",
    "        self.sigma_model_ = xgb.XGBRegressor(**sigma_params)\n",
    "        self.sigma_model_.fit(X_tr, target_sigma_tr)\n",
    "        sigma_resid_va = np.asarray(self.sigma_model_.predict(X_va), dtype=float)\n",
    "\n",
    "        sigma_quant_va = np.where(sigma_quant_va <= 0, 1e-6, sigma_quant_va)\n",
    "        sigma_resid_va = np.where(sigma_resid_va <= 0, 1e-6, sigma_resid_va)\n",
    "\n",
    "        sigma_range = float(np.ptp(sigma_quant_va)) if sigma_quant_va.size else 0.0\n",
    "        sigma_mean = float(np.mean(sigma_quant_va)) if sigma_quant_va.size else 0.0\n",
    "        rel_range = sigma_range / max(abs(sigma_mean), 1e-6) if sigma_quant_va.size else 0.0\n",
    "        use_fallback = (not np.isfinite(sigma_range)) or (sigma_range < self.sigma_min_range and rel_range < self.sigma_min_rel)\n",
    "\n",
    "        if use_fallback:\n",
    "            self.fallback_sigma_ = True\n",
    "            self.sigma_blend_weight_ = 0.0\n",
    "            sigma_va = sigma_resid_va\n",
    "        else:\n",
    "            blend_min, blend_max, blend_steps = self.sigma_blend_grid\n",
    "            weights = np.linspace(blend_min, blend_max, int(blend_steps)) if blend_steps > 1 else np.array([blend_min])\n",
    "            best_w, best_crps, best_sigma = 1.0, np.inf, sigma_quant_va\n",
    "            for w in weights:\n",
    "                sigma_candidate = w * sigma_quant_va + (1.0 - w) * sigma_resid_va\n",
    "                sigma_candidate = np.where(sigma_candidate <= 0, 1e-6, sigma_candidate)\n",
    "                crps = float(np.mean(gaussian_crps(y_va, mu_va_cal, sigma_candidate)))\n",
    "                if crps < best_crps:\n",
    "                    best_crps = crps\n",
    "                    best_w = float(w)\n",
    "                    best_sigma = sigma_candidate\n",
    "            self.fallback_sigma_ = False\n",
    "            self.sigma_blend_weight_ = best_w\n",
    "            sigma_va = best_sigma\n",
    "\n",
    "        sigma_va = np.where(sigma_va <= 0, 1e-6, sigma_va)\n",
    "\n",
    "        a, b = fit_sigma_affine(y_va, mu_va_cal, sigma_va, mode=\"constrained\")\n",
    "        self.sigma_cal_ = (a, b)\n",
    "\n",
    "        if self.fallback_sigma_:\n",
    "            self.sigma_source_ = \"residual\"\n",
    "        else:\n",
    "            if self.sigma_blend_weight_ >= 0.99:\n",
    "                self.sigma_source_ = \"quantiles\"\n",
    "            elif self.sigma_blend_weight_ <= 0.01:\n",
    "                self.sigma_source_ = \"residual\"\n",
    "            else:\n",
    "                self.sigma_source_ = \"blend\"\n",
    "\n",
    "        self._va_diag_ = {\n",
    "            \"mu\": mu_va_cal.tolist(),\n",
    "            \"sigma_quant\": sigma_quant_va.tolist(),\n",
    "            \"sigma_resid\": sigma_resid_va.tolist(),\n",
    "            \"sigma_final\": sigma_va.tolist(),\n",
    "            \"a\": a,\n",
    "            \"b\": b,\n",
    "            \"y\": y_va.tolist(),\n",
    "            \"sigma_source\": self.sigma_source_,\n",
    "            \"sigma_range_quant\": float(np.ptp(sigma_quant_va)),\n",
    "            \"sigma_mean_quant\": float(np.mean(sigma_quant_va)),\n",
    "            \"blend_weight_quantile\": self.sigma_blend_weight_,\n",
    "            \"fallback_used\": self.fallback_sigma_,\n",
    "            \"mu_calibration\": {\"slope\": slope, \"intercept\": intercept}\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def _predict_components(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        mu_stack = self.mu_stack_.predict(X)\n",
    "        q50 = self.q50_.predict(X)\n",
    "        mu = 0.7 * mu_stack + 0.3 * q50\n",
    "\n",
    "        sigma_quant = (self.q84_.predict(X) - self.q16_.predict(X)) / 2.0\n",
    "        sigma_quant = np.asarray(sigma_quant, dtype=float)\n",
    "        sigma_quant = np.where(sigma_quant <= 0, 1e-6, sigma_quant)\n",
    "\n",
    "        sigma_resid = np.asarray(self.sigma_model_.predict(X), dtype=float) if self.sigma_model_ is not None else sigma_quant\n",
    "        sigma_resid = np.where(sigma_resid <= 0, 1e-6, sigma_resid)\n",
    "\n",
    "        if self.fallback_sigma_:\n",
    "            sigma = sigma_resid\n",
    "        else:\n",
    "            sigma = self.sigma_blend_weight_ * sigma_quant + (1.0 - self.sigma_blend_weight_) * sigma_resid\n",
    "\n",
    "        slope, intercept = self.mu_calibration_\n",
    "        mu = slope * mu + intercept\n",
    "\n",
    "        sigma = np.where(sigma <= 0, 1e-6, sigma)\n",
    "        a, b = self.sigma_cal_\n",
    "        sigma_cal = a * sigma + b\n",
    "        sigma_cal = np.where(sigma_cal <= 0, 1e-6, sigma_cal)\n",
    "        return mu, sigma_cal\n",
    "\n",
    "    def predict_frame(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        mu, sigma = self._predict_components(X)\n",
    "        frame = pd.DataFrame({\n",
    "            \"mu_margin\": mu,\n",
    "            \"sigma_margin\": sigma,\n",
    "            \"p_home_win\": prob_home_win_from_margin(mu, sigma),\n",
    "            \"model_spread_home\": -mu\n",
    "        }, index=X.index)\n",
    "        frame[\"sigma_source\"] = self.sigma_source_\n",
    "        frame[\"sigma_weight_quantile\"] = self.sigma_blend_weight_\n",
    "        return frame\n",
    "\n",
    "# ----------------------------\n",
    "# TRAIN & EVALUATE\n",
    "# ----------------------------\n",
    "spread_stack = SpreadStackXGB().fit(X_tr, y_tr, X_va, y_va, groups_tr=groups_tr, groups_va=groups_va)\n",
    "\n",
    "pred_va = spread_stack.predict_frame(X_va)\n",
    "mu_va, sigma_va = pred_va[\"mu_margin\"].values, pred_va[\"sigma_margin\"].values\n",
    "\n",
    "mae, rmse = mae_rmse(y_va, mu_va)\n",
    "cov68 = coverage(y_va, mu_va, sigma_va, k=1.0)\n",
    "cov95 = coverage(y_va, mu_va, sigma_va, k=2.0)\n",
    "crps = float(np.mean(gaussian_crps(y_va, mu_va, sigma_va)))\n",
    "\n",
    "print(f\"[Validation]\")\n",
    "print(f\"MAE = {mae:.3f}   RMSE = {rmse:.3f}\")\n",
    "print(f\"Coverage @1Ïƒ = {cov68:.3f} (target â‰ˆ 0.683)   @2Ïƒ = {cov95:.3f} (target â‰ˆ 0.954)\")\n",
    "print(f\"Mean CRPS = {crps:.3f}\")\n",
    "bias = float(np.mean(mu_va - y_va))\n",
    "med_err = float(np.median(mu_va - y_va))\n",
    "print(f\"Bias (mean error) = {bias:.3f} | Median error = {med_err:.3f}\")\n",
    "print(f\"Sigma source: {spread_stack.sigma_source_} | blend weight (quantiles) = {spread_stack.sigma_blend_weight_:.3f}\")\n",
    "print(f\"Mu calibration: slope={spread_stack.mu_calibration_[0]:.4f}, intercept={spread_stack.mu_calibration_[1]:.4f}\")\n",
    "if spread_stack._va_diag_ is not None:\n",
    "    print(\"Diag preview:\", {k: spread_stack._va_diag_[k] for k in [\"sigma_source\", \"blend_weight_quantile\", \"fallback_used\"]})\n",
    "    print(\"Mu calib params:\", spread_stack._va_diag_.get(\"mu_calibration\"))\n",
    "\n",
    "# Optional test predictions\n",
    "try:\n",
    "    pred_te = spread_stack.predict_frame(X_te)\n",
    "    print(\"\\n[Test] Head:\")\n",
    "    print(pred_te[[\"mu_margin\",\"sigma_margin\",\"p_home_win\",\"model_spread_home\",\"sigma_source\",\"sigma_weight_quantile\"]].head())\n",
    "except NameError:\n",
    "    pred_te = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d5156568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "win_home\n",
       "True     3071\n",
       "False    2477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.where(pred_te['p_home_win'] > 0.5,  1, 0) == games_feat['win_home'].iloc[idx_te]).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
